[
  {
    "node_type": "agentAgentflow",
    "name": "agentAgentflow",
    "label": "Agent",
    "category": "Agent Flows",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-agentModel-asyncOptions",
        "name": "agentModel",
        "label": "agentModel",
        "type": "asyncOptions",
        "optional": true,
        "description": "Model"
      },
      {
        "id": "{nodeId}-input-agentMessages-array",
        "name": "agentMessages",
        "label": "agentMessages",
        "type": "array",
        "optional": true,
        "description": "Messages"
      },
      {
        "id": "{nodeId}-input-agentToolsBuiltInOpenAI-multiOptions",
        "name": "agentToolsBuiltInOpenAI",
        "label": "agentToolsBuiltInOpenAI",
        "type": "multiOptions",
        "optional": true,
        "description": "OpenAI Built-in Tools"
      },
      {
        "id": "{nodeId}-input-agentToolsBuiltInGemini-multiOptions",
        "name": "agentToolsBuiltInGemini",
        "label": "agentToolsBuiltInGemini",
        "type": "multiOptions",
        "optional": true,
        "description": "Gemini Built-in Tools"
      },
      {
        "id": "{nodeId}-input-agentToolsBuiltInAnthropic-multiOptions",
        "name": "agentToolsBuiltInAnthropic",
        "label": "agentToolsBuiltInAnthropic",
        "type": "multiOptions",
        "optional": true,
        "description": "Anthropic Built-in Tools"
      },
      {
        "id": "{nodeId}-input-agentTools-array",
        "name": "agentTools",
        "label": "agentTools",
        "type": "array",
        "optional": true,
        "description": "Tools"
      },
      {
        "id": "{nodeId}-input-agentKnowledgeDocumentStores-array",
        "name": "agentKnowledgeDocumentStores",
        "label": "agentKnowledgeDocumentStores",
        "type": "array",
        "optional": true,
        "description": "Give your agent context about different document sources. Document stores must be upserted in advanc"
      },
      {
        "id": "{nodeId}-input-agentKnowledgeVSEmbeddings-array",
        "name": "agentKnowledgeVSEmbeddings",
        "label": "agentKnowledgeVSEmbeddings",
        "type": "array",
        "optional": true,
        "description": "Give your agent context about different document sources from existing vector stores and embeddings"
      },
      {
        "id": "{nodeId}-input-agentEnableMemory-boolean",
        "name": "agentEnableMemory",
        "label": "agentEnableMemory",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "Enable memory for the conversation thread"
      },
      {
        "id": "{nodeId}-input-agentMemoryType-options",
        "name": "agentMemoryType",
        "label": "agentMemoryType",
        "type": "options",
        "optional": true,
        "default": "allMessages",
        "description": "Memory Type"
      },
      {
        "id": "{nodeId}-input-agentMemoryWindowSize-number",
        "name": "agentMemoryWindowSize",
        "label": "agentMemoryWindowSize",
        "type": "number",
        "optional": true,
        "default": "20",
        "description": "Uses a fixed window size to surface the last N messages"
      },
      {
        "id": "{nodeId}-input-agentMemoryMaxTokenLimit-number",
        "name": "agentMemoryMaxTokenLimit",
        "label": "agentMemoryMaxTokenLimit",
        "type": "number",
        "optional": true,
        "default": "2000",
        "description": "Summarize conversations once token limit is reached. Default to 2000"
      },
      {
        "id": "{nodeId}-input-agentUserMessage-string",
        "name": "agentUserMessage",
        "label": "agentUserMessage",
        "type": "string",
        "optional": true,
        "description": "Add an input message as user message at the end of the conversation"
      },
      {
        "id": "{nodeId}-input-agentReturnResponseAs-options",
        "name": "agentReturnResponseAs",
        "label": "agentReturnResponseAs",
        "type": "options",
        "optional": true,
        "default": "userMessage",
        "description": "Return Response As"
      },
      {
        "id": "{nodeId}-input-agentStructuredOutput-array",
        "name": "agentStructuredOutput",
        "label": "agentStructuredOutput",
        "type": "array",
        "optional": true,
        "description": "Instruct the Agent to give output in a JSON structured schema"
      },
      {
        "id": "{nodeId}-input-agentUpdateState-array",
        "name": "agentUpdateState",
        "label": "agentUpdateState",
        "type": "array",
        "optional": true,
        "description": "Update runtime state during the execution of the workflow"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-agentAgentflow-Agent",
        "name": "agentAgentflow",
        "label": "Agent",
        "type": "Agent"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "3.2",
    "description": "Dynamically choose and utilize tools during runtime, enabling multi-step reasoning",
    "baseClasses": [
      "Agent"
    ]
  },
  {
    "node_type": "conditionAgentAgentflow",
    "name": "conditionAgentAgentflow",
    "label": "Condition Agent",
    "category": "Agent Flows",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-conditionAgentModel-asyncOptions",
        "name": "conditionAgentModel",
        "label": "conditionAgentModel",
        "type": "asyncOptions",
        "optional": true,
        "description": "Model"
      },
      {
        "id": "{nodeId}-input-conditionAgentInstructions-string",
        "name": "conditionAgentInstructions",
        "label": "conditionAgentInstructions",
        "type": "string",
        "optional": true,
        "description": "A general instructions of what the condition agent should do"
      },
      {
        "id": "{nodeId}-input-conditionAgentInput-string",
        "name": "conditionAgentInput",
        "label": "conditionAgentInput",
        "type": "string",
        "optional": true,
        "default": "{{ question }}",
        "description": "Input to be used for the condition agent"
      },
      {
        "id": "{nodeId}-input-conditionAgentScenarios-array",
        "name": "conditionAgentScenarios",
        "label": "conditionAgentScenarios",
        "type": "array",
        "optional": true,
        "default": "[{'scenario': ''}, {'scenario': ''}]",
        "description": "Define the scenarios that will be used as the conditions to split the flow"
      },
      {
        "id": "{nodeId}-input-conditionAgentOverrideSystemPrompt-boolean",
        "name": "conditionAgentOverrideSystemPrompt",
        "label": "conditionAgentOverrideSystemPrompt",
        "type": "boolean",
        "optional": true,
        "description": "Override initial system prompt for Condition Agent"
      },
      {
        "id": "{nodeId}-input-conditionAgentSystemPrompt-string",
        "name": "conditionAgentSystemPrompt",
        "label": "conditionAgentSystemPrompt",
        "type": "string",
        "optional": true
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-conditionAgentAgentflow-ConditionAgent",
        "name": "conditionAgentAgentflow",
        "label": "Condition Agent",
        "type": "ConditionAgent"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1.1",
    "description": "Utilize an agent to split flows based on dynamic conditions",
    "baseClasses": [
      "ConditionAgent"
    ]
  },
  {
    "node_type": "conditionAgentflow",
    "name": "conditionAgentflow",
    "label": "Condition",
    "category": "Agent Flows",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-conditions-array",
        "name": "conditions",
        "label": "conditions",
        "type": "array",
        "optional": true,
        "default": "[{'type': 'string', 'value1': '', 'operation': 'equal', 'value2': ''}]",
        "description": "Values to compare"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-conditionAgentflow-Condition",
        "name": "conditionAgentflow",
        "label": "Condition",
        "type": "Condition"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Split flows based on If Else conditions",
    "baseClasses": [
      "Condition"
    ]
  },
  {
    "node_type": "customFunctionAgentflow",
    "name": "customFunctionAgentflow",
    "label": "Custom Function",
    "category": "Agent Flows",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-customFunctionInputVariables-array",
        "name": "customFunctionInputVariables",
        "label": "customFunctionInputVariables",
        "type": "array",
        "optional": true,
        "description": "Input variables can be used in the function with prefix $. For example: $foo"
      },
      {
        "id": "{nodeId}-input-customFunctionJavascriptFunction-code",
        "name": "customFunctionJavascriptFunction",
        "label": "customFunctionJavascriptFunction",
        "type": "code",
        "optional": true,
        "description": "The function to execute. Must return a string or an object that can be converted to a string."
      },
      {
        "id": "{nodeId}-input-customFunctionUpdateState-array",
        "name": "customFunctionUpdateState",
        "label": "customFunctionUpdateState",
        "type": "array",
        "optional": true,
        "description": "Update runtime state during the execution of the workflow"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-customFunctionAgentflow-CustomFunction",
        "name": "customFunctionAgentflow",
        "label": "Custom Function",
        "type": "CustomFunction"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1.1",
    "description": "Execute custom function",
    "baseClasses": [
      "CustomFunction"
    ]
  },
  {
    "node_type": "directReplyAgentflow",
    "name": "directReplyAgentflow",
    "label": "Direct Reply",
    "category": "Agent Flows",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-directReplyMessage-string",
        "name": "directReplyMessage",
        "label": "directReplyMessage",
        "type": "string",
        "optional": true,
        "description": "Message"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-directReplyAgentflow-DirectReply",
        "name": "directReplyAgentflow",
        "label": "Direct Reply",
        "type": "DirectReply"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Directly reply to the user with a message",
    "baseClasses": [
      "DirectReply"
    ]
  },
  {
    "node_type": "executeFlowAgentflow",
    "name": "executeFlowAgentflow",
    "label": "Execute Flow",
    "category": "Agent Flows",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-executeFlowSelectedFlow-asyncOptions",
        "name": "executeFlowSelectedFlow",
        "label": "executeFlowSelectedFlow",
        "type": "asyncOptions",
        "optional": true,
        "description": "Select Flow"
      },
      {
        "id": "{nodeId}-input-executeFlowInput-string",
        "name": "executeFlowInput",
        "label": "executeFlowInput",
        "type": "string",
        "optional": true,
        "description": "Input"
      },
      {
        "id": "{nodeId}-input-executeFlowOverrideConfig-json",
        "name": "executeFlowOverrideConfig",
        "label": "executeFlowOverrideConfig",
        "type": "json",
        "optional": true,
        "description": "Override the config passed to the flow"
      },
      {
        "id": "{nodeId}-input-executeFlowBaseURL-string",
        "name": "executeFlowBaseURL",
        "label": "executeFlowBaseURL",
        "type": "string",
        "optional": true,
        "description": "Base URL to Flowise. By default, it is the URL of the incoming request. Useful when you need to exec"
      },
      {
        "id": "{nodeId}-input-executeFlowReturnResponseAs-options",
        "name": "executeFlowReturnResponseAs",
        "label": "executeFlowReturnResponseAs",
        "type": "options",
        "optional": true,
        "default": "userMessage",
        "description": "Return Response As"
      },
      {
        "id": "{nodeId}-input-executeFlowUpdateState-array",
        "name": "executeFlowUpdateState",
        "label": "executeFlowUpdateState",
        "type": "array",
        "optional": true,
        "description": "Update runtime state during the execution of the workflow"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-executeFlowAgentflow-ExecuteFlow",
        "name": "executeFlowAgentflow",
        "label": "Execute Flow",
        "type": "ExecuteFlow"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1.2",
    "description": "Execute another flow",
    "baseClasses": [
      "ExecuteFlow"
    ],
    "credential_required": [
      "chatflowApi"
    ]
  },
  {
    "node_type": "httpAgentflow",
    "name": "httpAgentflow",
    "label": "HTTP",
    "category": "Agent Flows",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-method-options",
        "name": "method",
        "label": "method",
        "type": "options",
        "optional": true,
        "default": "GET",
        "description": "Method"
      },
      {
        "id": "{nodeId}-input-url-string",
        "name": "url",
        "label": "url",
        "type": "string",
        "optional": true,
        "description": "URL"
      },
      {
        "id": "{nodeId}-input-headers-array",
        "name": "headers",
        "label": "headers",
        "type": "array",
        "optional": true,
        "description": "Headers"
      },
      {
        "id": "{nodeId}-input-queryParams-array",
        "name": "queryParams",
        "label": "queryParams",
        "type": "array",
        "optional": true,
        "description": "Query Params"
      },
      {
        "id": "{nodeId}-input-bodyType-options",
        "name": "bodyType",
        "label": "bodyType",
        "type": "options",
        "optional": true,
        "description": "Body Type"
      },
      {
        "id": "{nodeId}-input-body-string",
        "name": "body",
        "label": "body",
        "type": "string",
        "optional": true,
        "description": "Body"
      },
      {
        "id": "{nodeId}-input-body-array",
        "name": "body",
        "label": "body",
        "type": "array",
        "optional": true,
        "description": "Body"
      },
      {
        "id": "{nodeId}-input-responseType-options",
        "name": "responseType",
        "label": "responseType",
        "type": "options",
        "optional": true,
        "description": "Response Type"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-httpAgentflow-HTTP",
        "name": "httpAgentflow",
        "label": "HTTP",
        "type": "HTTP"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1.1",
    "description": "Send a HTTP request",
    "baseClasses": [
      "HTTP"
    ],
    "credential_required": [
      "httpBasicAuth",
      "httpBearerToken",
      "httpApiKey"
    ]
  },
  {
    "node_type": "humanInputAgentflow",
    "name": "humanInputAgentflow",
    "label": "Human Input",
    "category": "Agent Flows",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-humanInputDescriptionType-options",
        "name": "humanInputDescriptionType",
        "label": "humanInputDescriptionType",
        "type": "options",
        "optional": true,
        "description": "Description Type"
      },
      {
        "id": "{nodeId}-input-humanInputDescription-string",
        "name": "humanInputDescription",
        "label": "humanInputDescription",
        "type": "string",
        "optional": true,
        "description": "Description"
      },
      {
        "id": "{nodeId}-input-humanInputModel-asyncOptions",
        "name": "humanInputModel",
        "label": "humanInputModel",
        "type": "asyncOptions",
        "optional": true,
        "description": "Model"
      },
      {
        "id": "{nodeId}-input-humanInputModelPrompt-string",
        "name": "humanInputModelPrompt",
        "label": "humanInputModelPrompt",
        "type": "string",
        "optional": true
      },
      {
        "id": "{nodeId}-input-humanInputEnableFeedback-boolean",
        "name": "humanInputEnableFeedback",
        "label": "humanInputEnableFeedback",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "Enable Feedback"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-humanInputAgentflow-HumanInput",
        "name": "humanInputAgentflow",
        "label": "Human Input",
        "type": "HumanInput"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Request human input, approval or rejection during execution",
    "baseClasses": [
      "HumanInput"
    ]
  },
  {
    "node_type": "iterationAgentflow",
    "name": "iterationAgentflow",
    "label": "Iteration",
    "category": "Agent Flows",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-iterationInput-string",
        "name": "iterationInput",
        "label": "iterationInput",
        "type": "string",
        "optional": true,
        "description": "The input array to iterate over"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-iterationAgentflow-Iteration",
        "name": "iterationAgentflow",
        "label": "Iteration",
        "type": "Iteration"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Execute the nodes within the iteration block through N iterations",
    "baseClasses": [
      "Iteration"
    ]
  },
  {
    "node_type": "llmAgentflow",
    "name": "llmAgentflow",
    "label": "LLM",
    "category": "Agent Flows",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-llmModel-asyncOptions",
        "name": "llmModel",
        "label": "llmModel",
        "type": "asyncOptions",
        "optional": true,
        "description": "Model"
      },
      {
        "id": "{nodeId}-input-llmMessages-array",
        "name": "llmMessages",
        "label": "llmMessages",
        "type": "array",
        "optional": true,
        "description": "Messages"
      },
      {
        "id": "{nodeId}-input-llmEnableMemory-boolean",
        "name": "llmEnableMemory",
        "label": "llmEnableMemory",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "Enable memory for the conversation thread"
      },
      {
        "id": "{nodeId}-input-llmMemoryType-options",
        "name": "llmMemoryType",
        "label": "llmMemoryType",
        "type": "options",
        "optional": true,
        "default": "allMessages",
        "description": "Memory Type"
      },
      {
        "id": "{nodeId}-input-llmMemoryWindowSize-number",
        "name": "llmMemoryWindowSize",
        "label": "llmMemoryWindowSize",
        "type": "number",
        "optional": true,
        "default": "20",
        "description": "Uses a fixed window size to surface the last N messages"
      },
      {
        "id": "{nodeId}-input-llmMemoryMaxTokenLimit-number",
        "name": "llmMemoryMaxTokenLimit",
        "label": "llmMemoryMaxTokenLimit",
        "type": "number",
        "optional": true,
        "default": "2000",
        "description": "Summarize conversations once token limit is reached. Default to 2000"
      },
      {
        "id": "{nodeId}-input-llmUserMessage-string",
        "name": "llmUserMessage",
        "label": "llmUserMessage",
        "type": "string",
        "optional": true,
        "description": "Add an input message as user message at the end of the conversation"
      },
      {
        "id": "{nodeId}-input-llmReturnResponseAs-options",
        "name": "llmReturnResponseAs",
        "label": "llmReturnResponseAs",
        "type": "options",
        "optional": true,
        "default": "userMessage",
        "description": "Return Response As"
      },
      {
        "id": "{nodeId}-input-llmStructuredOutput-array",
        "name": "llmStructuredOutput",
        "label": "llmStructuredOutput",
        "type": "array",
        "optional": true,
        "description": "Instruct the LLM to give output in a JSON structured schema"
      },
      {
        "id": "{nodeId}-input-llmUpdateState-array",
        "name": "llmUpdateState",
        "label": "llmUpdateState",
        "type": "array",
        "optional": true,
        "description": "Update runtime state during the execution of the workflow"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-llmAgentflow-LLM",
        "name": "llmAgentflow",
        "label": "LLM",
        "type": "LLM"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1.1",
    "description": "Large language models to analyze user-provided inputs and generate responses",
    "baseClasses": [
      "LLM"
    ]
  },
  {
    "node_type": "loopAgentflow",
    "name": "loopAgentflow",
    "label": "Loop",
    "category": "Agent Flows",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-loopBackToNode-asyncOptions",
        "name": "loopBackToNode",
        "label": "loopBackToNode",
        "type": "asyncOptions",
        "optional": true,
        "description": "Loop Back To"
      },
      {
        "id": "{nodeId}-input-maxLoopCount-number",
        "name": "maxLoopCount",
        "label": "maxLoopCount",
        "type": "number",
        "optional": true,
        "default": "5",
        "description": "Max Loop Count"
      },
      {
        "id": "{nodeId}-input-fallbackMessage-string",
        "name": "fallbackMessage",
        "label": "fallbackMessage",
        "type": "string",
        "optional": true,
        "description": "Message to display if the loop count is exceeded"
      },
      {
        "id": "{nodeId}-input-loopUpdateState-array",
        "name": "loopUpdateState",
        "label": "loopUpdateState",
        "type": "array",
        "optional": true,
        "description": "Update runtime state during the execution of the workflow"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-loopAgentflow-Loop",
        "name": "loopAgentflow",
        "label": "Loop",
        "type": "Loop"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1.2",
    "description": "Loop back to a previous node",
    "baseClasses": [
      "Loop"
    ]
  },
  {
    "node_type": "retrieverAgentflow",
    "name": "retrieverAgentflow",
    "label": "Retriever",
    "category": "Agent Flows",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-retrieverKnowledgeDocumentStores-array",
        "name": "retrieverKnowledgeDocumentStores",
        "label": "retrieverKnowledgeDocumentStores",
        "type": "array",
        "optional": true,
        "description": "Document stores to retrieve information from. Document stores must be upserted in advance."
      },
      {
        "id": "{nodeId}-input-retrieverQuery-string",
        "name": "retrieverQuery",
        "label": "retrieverQuery",
        "type": "string",
        "optional": true,
        "description": "Retriever Query"
      },
      {
        "id": "{nodeId}-input-outputFormat-options",
        "name": "outputFormat",
        "label": "outputFormat",
        "type": "options",
        "optional": true,
        "default": "text",
        "description": "Output Format"
      },
      {
        "id": "{nodeId}-input-retrieverUpdateState-array",
        "name": "retrieverUpdateState",
        "label": "retrieverUpdateState",
        "type": "array",
        "optional": true,
        "description": "Update runtime state during the execution of the workflow"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-retrieverAgentflow-Retriever",
        "name": "retrieverAgentflow",
        "label": "Retriever",
        "type": "Retriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1.1",
    "description": "Retrieve information from vector database",
    "baseClasses": [
      "Retriever"
    ]
  },
  {
    "node_type": "startAgentflow",
    "name": "startAgentflow",
    "label": "Start",
    "category": "Agent Flows",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-startInputType-options",
        "name": "startInputType",
        "label": "startInputType",
        "type": "options",
        "optional": true,
        "default": "chatInput",
        "description": "Input Type"
      },
      {
        "id": "{nodeId}-input-formTitle-string",
        "name": "formTitle",
        "label": "formTitle",
        "type": "string",
        "optional": true,
        "description": "Form Title"
      },
      {
        "id": "{nodeId}-input-formDescription-string",
        "name": "formDescription",
        "label": "formDescription",
        "type": "string",
        "optional": true,
        "description": "Form Description"
      },
      {
        "id": "{nodeId}-input-formInputTypes-array",
        "name": "formInputTypes",
        "label": "formInputTypes",
        "type": "array",
        "optional": true,
        "description": "Specify the type of form input"
      },
      {
        "id": "{nodeId}-input-startEphemeralMemory-boolean",
        "name": "startEphemeralMemory",
        "label": "startEphemeralMemory",
        "type": "boolean",
        "optional": true,
        "description": "Start fresh for every execution without past chat history"
      },
      {
        "id": "{nodeId}-input-startState-array",
        "name": "startState",
        "label": "startState",
        "type": "array",
        "optional": true,
        "description": "Runtime state during the execution of the workflow"
      },
      {
        "id": "{nodeId}-input-startPersistState-boolean",
        "name": "startPersistState",
        "label": "startPersistState",
        "type": "boolean",
        "optional": true,
        "description": "Persist the state in the same session"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-startAgentflow-Start",
        "name": "startAgentflow",
        "label": "Start",
        "type": "Start"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1.1",
    "description": "Starting point of the agentflow",
    "baseClasses": [
      "Start"
    ]
  },
  {
    "node_type": "stickyNoteAgentflow",
    "name": "stickyNoteAgentflow",
    "label": "Sticky Note",
    "category": "Agent Flows",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-note-string",
        "name": "note",
        "label": "note",
        "type": "string",
        "optional": true
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-stickyNoteAgentflow-StickyNote",
        "name": "stickyNoteAgentflow",
        "label": "Sticky Note",
        "type": "StickyNote"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Add notes to the agent flow",
    "baseClasses": [
      "StickyNote"
    ]
  },
  {
    "node_type": "toolAgentflow",
    "name": "toolAgentflow",
    "label": "Tool",
    "category": "Agent Flows",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-toolAgentflowSelectedTool-asyncOptions",
        "name": "toolAgentflowSelectedTool",
        "label": "toolAgentflowSelectedTool",
        "type": "asyncOptions",
        "optional": true,
        "description": "Tool"
      },
      {
        "id": "{nodeId}-input-toolInputArgs-array",
        "name": "toolInputArgs",
        "label": "toolInputArgs",
        "type": "array",
        "optional": true,
        "description": "Tool Input Arguments"
      },
      {
        "id": "{nodeId}-input-toolUpdateState-array",
        "name": "toolUpdateState",
        "label": "toolUpdateState",
        "type": "array",
        "optional": true,
        "description": "Update runtime state during the execution of the workflow"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-toolAgentflow-Tool",
        "name": "toolAgentflow",
        "label": "Tool",
        "type": "Tool"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1.2",
    "description": "Tools allow LLM to interact with external systems",
    "baseClasses": [
      "Tool"
    ]
  },
  {
    "node_type": "airtableAgent",
    "name": "airtableAgent",
    "label": "Airtable Agent",
    "category": "Agents",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-model-BaseLanguageModel",
        "name": "model",
        "label": "model",
        "type": "BaseLanguageModel",
        "optional": true,
        "description": "Language Model"
      },
      {
        "id": "{nodeId}-input-inputModeration-Moderation",
        "name": "inputModeration",
        "label": "inputModeration",
        "type": "Moderation",
        "optional": true,
        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-baseId-string",
        "name": "baseId",
        "label": "baseId",
        "type": "string",
        "optional": true,
        "description": "If your table URL looks like: https://airtable.com/app11RobdGoX0YNsC/tblJdmvbrgizbYICO/viw9UrP77Id0C"
      },
      {
        "id": "{nodeId}-input-tableId-string",
        "name": "tableId",
        "label": "tableId",
        "type": "string",
        "optional": true,
        "description": "If your table URL looks like: https://airtable.com/app11RobdGoX0YNsC/tblJdmvbrgizbYICO/viw9UrP77Id0C"
      },
      {
        "id": "{nodeId}-input-returnAll-boolean",
        "name": "returnAll",
        "label": "returnAll",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "If all results should be returned or only up to a given limit"
      },
      {
        "id": "{nodeId}-input-limit-number",
        "name": "limit",
        "label": "limit",
        "type": "number",
        "optional": true,
        "default": "100",
        "description": "Number of results to return"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-airtableAgent-AgentExecutor|BaseChain|Runnable",
        "name": "airtableAgent",
        "label": "Airtable Agent",
        "type": "AgentExecutor | BaseChain | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Agent used to answer queries on Airtable table",
    "baseClasses": [
      "AgentExecutor",
      "BaseChain",
      "Runnable"
    ],
    "credential_required": [
      "airtableApi"
    ]
  },
  {
    "node_type": "anthropicAgentLlamaIndex",
    "name": "anthropicAgentLlamaIndex",
    "label": "Anthropic Agent",
    "category": "Agents",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-tools-Tool_LlamaIndex",
        "name": "tools",
        "label": "tools",
        "type": "Tool_LlamaIndex",
        "optional": true,
        "description": "Tools"
      },
      {
        "id": "{nodeId}-input-memory-BaseChatMemory",
        "name": "memory",
        "label": "memory",
        "type": "BaseChatMemory",
        "optional": true,
        "description": "Memory"
      },
      {
        "id": "{nodeId}-input-model-BaseChatModel_LlamaIndex",
        "name": "model",
        "label": "model",
        "type": "BaseChatModel_LlamaIndex",
        "optional": true,
        "description": "Anthropic Claude Model"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-systemMessage-string",
        "name": "systemMessage",
        "label": "systemMessage",
        "type": "string",
        "optional": true,
        "description": "System Message"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-anthropicAgentLlamaIndex-AnthropicAgent|AgentRunner",
        "name": "anthropicAgentLlamaIndex",
        "label": "Anthropic Agent",
        "type": "AnthropicAgent | AgentRunner"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Agent that uses Anthropic Claude Function Calling to pick the tools and args to call using LlamaIndex",
    "baseClasses": [
      "AnthropicAgent",
      "AgentRunner"
    ]
  },
  {
    "node_type": "autoGPT",
    "name": "autoGPT",
    "label": "AutoGPT",
    "category": "Agents",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-tools-Tool",
        "name": "tools",
        "label": "tools",
        "type": "Tool",
        "optional": true,
        "description": "Allowed Tools"
      },
      {
        "id": "{nodeId}-input-model-BaseChatModel",
        "name": "model",
        "label": "model",
        "type": "BaseChatModel",
        "optional": true,
        "description": "Chat Model"
      },
      {
        "id": "{nodeId}-input-vectorStoreRetriever-BaseRetriever",
        "name": "vectorStoreRetriever",
        "label": "vectorStoreRetriever",
        "type": "BaseRetriever",
        "optional": true,
        "description": "Vector Store Retriever"
      },
      {
        "id": "{nodeId}-input-inputModeration-Moderation",
        "name": "inputModeration",
        "label": "inputModeration",
        "type": "Moderation",
        "optional": true,
        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-aiName-string",
        "name": "aiName",
        "label": "aiName",
        "type": "string",
        "optional": true,
        "description": "AutoGPT Name"
      },
      {
        "id": "{nodeId}-input-aiRole-string",
        "name": "aiRole",
        "label": "aiRole",
        "type": "string",
        "optional": true,
        "description": "AutoGPT Role"
      },
      {
        "id": "{nodeId}-input-maxLoop-number",
        "name": "maxLoop",
        "label": "maxLoop",
        "type": "number",
        "optional": true,
        "default": "5",
        "description": "Maximum Loop"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-autoGPT-AutoGPT",
        "name": "autoGPT",
        "label": "AutoGPT",
        "type": "AutoGPT"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Autonomous agent with chain of thoughts for self-guided task completion",
    "baseClasses": [
      "AutoGPT"
    ]
  },
  {
    "node_type": "babyAGI",
    "name": "babyAGI",
    "label": "BabyAGI",
    "category": "Agents",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-model-BaseChatModel",
        "name": "model",
        "label": "model",
        "type": "BaseChatModel",
        "optional": true,
        "description": "Chat Model"
      },
      {
        "id": "{nodeId}-input-vectorStore-VectorStore",
        "name": "vectorStore",
        "label": "vectorStore",
        "type": "VectorStore",
        "optional": true,
        "description": "Vector Store"
      },
      {
        "id": "{nodeId}-input-inputModeration-Moderation",
        "name": "inputModeration",
        "label": "inputModeration",
        "type": "Moderation",
        "optional": true,
        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-taskLoop-number",
        "name": "taskLoop",
        "label": "taskLoop",
        "type": "number",
        "optional": true,
        "default": "3",
        "description": "Task Loop"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-babyAGI-BabyAGI",
        "name": "babyAGI",
        "label": "BabyAGI",
        "type": "BabyAGI"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Task Driven Autonomous Agent which creates new task and reprioritizes task list based on objective",
    "baseClasses": [
      "BabyAGI"
    ]
  },
  {
    "node_type": "conversationalAgent",
    "name": "conversationalAgent",
    "label": "Conversational Agent",
    "category": "Agents",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-tools-Tool",
        "name": "tools",
        "label": "tools",
        "type": "Tool",
        "optional": true,
        "description": "Allowed Tools"
      },
      {
        "id": "{nodeId}-input-model-BaseChatModel",
        "name": "model",
        "label": "model",
        "type": "BaseChatModel",
        "optional": true,
        "description": "Chat Model"
      },
      {
        "id": "{nodeId}-input-memory-BaseChatMemory",
        "name": "memory",
        "label": "memory",
        "type": "BaseChatMemory",
        "optional": true,
        "description": "Memory"
      },
      {
        "id": "{nodeId}-input-inputModeration-Moderation",
        "name": "inputModeration",
        "label": "inputModeration",
        "type": "Moderation",
        "optional": true,
        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-systemMessage-string",
        "name": "systemMessage",
        "label": "systemMessage",
        "type": "string",
        "optional": true
      },
      {
        "id": "{nodeId}-input-maxIterations-number",
        "name": "maxIterations",
        "label": "maxIterations",
        "type": "number",
        "optional": true,
        "description": "Max Iterations"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-conversationalAgent-AgentExecutor|BaseChain|Runnable",
        "name": "conversationalAgent",
        "label": "Conversational Agent",
        "type": "AgentExecutor | BaseChain | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "3",
    "description": "Conversational agent for a chat model. It will utilize chat specific prompts",
    "baseClasses": [
      "AgentExecutor",
      "BaseChain",
      "Runnable"
    ]
  },
  {
    "node_type": "csvAgent",
    "name": "csvAgent",
    "label": "CSV Agent",
    "category": "Agents",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-model-BaseLanguageModel",
        "name": "model",
        "label": "model",
        "type": "BaseLanguageModel",
        "optional": true,
        "description": "Language Model"
      },
      {
        "id": "{nodeId}-input-inputModeration-Moderation",
        "name": "inputModeration",
        "label": "inputModeration",
        "type": "Moderation",
        "optional": true,
        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-csvFile-file",
        "name": "csvFile",
        "label": "csvFile",
        "type": "file",
        "optional": true,
        "description": "Csv File"
      },
      {
        "id": "{nodeId}-input-systemMessagePrompt-string",
        "name": "systemMessagePrompt",
        "label": "systemMessagePrompt",
        "type": "string",
        "optional": true,
        "description": "System Message"
      },
      {
        "id": "{nodeId}-input-customReadCSV-code",
        "name": "customReadCSV",
        "label": "customReadCSV",
        "type": "code",
        "optional": true,
        "default": "read_csv(csv_data)",
        "description": "Custom Pandas <a target=\"_blank\" href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pa"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-csvAgent-AgentExecutor|BaseChain|Runnable",
        "name": "csvAgent",
        "label": "CSV Agent",
        "type": "AgentExecutor | BaseChain | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "3",
    "description": "Agent used to answer queries on CSV data",
    "baseClasses": [
      "AgentExecutor",
      "BaseChain",
      "Runnable"
    ]
  },
  {
    "node_type": "openAIAssistant",
    "name": "openAIAssistant",
    "label": "OpenAI Assistant",
    "category": "Agents",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-tools-Tool",
        "name": "tools",
        "label": "tools",
        "type": "Tool",
        "optional": true,
        "description": "Allowed Tools"
      },
      {
        "id": "{nodeId}-input-inputModeration-Moderation",
        "name": "inputModeration",
        "label": "inputModeration",
        "type": "Moderation",
        "optional": true,
        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-selectedAssistant-asyncOptions",
        "name": "selectedAssistant",
        "label": "selectedAssistant",
        "type": "asyncOptions",
        "optional": true,
        "description": "Select Assistant"
      },
      {
        "id": "{nodeId}-input-toolChoice-string",
        "name": "toolChoice",
        "label": "toolChoice",
        "type": "string",
        "optional": true,
        "description": "Controls which (if any) tool is called by the model. Can be \"none\", \"auto\", \"required\", or the name"
      },
      {
        "id": "{nodeId}-input-parallelToolCalls-boolean",
        "name": "parallelToolCalls",
        "label": "parallelToolCalls",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "Whether to enable parallel function calling during tool use. Defaults to true"
      },
      {
        "id": "{nodeId}-input-disableFileDownload-boolean",
        "name": "disableFileDownload",
        "label": "disableFileDownload",
        "type": "boolean",
        "optional": true,
        "description": "Messages can contain text, images, or files. In some cases, you may want to prevent others from down"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-openAIAssistant-OpenAIAssistant",
        "name": "openAIAssistant",
        "label": "OpenAI Assistant",
        "type": "OpenAIAssistant"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "4",
    "description": "An agent that uses OpenAI Assistant API to pick the tool and args to call",
    "baseClasses": [
      "OpenAIAssistant"
    ]
  },
  {
    "node_type": "openAIToolAgentLlamaIndex",
    "name": "openAIToolAgentLlamaIndex",
    "label": "OpenAI Tool Agent",
    "category": "Agents",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-tools-Tool_LlamaIndex",
        "name": "tools",
        "label": "tools",
        "type": "Tool_LlamaIndex",
        "optional": true,
        "description": "Tools"
      },
      {
        "id": "{nodeId}-input-memory-BaseChatMemory",
        "name": "memory",
        "label": "memory",
        "type": "BaseChatMemory",
        "optional": true,
        "description": "Memory"
      },
      {
        "id": "{nodeId}-input-model-BaseChatModel_LlamaIndex",
        "name": "model",
        "label": "model",
        "type": "BaseChatModel_LlamaIndex",
        "optional": true,
        "description": "OpenAI/Azure Chat Model"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-systemMessage-string",
        "name": "systemMessage",
        "label": "systemMessage",
        "type": "string",
        "optional": true,
        "description": "System Message"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-openAIToolAgentLlamaIndex-OpenAIToolAgent|AgentRunner",
        "name": "openAIToolAgentLlamaIndex",
        "label": "OpenAI Tool Agent",
        "type": "OpenAIToolAgent | AgentRunner"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Agent that uses OpenAI Function Calling to pick the tools and args to call using LlamaIndex",
    "baseClasses": [
      "OpenAIToolAgent",
      "AgentRunner"
    ]
  },
  {
    "node_type": "reactAgentChat",
    "name": "reactAgentChat",
    "label": "ReAct Agent for Chat Models",
    "category": "Agents",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-tools-Tool",
        "name": "tools",
        "label": "tools",
        "type": "Tool",
        "optional": true,
        "description": "Allowed Tools"
      },
      {
        "id": "{nodeId}-input-model-BaseChatModel",
        "name": "model",
        "label": "model",
        "type": "BaseChatModel",
        "optional": true,
        "description": "Chat Model"
      },
      {
        "id": "{nodeId}-input-memory-BaseChatMemory",
        "name": "memory",
        "label": "memory",
        "type": "BaseChatMemory",
        "optional": true,
        "description": "Memory"
      },
      {
        "id": "{nodeId}-input-inputModeration-Moderation",
        "name": "inputModeration",
        "label": "inputModeration",
        "type": "Moderation",
        "optional": true,
        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-maxIterations-number",
        "name": "maxIterations",
        "label": "maxIterations",
        "type": "number",
        "optional": true,
        "description": "Max Iterations"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-reactAgentChat-AgentExecutor|BaseChain|Runnable",
        "name": "reactAgentChat",
        "label": "ReAct Agent for Chat Models",
        "type": "AgentExecutor | BaseChain | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "4",
    "description": "Agent that uses the ReAct logic to decide what action to take, optimized to be used with Chat Models",
    "baseClasses": [
      "AgentExecutor",
      "BaseChain",
      "Runnable"
    ]
  },
  {
    "node_type": "reactAgentLLM",
    "name": "reactAgentLLM",
    "label": "ReAct Agent for LLMs",
    "category": "Agents",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-tools-Tool",
        "name": "tools",
        "label": "tools",
        "type": "Tool",
        "optional": true,
        "description": "Allowed Tools"
      },
      {
        "id": "{nodeId}-input-model-BaseLanguageModel",
        "name": "model",
        "label": "model",
        "type": "BaseLanguageModel",
        "optional": true,
        "description": "Language Model"
      },
      {
        "id": "{nodeId}-input-inputModeration-Moderation",
        "name": "inputModeration",
        "label": "inputModeration",
        "type": "Moderation",
        "optional": true,
        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-maxIterations-number",
        "name": "maxIterations",
        "label": "maxIterations",
        "type": "number",
        "optional": true,
        "description": "Max Iterations"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-reactAgentLLM-AgentExecutor|BaseChain|Runnable",
        "name": "reactAgentLLM",
        "label": "ReAct Agent for LLMs",
        "type": "AgentExecutor | BaseChain | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Agent that uses the ReAct logic to decide what action to take, optimized to be used with LLMs",
    "baseClasses": [
      "AgentExecutor",
      "BaseChain",
      "Runnable"
    ]
  },
  {
    "node_type": "toolAgent",
    "name": "toolAgent",
    "label": "Tool Agent",
    "category": "Agents",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-tools-Tool",
        "name": "tools",
        "label": "tools",
        "type": "Tool",
        "optional": true,
        "description": "Tools"
      },
      {
        "id": "{nodeId}-input-memory-BaseChatMemory",
        "name": "memory",
        "label": "memory",
        "type": "BaseChatMemory",
        "optional": true,
        "description": "Memory"
      },
      {
        "id": "{nodeId}-input-model-BaseChatModel",
        "name": "model",
        "label": "model",
        "type": "BaseChatModel",
        "optional": true,
        "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthr"
      },
      {
        "id": "{nodeId}-input-chatPromptTemplate-ChatPromptTemplate",
        "name": "chatPromptTemplate",
        "label": "chatPromptTemplate",
        "type": "ChatPromptTemplate",
        "optional": true,
        "description": "Override existing prompt with Chat Prompt Template. Human Message must includes {input} variable"
      },
      {
        "id": "{nodeId}-input-inputModeration-Moderation",
        "name": "inputModeration",
        "label": "inputModeration",
        "type": "Moderation",
        "optional": true,
        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-systemMessage-string",
        "name": "systemMessage",
        "label": "systemMessage",
        "type": "string",
        "optional": true,
        "default": "You are a helpful AI assistant.",
        "description": "If Chat Prompt Template is provided, this will be ignored"
      },
      {
        "id": "{nodeId}-input-maxIterations-number",
        "name": "maxIterations",
        "label": "maxIterations",
        "type": "number",
        "optional": true,
        "description": "Max Iterations"
      },
      {
        "id": "{nodeId}-input-enableDetailedStreaming-boolean",
        "name": "enableDetailedStreaming",
        "label": "enableDetailedStreaming",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Stream detailed intermediate steps during agent execution"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-toolAgent-AgentExecutor|BaseChain|Runnable",
        "name": "toolAgent",
        "label": "Tool Agent",
        "type": "AgentExecutor | BaseChain | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Agent that uses Function Calling to pick the tools and args to call",
    "baseClasses": [
      "AgentExecutor",
      "BaseChain",
      "Runnable"
    ]
  },
  {
    "node_type": "xmlAgent",
    "name": "xmlAgent",
    "label": "XML Agent",
    "category": "Agents",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-tools-Tool",
        "name": "tools",
        "label": "tools",
        "type": "Tool",
        "optional": true,
        "description": "Tools"
      },
      {
        "id": "{nodeId}-input-memory-BaseChatMemory",
        "name": "memory",
        "label": "memory",
        "type": "BaseChatMemory",
        "optional": true,
        "description": "Memory"
      },
      {
        "id": "{nodeId}-input-model-BaseChatModel",
        "name": "model",
        "label": "model",
        "type": "BaseChatModel",
        "optional": true,
        "description": "Chat Model"
      },
      {
        "id": "{nodeId}-input-inputModeration-Moderation",
        "name": "inputModeration",
        "label": "inputModeration",
        "type": "Moderation",
        "optional": true,
        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-systemMessage-string",
        "name": "systemMessage",
        "label": "systemMessage",
        "type": "string",
        "optional": true
      },
      {
        "id": "{nodeId}-input-maxIterations-number",
        "name": "maxIterations",
        "label": "maxIterations",
        "type": "number",
        "optional": true,
        "description": "Max Iterations"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-xmlAgent-XMLAgent|BaseChain|Runnable",
        "name": "xmlAgent",
        "label": "XML Agent",
        "type": "XMLAgent | BaseChain | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Agent that is designed for LLMs that are good for reasoning/writing XML (e.g: Anthropic Claude)",
    "baseClasses": [
      "XMLAgent",
      "BaseChain",
      "Runnable"
    ]
  },
  {
    "node_type": "googleGenerativeAIContextCache",
    "name": "googleGenerativeAIContextCache",
    "label": "Google GenAI Context Cache",
    "category": "Cache",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-ttl-number",
        "name": "ttl",
        "label": "ttl",
        "type": "number",
        "optional": true,
        "default": "2592000",
        "description": "TTL"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-googleGenerativeAIContextCache-GoogleAICacheManager|GoogleAICacheManager",
        "name": "googleGenerativeAIContextCache",
        "label": "Google GenAI Context Cache",
        "type": "GoogleAICacheManager | GoogleAICacheManager"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Large context cache for Google Gemini large language models",
    "baseClasses": [
      "GoogleAICacheManager",
      "GoogleAICacheManager"
    ],
    "credential_required": [
      "googleGenerativeAI"
    ]
  },
  {
    "node_type": "inMemoryCache",
    "name": "inMemoryCache",
    "label": "InMemory Cache",
    "category": "Cache",
    "inputAnchors": [],
    "inputParams": [],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-inMemoryCache-InMemoryCache|BaseCache",
        "name": "inMemoryCache",
        "label": "InMemory Cache",
        "type": "InMemoryCache | BaseCache"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Cache LLM response in memory, will be cleared once app restarted",
    "baseClasses": [
      "InMemoryCache",
      "BaseCache"
    ]
  },
  {
    "node_type": "inMemoryEmbeddingCache",
    "name": "inMemoryEmbeddingCache",
    "label": "InMemory Embedding Cache",
    "category": "Cache",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-embeddings-Embeddings",
        "name": "embeddings",
        "label": "embeddings",
        "type": "Embeddings",
        "optional": true,
        "description": "Embeddings"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-namespace-string",
        "name": "namespace",
        "label": "namespace",
        "type": "string",
        "optional": true,
        "description": "Namespace"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-inMemoryEmbeddingCache-InMemoryEmbeddingCache|Embeddings",
        "name": "inMemoryEmbeddingCache",
        "label": "InMemory Embedding Cache",
        "type": "InMemoryEmbeddingCache | Embeddings"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Cache generated Embeddings in memory to avoid needing to recompute them.",
    "baseClasses": [
      "InMemoryEmbeddingCache",
      "Embeddings"
    ]
  },
  {
    "node_type": "momentoCache",
    "name": "momentoCache",
    "label": "Momento Cache",
    "category": "Cache",
    "inputAnchors": [],
    "inputParams": [],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-momentoCache-MomentoCache|BaseCache",
        "name": "momentoCache",
        "label": "Momento Cache",
        "type": "MomentoCache | BaseCache"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Cache LLM response using Momento, a distributed, serverless cache",
    "baseClasses": [
      "MomentoCache",
      "BaseCache"
    ],
    "credential_required": [
      "momentoCacheApi"
    ]
  },
  {
    "node_type": "redisCache",
    "name": "redisCache",
    "label": "Redis Cache",
    "category": "Cache",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-ttl-number",
        "name": "ttl",
        "label": "ttl",
        "type": "number",
        "optional": true,
        "description": "Time to Live (ms)"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-redisCache-RedisCache|BaseCache",
        "name": "redisCache",
        "label": "Redis Cache",
        "type": "RedisCache | BaseCache"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Cache LLM response in Redis, useful for sharing cache across multiple processes or servers",
    "baseClasses": [
      "RedisCache",
      "BaseCache"
    ],
    "credential_required": [
      "redisCacheApi",
      "redisCacheUrlApi"
    ]
  },
  {
    "node_type": "redisEmbeddingsCache",
    "name": "redisEmbeddingsCache",
    "label": "Redis Embeddings Cache",
    "category": "Cache",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-embeddings-Embeddings",
        "name": "embeddings",
        "label": "embeddings",
        "type": "Embeddings",
        "optional": true,
        "description": "Embeddings"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-ttl-number",
        "name": "ttl",
        "label": "ttl",
        "type": "number",
        "optional": true,
        "default": "3600",
        "description": "Time to Live (ms)"
      },
      {
        "id": "{nodeId}-input-namespace-string",
        "name": "namespace",
        "label": "namespace",
        "type": "string",
        "optional": true,
        "description": "Namespace"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-redisEmbeddingsCache-RedisEmbeddingsCache|Embeddings",
        "name": "redisEmbeddingsCache",
        "label": "Redis Embeddings Cache",
        "type": "RedisEmbeddingsCache | Embeddings"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Cache generated Embeddings in Redis to avoid needing to recompute them.",
    "baseClasses": [
      "RedisEmbeddingsCache",
      "Embeddings"
    ],
    "credential_required": [
      "redisCacheApi",
      "redisCacheUrlApi"
    ]
  },
  {
    "node_type": "upstashRedisCache",
    "name": "upstashRedisCache",
    "label": "Upstash Redis Cache",
    "category": "Cache",
    "inputAnchors": [],
    "inputParams": [],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-upstashRedisCache-UpstashRedisCache|BaseCache",
        "name": "upstashRedisCache",
        "label": "Upstash Redis Cache",
        "type": "UpstashRedisCache | BaseCache"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Cache LLM response in Upstash Redis, serverless data for Redis and Kafka",
    "baseClasses": [
      "UpstashRedisCache",
      "BaseCache"
    ],
    "credential_required": [
      "upstashRedisApi"
    ]
  },
  {
    "node_type": "conversationChain",
    "name": "conversationChain",
    "label": "Conversation Chain",
    "category": "Chains",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-model-BaseChatModel",
        "name": "model",
        "label": "model",
        "type": "BaseChatModel",
        "optional": true,
        "description": "Chat Model"
      },
      {
        "id": "{nodeId}-input-memory-BaseMemory",
        "name": "memory",
        "label": "memory",
        "type": "BaseMemory",
        "optional": true,
        "description": "Memory"
      },
      {
        "id": "{nodeId}-input-chatPromptTemplate-ChatPromptTemplate",
        "name": "chatPromptTemplate",
        "label": "chatPromptTemplate",
        "type": "ChatPromptTemplate",
        "optional": true,
        "description": "Override existing prompt with Chat Prompt Template. Human Message must includes {input} variable"
      },
      {
        "id": "{nodeId}-input-inputModeration-Moderation",
        "name": "inputModeration",
        "label": "inputModeration",
        "type": "Moderation",
        "optional": true,
        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-systemMessagePrompt-string",
        "name": "systemMessagePrompt",
        "label": "systemMessagePrompt",
        "type": "string",
        "optional": true,
        "default": "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.",
        "description": "If Chat Prompt Template is provided, this will be ignored"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-conversationChain-ConversationChain|LLMChain|BaseChain|Runnable",
        "name": "conversationChain",
        "label": "Conversation Chain",
        "type": "ConversationChain | LLMChain | BaseChain | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "3",
    "description": "Chat models specific conversational chain with memory",
    "baseClasses": [
      "ConversationChain",
      "LLMChain",
      "BaseChain",
      "Runnable"
    ]
  },
  {
    "node_type": "conversationalRetrievalQAChain",
    "name": "conversationalRetrievalQAChain",
    "label": "Conversational Retrieval QA Chain",
    "category": "Chains",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-model-BaseChatModel",
        "name": "model",
        "label": "model",
        "type": "BaseChatModel",
        "optional": true,
        "description": "Chat Model"
      },
      {
        "id": "{nodeId}-input-vectorStoreRetriever-BaseRetriever",
        "name": "vectorStoreRetriever",
        "label": "vectorStoreRetriever",
        "type": "BaseRetriever",
        "optional": true,
        "description": "Vector Store Retriever"
      },
      {
        "id": "{nodeId}-input-memory-BaseMemory",
        "name": "memory",
        "label": "memory",
        "type": "BaseMemory",
        "optional": true,
        "description": "If left empty, a default BufferMemory will be used"
      },
      {
        "id": "{nodeId}-input-inputModeration-Moderation",
        "name": "inputModeration",
        "label": "inputModeration",
        "type": "Moderation",
        "optional": true,
        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-returnSourceDocuments-boolean",
        "name": "returnSourceDocuments",
        "label": "returnSourceDocuments",
        "type": "boolean",
        "optional": true,
        "description": "Return Source Documents"
      },
      {
        "id": "{nodeId}-input-rephrasePrompt-string",
        "name": "rephrasePrompt",
        "label": "rephrasePrompt",
        "type": "string",
        "optional": true
      },
      {
        "id": "{nodeId}-input-responsePrompt-string",
        "name": "responsePrompt",
        "label": "responsePrompt",
        "type": "string",
        "optional": true,
        "description": "If there is nothing in the context relevant to the question at hand, just say \"Hmm, I'm not sure\" and stop after that. Refuse to answer any question not about the info. Never break character."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-conversationalRetrievalQAChain-ConversationalRetrievalQAChain|BaseChain|Runnable",
        "name": "conversationalRetrievalQAChain",
        "label": "Conversational Retrieval QA Chain",
        "type": "ConversationalRetrievalQAChain | BaseChain | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "3",
    "description": "Document QA - built on RetrievalQAChain to provide a chat history component",
    "baseClasses": [
      "ConversationalRetrievalQAChain",
      "BaseChain",
      "Runnable"
    ]
  },
  {
    "node_type": "getApiChain",
    "name": "getApiChain",
    "label": "GET API Chain",
    "category": "Chains",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-model-BaseLanguageModel",
        "name": "model",
        "label": "model",
        "type": "BaseLanguageModel",
        "optional": true,
        "description": "Language Model"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-apiDocs-string",
        "name": "apiDocs",
        "label": "apiDocs",
        "type": "string",
        "optional": true,
        "description": "Description of how API works. Please refer to more <a target=\"_blank\" href=\"https://github.com/langc"
      },
      {
        "id": "{nodeId}-input-headers-json",
        "name": "headers",
        "label": "headers",
        "type": "json",
        "optional": true,
        "description": "Headers"
      },
      {
        "id": "{nodeId}-input-urlPrompt-string",
        "name": "urlPrompt",
        "label": "urlPrompt",
        "type": "string",
        "optional": true,
        "description": "{api_docs} Using this documentation, generate the full API url to call for answering the user question. You should build the API url in order to get a response that is as short as possible, while stil"
      },
      {
        "id": "{nodeId}-input-ansPrompt-string",
        "name": "ansPrompt",
        "label": "ansPrompt",
        "type": "string",
        "optional": true,
        "default": "Given this {api_response} response for {api_url}. use the given response to answer this {question}",
        "description": "Prompt used to tell LLMs how to return the API response. Must contains {api_response}, {api_url}, an"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-getApiChain-GETApiChain|BaseChain|Runnable",
        "name": "getApiChain",
        "label": "GET API Chain",
        "type": "GETApiChain | BaseChain | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Chain to run queries against GET API",
    "baseClasses": [
      "GETApiChain",
      "BaseChain",
      "Runnable"
    ]
  },
  {
    "node_type": "graphCypherQAChain",
    "name": "graphCypherQAChain",
    "label": "Graph Cypher QA Chain",
    "category": "Chains",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-model-BaseLanguageModel",
        "name": "model",
        "label": "model",
        "type": "BaseLanguageModel",
        "optional": true,
        "description": "Model for generating Cypher queries and answers."
      },
      {
        "id": "{nodeId}-input-graph-Neo4j",
        "name": "graph",
        "label": "graph",
        "type": "Neo4j",
        "optional": true,
        "description": "Neo4j Graph"
      },
      {
        "id": "{nodeId}-input-cypherPrompt-BasePromptTemplate",
        "name": "cypherPrompt",
        "label": "cypherPrompt",
        "type": "BasePromptTemplate",
        "optional": true,
        "description": "Prompt template for generating Cypher queries. Must include {schema} and {question} variables. If no"
      },
      {
        "id": "{nodeId}-input-cypherModel-BaseLanguageModel",
        "name": "cypherModel",
        "label": "cypherModel",
        "type": "BaseLanguageModel",
        "optional": true,
        "description": "Model for generating Cypher queries. If not provided, the main model will be used."
      },
      {
        "id": "{nodeId}-input-qaPrompt-BasePromptTemplate",
        "name": "qaPrompt",
        "label": "qaPrompt",
        "type": "BasePromptTemplate",
        "optional": true,
        "description": "Prompt template for generating answers. Must include {context} and {question} variables. If not prov"
      },
      {
        "id": "{nodeId}-input-qaModel-BaseLanguageModel",
        "name": "qaModel",
        "label": "qaModel",
        "type": "BaseLanguageModel",
        "optional": true,
        "description": "Model for generating answers. If not provided, the main model will be used."
      },
      {
        "id": "{nodeId}-input-inputModeration-Moderation",
        "name": "inputModeration",
        "label": "inputModeration",
        "type": "Moderation",
        "optional": true,
        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-returnDirect-boolean",
        "name": "returnDirect",
        "label": "returnDirect",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "If true, return the raw query results instead of using the QA chain"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-graphCypherQAChain-GraphCypherQAChain|BaseChain|Runnable",
        "name": "graphCypherQAChain",
        "label": "Graph Cypher QA Chain",
        "type": "GraphCypherQAChain | BaseChain | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1.1",
    "description": "Advanced chain for question-answering against a Neo4j graph by generating Cypher statements",
    "baseClasses": [
      "GraphCypherQAChain",
      "BaseChain",
      "Runnable"
    ]
  },
  {
    "node_type": "llmChain",
    "name": "llmChain",
    "label": "LLM Chain",
    "category": "Chains",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-model-BaseLanguageModel",
        "name": "model",
        "label": "model",
        "type": "BaseLanguageModel",
        "optional": true,
        "description": "Language Model"
      },
      {
        "id": "{nodeId}-input-prompt-BasePromptTemplate",
        "name": "prompt",
        "label": "prompt",
        "type": "BasePromptTemplate",
        "optional": true,
        "description": "Prompt"
      },
      {
        "id": "{nodeId}-input-outputParser-BaseLLMOutputParser",
        "name": "outputParser",
        "label": "outputParser",
        "type": "BaseLLMOutputParser",
        "optional": true,
        "description": "Output Parser"
      },
      {
        "id": "{nodeId}-input-inputModeration-Moderation",
        "name": "inputModeration",
        "label": "inputModeration",
        "type": "Moderation",
        "optional": true,
        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-chainName-string",
        "name": "chainName",
        "label": "chainName",
        "type": "string",
        "optional": true,
        "description": "Chain Name"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-llmChain-LLMChain|BaseChain|Runnable",
        "name": "llmChain",
        "label": "LLM Chain",
        "type": "LLMChain | BaseChain | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "3",
    "description": "Chain to run queries against LLMs",
    "baseClasses": [
      "LLMChain",
      "BaseChain",
      "Runnable"
    ]
  },
  {
    "node_type": "multiPromptChain",
    "name": "multiPromptChain",
    "label": "Multi Prompt Chain",
    "category": "Chains",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-model-BaseLanguageModel",
        "name": "model",
        "label": "model",
        "type": "BaseLanguageModel",
        "optional": true,
        "description": "Language Model"
      },
      {
        "id": "{nodeId}-input-promptRetriever-PromptRetriever",
        "name": "promptRetriever",
        "label": "promptRetriever",
        "type": "PromptRetriever",
        "optional": true,
        "description": "Prompt Retriever"
      },
      {
        "id": "{nodeId}-input-inputModeration-Moderation",
        "name": "inputModeration",
        "label": "inputModeration",
        "type": "Moderation",
        "optional": true,
        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model"
      }
    ],
    "inputParams": [],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-multiPromptChain-MultiPromptChain|MultiRouteChain|BaseChain|Runnable",
        "name": "multiPromptChain",
        "label": "Multi Prompt Chain",
        "type": "MultiPromptChain | MultiRouteChain | BaseChain | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Chain automatically picks an appropriate prompt from multiple prompt templates",
    "baseClasses": [
      "MultiPromptChain",
      "MultiRouteChain",
      "BaseChain",
      "Runnable"
    ]
  },
  {
    "node_type": "multiRetrievalQAChain",
    "name": "multiRetrievalQAChain",
    "label": "Multi Retrieval QA Chain",
    "category": "Chains",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-model-BaseLanguageModel",
        "name": "model",
        "label": "model",
        "type": "BaseLanguageModel",
        "optional": true,
        "description": "Language Model"
      },
      {
        "id": "{nodeId}-input-vectorStoreRetriever-VectorStoreRetriever",
        "name": "vectorStoreRetriever",
        "label": "vectorStoreRetriever",
        "type": "VectorStoreRetriever",
        "optional": true,
        "description": "Vector Store Retriever"
      },
      {
        "id": "{nodeId}-input-inputModeration-Moderation",
        "name": "inputModeration",
        "label": "inputModeration",
        "type": "Moderation",
        "optional": true,
        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-returnSourceDocuments-boolean",
        "name": "returnSourceDocuments",
        "label": "returnSourceDocuments",
        "type": "boolean",
        "optional": true,
        "description": "Return Source Documents"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-multiRetrievalQAChain-MultiRetrievalQAChain|MultiRouteChain|BaseChain|Runnable",
        "name": "multiRetrievalQAChain",
        "label": "Multi Retrieval QA Chain",
        "type": "MultiRetrievalQAChain | MultiRouteChain | BaseChain | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "QA Chain that automatically picks an appropriate vector store from multiple retrievers",
    "baseClasses": [
      "MultiRetrievalQAChain",
      "MultiRouteChain",
      "BaseChain",
      "Runnable"
    ]
  },
  {
    "node_type": "openApiChain",
    "name": "openApiChain",
    "label": "OpenAPI Chain",
    "category": "Chains",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-model-BaseChatModel",
        "name": "model",
        "label": "model",
        "type": "BaseChatModel",
        "optional": true,
        "description": "Chat Model"
      },
      {
        "id": "{nodeId}-input-inputModeration-Moderation",
        "name": "inputModeration",
        "label": "inputModeration",
        "type": "Moderation",
        "optional": true,
        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-yamlLink-string",
        "name": "yamlLink",
        "label": "yamlLink",
        "type": "string",
        "optional": true,
        "description": "If YAML link is provided, uploaded YAML File will be ignored and YAML link will be used instead"
      },
      {
        "id": "{nodeId}-input-yamlFile-file",
        "name": "yamlFile",
        "label": "yamlFile",
        "type": "file",
        "optional": true,
        "description": "If YAML link is provided, uploaded YAML File will be ignored and YAML link will be used instead"
      },
      {
        "id": "{nodeId}-input-headers-json",
        "name": "headers",
        "label": "headers",
        "type": "json",
        "optional": true,
        "description": "Headers"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-openApiChain-OpenAPIChain|BaseChain|Runnable",
        "name": "openApiChain",
        "label": "OpenAPI Chain",
        "type": "OpenAPIChain | BaseChain | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Chain that automatically select and call APIs based only on an OpenAPI spec",
    "baseClasses": [
      "OpenAPIChain",
      "BaseChain",
      "Runnable"
    ]
  },
  {
    "node_type": "postApiChain",
    "name": "postApiChain",
    "label": "POST API Chain",
    "category": "Chains",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-model-BaseLanguageModel",
        "name": "model",
        "label": "model",
        "type": "BaseLanguageModel",
        "optional": true,
        "description": "Language Model"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-apiDocs-string",
        "name": "apiDocs",
        "label": "apiDocs",
        "type": "string",
        "optional": true,
        "description": "Description of how API works. Please refer to more <a target=\"_blank\" href=\"https://github.com/langc"
      },
      {
        "id": "{nodeId}-input-headers-json",
        "name": "headers",
        "label": "headers",
        "type": "json",
        "optional": true,
        "description": "Headers"
      },
      {
        "id": "{nodeId}-input-urlPrompt-string",
        "name": "urlPrompt",
        "label": "urlPrompt",
        "type": "string",
        "optional": true,
        "description": "{api_docs} Using this documentation, generate a json string with two keys: \"url\" and \"data\". The value of \"url\" should be a string, which is the API url to call for answering the user question. The va"
      },
      {
        "id": "{nodeId}-input-ansPrompt-string",
        "name": "ansPrompt",
        "label": "ansPrompt",
        "type": "string",
        "optional": true,
        "description": "{api_docs} Using this documentation, generate a json string with two keys: \"url\" and \"data\". The value of \"url\" should be a string, which is the API url to call for answering the user question. The va"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-postApiChain-POSTApiChain|BaseChain|Runnable",
        "name": "postApiChain",
        "label": "POST API Chain",
        "type": "POSTApiChain | BaseChain | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Chain to run queries against POST API",
    "baseClasses": [
      "POSTApiChain",
      "BaseChain",
      "Runnable"
    ]
  },
  {
    "node_type": "retrievalQAChain",
    "name": "retrievalQAChain",
    "label": "Retrieval QA Chain",
    "category": "Chains",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-model-BaseLanguageModel",
        "name": "model",
        "label": "model",
        "type": "BaseLanguageModel",
        "optional": true,
        "description": "Language Model"
      },
      {
        "id": "{nodeId}-input-vectorStoreRetriever-BaseRetriever",
        "name": "vectorStoreRetriever",
        "label": "vectorStoreRetriever",
        "type": "BaseRetriever",
        "optional": true,
        "description": "Vector Store Retriever"
      },
      {
        "id": "{nodeId}-input-inputModeration-Moderation",
        "name": "inputModeration",
        "label": "inputModeration",
        "type": "Moderation",
        "optional": true,
        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model"
      }
    ],
    "inputParams": [],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-retrievalQAChain-RetrievalQAChain|BaseChain|Runnable",
        "name": "retrievalQAChain",
        "label": "Retrieval QA Chain",
        "type": "RetrievalQAChain | BaseChain | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "QA chain to answer a question based on the retrieved documents",
    "baseClasses": [
      "RetrievalQAChain",
      "BaseChain",
      "Runnable"
    ]
  },
  {
    "node_type": "sqlDatabaseChain",
    "name": "sqlDatabaseChain",
    "label": "Sql Database Chain",
    "category": "Chains",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-model-BaseLanguageModel",
        "name": "model",
        "label": "model",
        "type": "BaseLanguageModel",
        "optional": true,
        "description": "Language Model"
      },
      {
        "id": "{nodeId}-input-inputModeration-Moderation",
        "name": "inputModeration",
        "label": "inputModeration",
        "type": "Moderation",
        "optional": true,
        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-database-options",
        "name": "database",
        "label": "database",
        "type": "options",
        "optional": true,
        "default": "sqlite",
        "description": "Database"
      },
      {
        "id": "{nodeId}-input-url-string",
        "name": "url",
        "label": "url",
        "type": "string",
        "optional": true,
        "description": "Connection string or file path (sqlite only)"
      },
      {
        "id": "{nodeId}-input-includesTables-string",
        "name": "includesTables",
        "label": "includesTables",
        "type": "string",
        "optional": true,
        "description": "Tables to include for queries, separated by comma. Can only use Include Tables or Ignore Tables"
      },
      {
        "id": "{nodeId}-input-ignoreTables-string",
        "name": "ignoreTables",
        "label": "ignoreTables",
        "type": "string",
        "optional": true,
        "description": "Tables to ignore for queries, separated by comma. Can only use Ignore Tables or Include Tables"
      },
      {
        "id": "{nodeId}-input-sampleRowsInTableInfo-number",
        "name": "sampleRowsInTableInfo",
        "label": "sampleRowsInTableInfo",
        "type": "number",
        "optional": true,
        "description": "Number of sample row for tables to load for info."
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "If you are querying for several rows of a table you can select the maximum number of results you wan"
      },
      {
        "id": "{nodeId}-input-customPrompt-string",
        "name": "customPrompt",
        "label": "customPrompt",
        "type": "string",
        "optional": true,
        "description": "You can provide custom prompt to the chain. This will override the existing default prompt used. See"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-sqlDatabaseChain-SqlDatabaseChain|BaseChain|Runnable",
        "name": "sqlDatabaseChain",
        "label": "Sql Database Chain",
        "type": "SqlDatabaseChain | BaseChain | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "5",
    "description": "Answer questions over a SQL database",
    "baseClasses": [
      "SqlDatabaseChain",
      "BaseChain",
      "Runnable"
    ]
  },
  {
    "node_type": "vectaraQAChain",
    "name": "vectaraQAChain",
    "label": "Vectara QA Chain",
    "category": "Chains",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-vectaraStore-VectorStore",
        "name": "vectaraStore",
        "label": "vectaraStore",
        "type": "VectorStore",
        "optional": true,
        "description": "Vectara Store"
      },
      {
        "id": "{nodeId}-input-inputModeration-Moderation",
        "name": "inputModeration",
        "label": "inputModeration",
        "type": "Moderation",
        "optional": true,
        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-summarizerPromptName-options",
        "name": "summarizerPromptName",
        "label": "summarizerPromptName",
        "type": "options",
        "optional": true,
        "default": "vectara-summary-ext-v1.2.0",
        "description": "Summarize the results fetched from Vectara. Read <a target=\"_blank\" href=\"https://docs.vectara.com/d"
      },
      {
        "id": "{nodeId}-input-responseLang-options",
        "name": "responseLang",
        "label": "responseLang",
        "type": "options",
        "optional": true,
        "default": "eng",
        "description": "Return the response in specific language. If not selected, Vectara will automatically detects the la"
      },
      {
        "id": "{nodeId}-input-maxSummarizedResults-number",
        "name": "maxSummarizedResults",
        "label": "maxSummarizedResults",
        "type": "number",
        "optional": true,
        "default": "7",
        "description": "Maximum results used to build the summarized response"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-vectaraQAChain-VectaraQAChain|BaseChain|Runnable",
        "name": "vectaraQAChain",
        "label": "Vectara QA Chain",
        "type": "VectaraQAChain | BaseChain | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "QA chain for Vectara",
    "baseClasses": [
      "VectaraQAChain",
      "BaseChain",
      "Runnable"
    ]
  },
  {
    "node_type": "vectorDBQAChain",
    "name": "vectorDBQAChain",
    "label": "VectorDB QA Chain",
    "category": "Chains",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-model-BaseLanguageModel",
        "name": "model",
        "label": "model",
        "type": "BaseLanguageModel",
        "optional": true,
        "description": "Language Model"
      },
      {
        "id": "{nodeId}-input-vectorStore-VectorStore",
        "name": "vectorStore",
        "label": "vectorStore",
        "type": "VectorStore",
        "optional": true,
        "description": "Vector Store"
      },
      {
        "id": "{nodeId}-input-inputModeration-Moderation",
        "name": "inputModeration",
        "label": "inputModeration",
        "type": "Moderation",
        "optional": true,
        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model"
      }
    ],
    "inputParams": [],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-vectorDBQAChain-VectorDBQAChain|BaseChain|Runnable",
        "name": "vectorDBQAChain",
        "label": "VectorDB QA Chain",
        "type": "VectorDBQAChain | BaseChain | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "QA chain for vector databases",
    "baseClasses": [
      "VectorDBQAChain",
      "BaseChain",
      "Runnable"
    ]
  },
  {
    "node_type": "awsChatBedrock",
    "name": "awsChatBedrock",
    "label": "AWS ChatBedrock",
    "category": "Chat Models",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-region-asyncOptions",
        "name": "region",
        "label": "region",
        "type": "asyncOptions",
        "optional": true,
        "default": "us-east-1",
        "description": "Region"
      },
      {
        "id": "{nodeId}-input-model-asyncOptions",
        "name": "model",
        "label": "model",
        "type": "asyncOptions",
        "optional": true,
        "default": "anthropic.claude-3-haiku-20240307-v1:0",
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-customModel-string",
        "name": "customModel",
        "label": "customModel",
        "type": "string",
        "optional": true,
        "description": "If provided, will override model selected from Model Name option"
      },
      {
        "id": "{nodeId}-input-endpointHost-string",
        "name": "endpointHost",
        "label": "endpointHost",
        "type": "string",
        "optional": true,
        "description": "Custom endpoint host to use for the model. If provided, will override the default endpoint host."
      },
      {
        "id": "{nodeId}-input-allowImageUploads-boolean",
        "name": "allowImageUploads",
        "label": "allowImageUploads",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" tar"
      },
      {
        "id": "{nodeId}-input-streaming-boolean",
        "name": "streaming",
        "label": "streaming",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "Streaming"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.7",
        "description": "Temperature parameter may not apply to certain model. Please check available model parameters"
      },
      {
        "id": "{nodeId}-input-max_tokens_to_sample-number",
        "name": "max_tokens_to_sample",
        "label": "max_tokens_to_sample",
        "type": "number",
        "optional": true,
        "default": "200",
        "description": "Max Tokens parameter may not apply to certain model. Please check available model parameters"
      },
      {
        "id": "{nodeId}-input-latencyOptimized-boolean",
        "name": "latencyOptimized",
        "label": "latencyOptimized",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Enable latency optimized configuration for supported models. Refer to the supported <a href=\"https:/"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-awsChatBedrock-AWSChatBedrock|BaseChatModel|BaseLanguageModel|Runnable",
        "name": "awsChatBedrock",
        "label": "AWS ChatBedrock",
        "type": "AWSChatBedrock | BaseChatModel | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "6.1",
    "description": "Wrapper around AWS Bedrock large language models that use the Converse API",
    "baseClasses": [
      "AWSChatBedrock",
      "BaseChatModel",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "awsApi"
    ]
  },
  {
    "node_type": "azureChatOpenAI",
    "name": "azureChatOpenAI",
    "label": "Azure ChatOpenAI",
    "category": "Chat Models",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-imageResolution-options",
        "name": "imageResolution",
        "label": "imageResolution",
        "type": "options",
        "optional": false,
        "default": "low",
        "description": "This parameter controls the resolution in which the model views the image."
      },
      {
        "id": "{nodeId}-input-modelName-asyncOptions",
        "name": "modelName",
        "label": "modelName",
        "type": "asyncOptions",
        "optional": true,
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.9",
        "description": "Temperature"
      },
      {
        "id": "{nodeId}-input-allowImageUploads-boolean",
        "name": "allowImageUploads",
        "label": "allowImageUploads",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" tar"
      },
      {
        "id": "{nodeId}-input-maxTokens-number",
        "name": "maxTokens",
        "label": "maxTokens",
        "type": "number",
        "optional": true,
        "description": "Max Tokens"
      },
      {
        "id": "{nodeId}-input-streaming-boolean",
        "name": "streaming",
        "label": "streaming",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "Streaming"
      },
      {
        "id": "{nodeId}-input-topP-number",
        "name": "topP",
        "label": "topP",
        "type": "number",
        "optional": true,
        "description": "Top Probability"
      },
      {
        "id": "{nodeId}-input-frequencyPenalty-number",
        "name": "frequencyPenalty",
        "label": "frequencyPenalty",
        "type": "number",
        "optional": true,
        "description": "Frequency Penalty"
      },
      {
        "id": "{nodeId}-input-presencePenalty-number",
        "name": "presencePenalty",
        "label": "presencePenalty",
        "type": "number",
        "optional": true,
        "description": "Presence Penalty"
      },
      {
        "id": "{nodeId}-input-timeout-number",
        "name": "timeout",
        "label": "timeout",
        "type": "number",
        "optional": true,
        "description": "Timeout"
      },
      {
        "id": "{nodeId}-input-basepath-string",
        "name": "basepath",
        "label": "basepath",
        "type": "string",
        "optional": true,
        "description": "BasePath"
      },
      {
        "id": "{nodeId}-input-baseOptions-json",
        "name": "baseOptions",
        "label": "baseOptions",
        "type": "json",
        "optional": true,
        "description": "BaseOptions"
      },
      {
        "id": "{nodeId}-input-imageResolution-options",
        "name": "imageResolution",
        "label": "imageResolution",
        "type": "options",
        "optional": true,
        "default": "low",
        "description": "This parameter controls the resolution in which the model views the image."
      },
      {
        "id": "{nodeId}-input-reasoning-boolean",
        "name": "reasoning",
        "label": "reasoning",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Whether the model supports reasoning. Only applicable for reasoning models."
      },
      {
        "id": "{nodeId}-input-reasoningEffort-options",
        "name": "reasoningEffort",
        "label": "reasoningEffort",
        "type": "options",
        "optional": true,
        "description": "Constrains effort on reasoning for reasoning models. Only applicable for o1 and o3 models."
      },
      {
        "id": "{nodeId}-input-reasoningSummary-options",
        "name": "reasoningSummary",
        "label": "reasoningSummary",
        "type": "options",
        "optional": true,
        "description": "A summary of the reasoning performed by the model. This can be useful for debugging and understandin"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-azureChatOpenAI-AzureChatOpenAI|ChatOpenAI|BaseChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
        "name": "azureChatOpenAI",
        "label": "Azure ChatOpenAI",
        "type": "AzureChatOpenAI | ChatOpenAI | BaseChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "7.1",
    "description": "Wrapper around Azure OpenAI large language models that use the Chat endpoint",
    "baseClasses": [
      "AzureChatOpenAI",
      "ChatOpenAI",
      "BaseChatOpenAI",
      "BaseChatModel",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "azureOpenAIApi"
    ]
  },
  {
    "node_type": "azureChatOpenAI_LlamaIndex",
    "name": "azureChatOpenAI_LlamaIndex",
    "label": "AzureChatOpenAI",
    "category": "Chat Models",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-asyncOptions",
        "name": "modelName",
        "label": "modelName",
        "type": "asyncOptions",
        "optional": true,
        "default": "gpt-3.5-turbo-16k",
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.9",
        "description": "Temperature"
      },
      {
        "id": "{nodeId}-input-maxTokens-number",
        "name": "maxTokens",
        "label": "maxTokens",
        "type": "number",
        "optional": true,
        "description": "Max Tokens"
      },
      {
        "id": "{nodeId}-input-topP-number",
        "name": "topP",
        "label": "topP",
        "type": "number",
        "optional": true,
        "description": "Top Probability"
      },
      {
        "id": "{nodeId}-input-timeout-number",
        "name": "timeout",
        "label": "timeout",
        "type": "number",
        "optional": true,
        "description": "Timeout"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-azureChatOpenAI_LlamaIndex-AzureChatOpenAI|BaseChatModel_LlamaIndex|ToolCallLLM|BaseLLM",
        "name": "azureChatOpenAI_LlamaIndex",
        "label": "AzureChatOpenAI",
        "type": "AzureChatOpenAI | BaseChatModel_LlamaIndex | ToolCallLLM | BaseLLM"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Wrapper around Azure OpenAI Chat LLM specific for LlamaIndex",
    "baseClasses": [
      "AzureChatOpenAI",
      "BaseChatModel_LlamaIndex",
      "ToolCallLLM",
      "BaseLLM"
    ],
    "credential_required": [
      "azureOpenAIApi"
    ]
  },
  {
    "node_type": "chatAlibabaTongyi",
    "name": "chatAlibabaTongyi",
    "label": "ChatAlibabaTongyi",
    "category": "Chat Models",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-string",
        "name": "modelName",
        "label": "modelName",
        "type": "string",
        "optional": true,
        "description": "Model"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.9",
        "description": "Temperature"
      },
      {
        "id": "{nodeId}-input-streaming-boolean",
        "name": "streaming",
        "label": "streaming",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "Streaming"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-chatAlibabaTongyi-ChatAlibabaTongyi|BaseChatModel|BaseLanguageModel|Runnable",
        "name": "chatAlibabaTongyi",
        "label": "ChatAlibabaTongyi",
        "type": "ChatAlibabaTongyi | BaseChatModel | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Wrapper around Alibaba Tongyi Chat Endpoints",
    "baseClasses": [
      "ChatAlibabaTongyi",
      "BaseChatModel",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "AlibabaApi"
    ]
  },
  {
    "node_type": "chatAnthropic",
    "name": "chatAnthropic",
    "label": "ChatAnthropic",
    "category": "Chat Models",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-asyncOptions",
        "name": "modelName",
        "label": "modelName",
        "type": "asyncOptions",
        "optional": true,
        "default": "claude-3-haiku",
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.9",
        "description": "Temperature"
      },
      {
        "id": "{nodeId}-input-allowImageUploads-boolean",
        "name": "allowImageUploads",
        "label": "allowImageUploads",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" tar"
      },
      {
        "id": "{nodeId}-input-streaming-boolean",
        "name": "streaming",
        "label": "streaming",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "Streaming"
      },
      {
        "id": "{nodeId}-input-maxTokensToSample-number",
        "name": "maxTokensToSample",
        "label": "maxTokensToSample",
        "type": "number",
        "optional": true,
        "description": "Max Tokens"
      },
      {
        "id": "{nodeId}-input-topP-number",
        "name": "topP",
        "label": "topP",
        "type": "number",
        "optional": true,
        "description": "Top P"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Top K"
      },
      {
        "id": "{nodeId}-input-extendedThinking-boolean",
        "name": "extendedThinking",
        "label": "extendedThinking",
        "type": "boolean",
        "optional": true,
        "description": "Enable extended thinking for reasoning model such as Claude Sonnet 3.7 and Claude 4"
      },
      {
        "id": "{nodeId}-input-budgetTokens-number",
        "name": "budgetTokens",
        "label": "budgetTokens",
        "type": "number",
        "optional": true,
        "default": "1024",
        "description": "Maximum number of tokens Claude is allowed use for its internal reasoning process"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-chatAnthropic-ChatAnthropic|ChatAnthropicMessages|BaseChatModel|BaseLanguageModel|Runnable",
        "name": "chatAnthropic",
        "label": "ChatAnthropic",
        "type": "ChatAnthropic | ChatAnthropicMessages | BaseChatModel | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "8",
    "description": "Wrapper around ChatAnthropic large language models that use the Chat endpoint",
    "baseClasses": [
      "ChatAnthropic",
      "ChatAnthropicMessages",
      "BaseChatModel",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "anthropicApi"
    ]
  },
  {
    "node_type": "chatAnthropic_LlamaIndex",
    "name": "chatAnthropic_LlamaIndex",
    "label": "ChatAnthropic",
    "category": "Chat Models",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-asyncOptions",
        "name": "modelName",
        "label": "modelName",
        "type": "asyncOptions",
        "optional": true,
        "default": "claude-3-haiku",
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.9",
        "description": "Temperature"
      },
      {
        "id": "{nodeId}-input-maxTokensToSample-number",
        "name": "maxTokensToSample",
        "label": "maxTokensToSample",
        "type": "number",
        "optional": true,
        "description": "Max Tokens"
      },
      {
        "id": "{nodeId}-input-topP-number",
        "name": "topP",
        "label": "topP",
        "type": "number",
        "optional": true,
        "description": "Top P"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-chatAnthropic_LlamaIndex-ChatAnthropic|BaseChatModel_LlamaIndex|ToolCallLLM|BaseLLM",
        "name": "chatAnthropic_LlamaIndex",
        "label": "ChatAnthropic",
        "type": "ChatAnthropic | BaseChatModel_LlamaIndex | ToolCallLLM | BaseLLM"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "3",
    "description": "Wrapper around ChatAnthropic LLM specific for LlamaIndex",
    "baseClasses": [
      "ChatAnthropic",
      "BaseChatModel_LlamaIndex",
      "ToolCallLLM",
      "BaseLLM"
    ],
    "credential_required": [
      "anthropicApi"
    ]
  },
  {
    "node_type": "chatBaiduWenxin",
    "name": "chatBaiduWenxin",
    "label": "ChatBaiduWenxin",
    "category": "Chat Models",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-string",
        "name": "modelName",
        "label": "modelName",
        "type": "string",
        "optional": true,
        "description": "Model"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.9",
        "description": "Temperature"
      },
      {
        "id": "{nodeId}-input-streaming-boolean",
        "name": "streaming",
        "label": "streaming",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "Streaming"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-chatBaiduWenxin-ChatBaiduWenxin|BaseChatModel|BaseLanguageModel|Runnable",
        "name": "chatBaiduWenxin",
        "label": "ChatBaiduWenxin",
        "type": "ChatBaiduWenxin | BaseChatModel | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Wrapper around BaiduWenxin Chat Endpoints",
    "baseClasses": [
      "ChatBaiduWenxin",
      "BaseChatModel",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "baiduQianfanApi"
    ]
  },
  {
    "node_type": "chatCerebras",
    "name": "chatCerebras",
    "label": "ChatCerebras",
    "category": "Chat Models",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-asyncOptions",
        "name": "modelName",
        "label": "modelName",
        "type": "asyncOptions",
        "optional": true,
        "default": "llama3.1-8b",
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.9",
        "description": "Temperature"
      },
      {
        "id": "{nodeId}-input-streaming-boolean",
        "name": "streaming",
        "label": "streaming",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "Streaming"
      },
      {
        "id": "{nodeId}-input-maxTokens-number",
        "name": "maxTokens",
        "label": "maxTokens",
        "type": "number",
        "optional": true,
        "description": "Max Tokens"
      },
      {
        "id": "{nodeId}-input-topP-number",
        "name": "topP",
        "label": "topP",
        "type": "number",
        "optional": true,
        "description": "Top Probability"
      },
      {
        "id": "{nodeId}-input-frequencyPenalty-number",
        "name": "frequencyPenalty",
        "label": "frequencyPenalty",
        "type": "number",
        "optional": true,
        "description": "Frequency Penalty"
      },
      {
        "id": "{nodeId}-input-presencePenalty-number",
        "name": "presencePenalty",
        "label": "presencePenalty",
        "type": "number",
        "optional": true,
        "description": "Presence Penalty"
      },
      {
        "id": "{nodeId}-input-timeout-number",
        "name": "timeout",
        "label": "timeout",
        "type": "number",
        "optional": true,
        "description": "Timeout"
      },
      {
        "id": "{nodeId}-input-basepath-string",
        "name": "basepath",
        "label": "basepath",
        "type": "string",
        "optional": true,
        "default": "https://api.cerebras.ai/v1",
        "description": "BasePath"
      },
      {
        "id": "{nodeId}-input-baseOptions-json",
        "name": "baseOptions",
        "label": "baseOptions",
        "type": "json",
        "optional": true,
        "description": "BaseOptions"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-chatCerebras-ChatCerebras|BaseChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
        "name": "chatCerebras",
        "label": "ChatCerebras",
        "type": "ChatCerebras | BaseChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "3",
    "description": "Wrapper around Cerebras Inference API",
    "baseClasses": [
      "ChatCerebras",
      "BaseChatOpenAI",
      "BaseChatModel",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "cerebrasAIApi"
    ]
  },
  {
    "node_type": "chatCloudflareWorkersAI",
    "name": "chatCloudflareWorkersAI",
    "label": "ChatCloudflareWorkersAI",
    "category": "Chat Models",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-model-string",
        "name": "model",
        "label": "model",
        "type": "string",
        "optional": true,
        "default": "@cf/meta/llama-3.1-8b-instruct-fast",
        "description": "Model to use, e.g. @cf/meta/llama-3.1-8b-instruct-fast"
      },
      {
        "id": "{nodeId}-input-baseUrl-string",
        "name": "baseUrl",
        "label": "baseUrl",
        "type": "string",
        "optional": true,
        "description": "Base URL for Cloudflare Workers AI. Defaults to https://api.cloudflare.com/client/v4/accounts"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-chatCloudflareWorkersAI-ChatCloudflareWorkersAI|SimpleChatModel|BaseChatModel|BaseLanguageModel|Runnable",
        "name": "chatCloudflareWorkersAI",
        "label": "ChatCloudflareWorkersAI",
        "type": "ChatCloudflareWorkersAI | SimpleChatModel | BaseChatModel | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Wrapper around Cloudflare Workers AI chat models",
    "baseClasses": [
      "ChatCloudflareWorkersAI",
      "SimpleChatModel",
      "BaseChatModel",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "cloudflareApi"
    ]
  },
  {
    "node_type": "chatCohere",
    "name": "chatCohere",
    "label": "ChatCohere",
    "category": "Chat Models",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-asyncOptions",
        "name": "modelName",
        "label": "modelName",
        "type": "asyncOptions",
        "optional": true,
        "default": "command-r",
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.7",
        "description": "Temperature"
      },
      {
        "id": "{nodeId}-input-streaming-boolean",
        "name": "streaming",
        "label": "streaming",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "Streaming"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-chatCohere-ChatCohere|BaseChatModel|BaseLanguageModel|Runnable",
        "name": "chatCohere",
        "label": "ChatCohere",
        "type": "ChatCohere | BaseChatModel | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Wrapper around Cohere Chat Endpoints",
    "baseClasses": [
      "ChatCohere",
      "BaseChatModel",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "cohereApi"
    ]
  },
  {
    "node_type": "chatCometAPI",
    "name": "chatCometAPI",
    "label": "ChatCometAPI",
    "category": "Chat Models",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-string",
        "name": "modelName",
        "label": "modelName",
        "type": "string",
        "optional": true,
        "default": "gpt-5-mini",
        "description": "Enter the model name (e.g., gpt-5-mini, claude-sonnet-4-20250514, gemini-2.0-flash)"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.7",
        "description": "Temperature"
      },
      {
        "id": "{nodeId}-input-streaming-boolean",
        "name": "streaming",
        "label": "streaming",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "Streaming"
      },
      {
        "id": "{nodeId}-input-maxTokens-number",
        "name": "maxTokens",
        "label": "maxTokens",
        "type": "number",
        "optional": true,
        "description": "Max Tokens"
      },
      {
        "id": "{nodeId}-input-topP-number",
        "name": "topP",
        "label": "topP",
        "type": "number",
        "optional": true,
        "description": "Top Probability"
      },
      {
        "id": "{nodeId}-input-frequencyPenalty-number",
        "name": "frequencyPenalty",
        "label": "frequencyPenalty",
        "type": "number",
        "optional": true,
        "description": "Frequency Penalty"
      },
      {
        "id": "{nodeId}-input-presencePenalty-number",
        "name": "presencePenalty",
        "label": "presencePenalty",
        "type": "number",
        "optional": true,
        "description": "Presence Penalty"
      },
      {
        "id": "{nodeId}-input-baseOptions-json",
        "name": "baseOptions",
        "label": "baseOptions",
        "type": "json",
        "optional": true,
        "description": "Additional options to pass to the CometAPI client. This should be a JSON object."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-chatCometAPI-ChatCometAPI|BaseChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
        "name": "chatCometAPI",
        "label": "ChatCometAPI",
        "type": "ChatCometAPI | BaseChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Wrapper around CometAPI large language models that use the Chat endpoint",
    "baseClasses": [
      "ChatCometAPI",
      "BaseChatOpenAI",
      "BaseChatModel",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "cometApi"
    ]
  },
  {
    "node_type": "chatDeepseek",
    "name": "chatDeepseek",
    "label": "ChatDeepseek",
    "category": "Chat Models",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-asyncOptions",
        "name": "modelName",
        "label": "modelName",
        "type": "asyncOptions",
        "optional": true,
        "default": "deepseek-chat",
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.7",
        "description": "Temperature"
      },
      {
        "id": "{nodeId}-input-streaming-boolean",
        "name": "streaming",
        "label": "streaming",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "Streaming"
      },
      {
        "id": "{nodeId}-input-maxTokens-number",
        "name": "maxTokens",
        "label": "maxTokens",
        "type": "number",
        "optional": true,
        "description": "Max Tokens"
      },
      {
        "id": "{nodeId}-input-topP-number",
        "name": "topP",
        "label": "topP",
        "type": "number",
        "optional": true,
        "description": "Top Probability"
      },
      {
        "id": "{nodeId}-input-frequencyPenalty-number",
        "name": "frequencyPenalty",
        "label": "frequencyPenalty",
        "type": "number",
        "optional": true,
        "description": "Frequency Penalty"
      },
      {
        "id": "{nodeId}-input-presencePenalty-number",
        "name": "presencePenalty",
        "label": "presencePenalty",
        "type": "number",
        "optional": true,
        "description": "Presence Penalty"
      },
      {
        "id": "{nodeId}-input-timeout-number",
        "name": "timeout",
        "label": "timeout",
        "type": "number",
        "optional": true,
        "description": "Timeout"
      },
      {
        "id": "{nodeId}-input-stopSequence-string",
        "name": "stopSequence",
        "label": "stopSequence",
        "type": "string",
        "optional": true,
        "description": "List of stop words to use when generating. Use comma to separate multiple stop words."
      },
      {
        "id": "{nodeId}-input-baseOptions-json",
        "name": "baseOptions",
        "label": "baseOptions",
        "type": "json",
        "optional": true,
        "description": "Additional options to pass to the Deepseek client. This should be a JSON object."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-chatDeepseek-chatDeepseek|BaseChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
        "name": "chatDeepseek",
        "label": "ChatDeepseek",
        "type": "chatDeepseek | BaseChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Wrapper around Deepseek large language models that use the Chat endpoint",
    "baseClasses": [
      "chatDeepseek",
      "BaseChatOpenAI",
      "BaseChatModel",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "deepseekApi"
    ]
  },
  {
    "node_type": "chatFireworks",
    "name": "chatFireworks",
    "label": "ChatFireworks",
    "category": "Chat Models",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-string",
        "name": "modelName",
        "label": "modelName",
        "type": "string",
        "optional": true,
        "default": "accounts/fireworks/models/llama-v3p1-8b-instruct",
        "description": "Model"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.9",
        "description": "Temperature"
      },
      {
        "id": "{nodeId}-input-streaming-boolean",
        "name": "streaming",
        "label": "streaming",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "Streaming"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-chatFireworks-ChatFireworks|ChatOpenAICompletions|BaseChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
        "name": "chatFireworks",
        "label": "ChatFireworks",
        "type": "ChatFireworks | ChatOpenAICompletions | BaseChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Wrapper around Fireworks Chat Endpoints",
    "baseClasses": [
      "ChatFireworks",
      "ChatOpenAICompletions",
      "BaseChatOpenAI",
      "BaseChatModel",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "fireworksApi"
    ]
  },
  {
    "node_type": "chatGoogleGenerativeAI",
    "name": "chatGoogleGenerativeAI",
    "label": "ChatGoogleGenerativeAI",
    "category": "Chat Models",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-asyncOptions",
        "name": "modelName",
        "label": "modelName",
        "type": "asyncOptions",
        "optional": true,
        "default": "gemini-1.5-flash-latest",
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.9",
        "description": "Temperature"
      },
      {
        "id": "{nodeId}-input-allowImageUploads-boolean",
        "name": "allowImageUploads",
        "label": "allowImageUploads",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" tar"
      },
      {
        "id": "{nodeId}-input-customModelName-string",
        "name": "customModelName",
        "label": "customModelName",
        "type": "string",
        "optional": true,
        "description": "Custom model name to use. If provided, it will override the model selected"
      },
      {
        "id": "{nodeId}-input-streaming-boolean",
        "name": "streaming",
        "label": "streaming",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "Streaming"
      },
      {
        "id": "{nodeId}-input-maxOutputTokens-number",
        "name": "maxOutputTokens",
        "label": "maxOutputTokens",
        "type": "number",
        "optional": true,
        "description": "Max Output Tokens"
      },
      {
        "id": "{nodeId}-input-topP-number",
        "name": "topP",
        "label": "topP",
        "type": "number",
        "optional": true,
        "description": "Top Probability"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive"
      },
      {
        "id": "{nodeId}-input-safetySettings-array",
        "name": "safetySettings",
        "label": "safetySettings",
        "type": "array",
        "optional": true,
        "description": "Safety settings for the model. Refer to the <a href=\"https://ai.google.dev/gemini-api/docs/safety-se"
      },
      {
        "id": "{nodeId}-input-thinkingBudget-number",
        "name": "thinkingBudget",
        "label": "thinkingBudget",
        "type": "number",
        "optional": true,
        "description": "Guides the number of thinking tokens. -1 for dynamic, 0 to disable, or positive integer (Gemini 2.5"
      },
      {
        "id": "{nodeId}-input-baseUrl-string",
        "name": "baseUrl",
        "label": "baseUrl",
        "type": "string",
        "optional": true,
        "description": "Base URL for the API. Leave empty to use the default."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable",
        "name": "chatGoogleGenerativeAI",
        "label": "ChatGoogleGenerativeAI",
        "type": "ChatGoogleGenerativeAI | LangchainChatGoogleGenerativeAI | BaseChatModel | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "3.1",
    "description": "Wrapper around Google Gemini large language models that use the Chat endpoint",
    "baseClasses": [
      "ChatGoogleGenerativeAI",
      "LangchainChatGoogleGenerativeAI",
      "BaseChatModel",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "googleGenerativeAI"
    ]
  },
  {
    "node_type": "chatGoogleVertexAI",
    "name": "chatGoogleVertexAI",
    "label": "ChatGoogleVertexAI",
    "category": "Chat Models",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-region-asyncOptions",
        "name": "region",
        "label": "region",
        "type": "asyncOptions",
        "optional": true,
        "description": "Region to use for the model."
      },
      {
        "id": "{nodeId}-input-modelName-asyncOptions",
        "name": "modelName",
        "label": "modelName",
        "type": "asyncOptions",
        "optional": true,
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.9",
        "description": "Temperature"
      },
      {
        "id": "{nodeId}-input-allowImageUploads-boolean",
        "name": "allowImageUploads",
        "label": "allowImageUploads",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" tar"
      },
      {
        "id": "{nodeId}-input-customModelName-string",
        "name": "customModelName",
        "label": "customModelName",
        "type": "string",
        "optional": true,
        "description": "Custom model name to use. If provided, it will override the model selected"
      },
      {
        "id": "{nodeId}-input-streaming-boolean",
        "name": "streaming",
        "label": "streaming",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "Streaming"
      },
      {
        "id": "{nodeId}-input-maxOutputTokens-number",
        "name": "maxOutputTokens",
        "label": "maxOutputTokens",
        "type": "number",
        "optional": true,
        "description": "Max Output Tokens"
      },
      {
        "id": "{nodeId}-input-topP-number",
        "name": "topP",
        "label": "topP",
        "type": "number",
        "optional": true,
        "description": "Top Probability"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive"
      },
      {
        "id": "{nodeId}-input-thinkingBudget-number",
        "name": "thinkingBudget",
        "label": "thinkingBudget",
        "type": "number",
        "optional": true,
        "description": "Number of tokens to use for thinking process (0 to disable)"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-chatGoogleVertexAI-ChatGoogleVertexAI|ChatVertexAI|ChatGoogle|ChatGoogleBase|BaseChatModel|BaseLanguageModel|Runnable",
        "name": "chatGoogleVertexAI",
        "label": "ChatGoogleVertexAI",
        "type": "ChatGoogleVertexAI | ChatVertexAI | ChatGoogle | ChatGoogleBase | BaseChatModel | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "5.3",
    "description": "Wrapper around VertexAI large language models that use the Chat endpoint",
    "baseClasses": [
      "ChatGoogleVertexAI",
      "ChatVertexAI",
      "ChatGoogle",
      "ChatGoogleBase",
      "BaseChatModel",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "googleVertexAuth"
    ]
  },
  {
    "node_type": "chatGroq_LlamaIndex",
    "name": "chatGroq_LlamaIndex",
    "label": "ChatGroq",
    "category": "Chat Models",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-asyncOptions",
        "name": "modelName",
        "label": "modelName",
        "type": "asyncOptions",
        "optional": true,
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.9",
        "description": "Temperature"
      },
      {
        "id": "{nodeId}-input-maxTokens-number",
        "name": "maxTokens",
        "label": "maxTokens",
        "type": "number",
        "optional": true,
        "description": "Max Tokens"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-chatGroq_LlamaIndex-ChatGroq|BaseChatModel_LlamaIndex|OpenAI|ToolCallLLM|BaseLLM",
        "name": "chatGroq_LlamaIndex",
        "label": "ChatGroq",
        "type": "ChatGroq | BaseChatModel_LlamaIndex | OpenAI | ToolCallLLM | BaseLLM"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Wrapper around Groq LLM specific for LlamaIndex",
    "baseClasses": [
      "ChatGroq",
      "BaseChatModel_LlamaIndex",
      "OpenAI",
      "ToolCallLLM",
      "BaseLLM"
    ],
    "credential_required": [
      "groqApi"
    ]
  },
  {
    "node_type": "chatHuggingFace",
    "name": "chatHuggingFace",
    "label": "ChatHuggingFace",
    "category": "Chat Models",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-model-string",
        "name": "model",
        "label": "model",
        "type": "string",
        "optional": true,
        "description": "Model name (e.g., deepseek-ai/DeepSeek-V3.2-Exp:novita). If model includes provider (:) or using rou"
      },
      {
        "id": "{nodeId}-input-endpoint-string",
        "name": "endpoint",
        "label": "endpoint",
        "type": "string",
        "optional": true,
        "description": "Custom inference endpoint (optional). Not needed for models with providers (:) or router endpoints."
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "description": "Temperature parameter may not apply to certain model. Please check available model parameters"
      },
      {
        "id": "{nodeId}-input-maxTokens-number",
        "name": "maxTokens",
        "label": "maxTokens",
        "type": "number",
        "optional": true,
        "description": "Max Tokens parameter may not apply to certain model. Please check available model parameters"
      },
      {
        "id": "{nodeId}-input-topP-number",
        "name": "topP",
        "label": "topP",
        "type": "number",
        "optional": true,
        "description": "Top Probability parameter may not apply to certain model. Please check available model parameters"
      },
      {
        "id": "{nodeId}-input-hfTopK-number",
        "name": "hfTopK",
        "label": "hfTopK",
        "type": "number",
        "optional": true,
        "description": "Top K parameter may not apply to certain model. Please check available model parameters"
      },
      {
        "id": "{nodeId}-input-frequencyPenalty-number",
        "name": "frequencyPenalty",
        "label": "frequencyPenalty",
        "type": "number",
        "optional": true,
        "description": "Frequency Penalty parameter may not apply to certain model. Please check available model parameters"
      },
      {
        "id": "{nodeId}-input-stop-string",
        "name": "stop",
        "label": "stop",
        "type": "string",
        "optional": true,
        "description": "Sets the stop sequences to use. Use comma to separate different sequences."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-chatHuggingFace-ChatHuggingFace|BaseChatModel|LLM|BaseLLM|BaseLanguageModel|Runnable",
        "name": "chatHuggingFace",
        "label": "ChatHuggingFace",
        "type": "ChatHuggingFace | BaseChatModel | LLM | BaseLLM | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "3",
    "description": "Wrapper around HuggingFace large language models",
    "baseClasses": [
      "ChatHuggingFace",
      "BaseChatModel",
      "LLM",
      "BaseLLM",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "huggingFaceApi"
    ]
  },
  {
    "node_type": "chatIBMWatsonx",
    "name": "chatIBMWatsonx",
    "label": "ChatIBMWatsonx",
    "category": "Chat Models",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-string",
        "name": "modelName",
        "label": "modelName",
        "type": "string",
        "optional": true,
        "description": "Model"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.9",
        "description": "Temperature"
      },
      {
        "id": "{nodeId}-input-streaming-boolean",
        "name": "streaming",
        "label": "streaming",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "Streaming"
      },
      {
        "id": "{nodeId}-input-maxTokens-number",
        "name": "maxTokens",
        "label": "maxTokens",
        "type": "number",
        "optional": true,
        "description": "Max Tokens"
      },
      {
        "id": "{nodeId}-input-frequencyPenalty-number",
        "name": "frequencyPenalty",
        "label": "frequencyPenalty",
        "type": "number",
        "optional": true,
        "description": "Positive values penalize new tokens based on their existing frequency in the text so far, decreasing"
      },
      {
        "id": "{nodeId}-input-logprobs-boolean",
        "name": "logprobs",
        "label": "logprobs",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Whether to return log probabilities of the output tokens or not. If true, returns the log probabilit"
      },
      {
        "id": "{nodeId}-input-n-number",
        "name": "n",
        "label": "n",
        "type": "number",
        "optional": true,
        "default": "1",
        "description": "How many chat completion choices to generate for each input message. Note that you will be charged b"
      },
      {
        "id": "{nodeId}-input-presencePenalty-number",
        "name": "presencePenalty",
        "label": "presencePenalty",
        "type": "number",
        "optional": true,
        "default": "1",
        "description": "Positive values penalize new tokens based on whether they appear in the text so far, increasing the"
      },
      {
        "id": "{nodeId}-input-topP-number",
        "name": "topP",
        "label": "topP",
        "type": "number",
        "optional": true,
        "default": "0.1",
        "description": "An alternative to sampling with temperature, called nucleus sampling, where the model considers the"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-chatIBMWatsonx-ChatIBMWatsonx|BaseChatModel|BaseLanguageModel|Runnable",
        "name": "chatIBMWatsonx",
        "label": "ChatIBMWatsonx",
        "type": "ChatIBMWatsonx | BaseChatModel | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Wrapper around IBM watsonx.ai foundation models",
    "baseClasses": [
      "ChatIBMWatsonx",
      "BaseChatModel",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "ibmWatsonx"
    ]
  },
  {
    "node_type": "chatLitellm",
    "name": "chatLitellm",
    "label": "ChatLitellm",
    "category": "Chat Models",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-imageResolution-options",
        "name": "imageResolution",
        "label": "imageResolution",
        "type": "options",
        "optional": false,
        "default": "low",
        "description": "This parameter controls the resolution in which the model views the image."
      },
      {
        "id": "{nodeId}-input-basePath-string",
        "name": "basePath",
        "label": "basePath",
        "type": "string",
        "optional": true,
        "description": "Base URL"
      },
      {
        "id": "{nodeId}-input-modelName-string",
        "name": "modelName",
        "label": "modelName",
        "type": "string",
        "optional": true,
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.9",
        "description": "Temperature"
      },
      {
        "id": "{nodeId}-input-allowImageUploads-boolean",
        "name": "allowImageUploads",
        "label": "allowImageUploads",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Allow image input. Image uploads need a model marked supports_vision=true in LiteLLM. Refer to the <"
      },
      {
        "id": "{nodeId}-input-streaming-boolean",
        "name": "streaming",
        "label": "streaming",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "Streaming"
      },
      {
        "id": "{nodeId}-input-maxTokens-number",
        "name": "maxTokens",
        "label": "maxTokens",
        "type": "number",
        "optional": true,
        "description": "Max Tokens"
      },
      {
        "id": "{nodeId}-input-topP-number",
        "name": "topP",
        "label": "topP",
        "type": "number",
        "optional": true,
        "description": "Top P"
      },
      {
        "id": "{nodeId}-input-timeout-number",
        "name": "timeout",
        "label": "timeout",
        "type": "number",
        "optional": true,
        "description": "Timeout"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-chatLitellm-ChatLitellm|BaseChatModel|BaseChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
        "name": "chatLitellm",
        "label": "ChatLitellm",
        "type": "ChatLitellm | BaseChatModel | BaseChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Connect to a Litellm server using OpenAI-compatible API",
    "baseClasses": [
      "ChatLitellm",
      "BaseChatModel",
      "BaseChatOpenAI",
      "BaseChatModel",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "litellmApi"
    ]
  },
  {
    "node_type": "chatLocalAI",
    "name": "chatLocalAI",
    "label": "ChatLocalAI",
    "category": "Chat Models",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-basePath-string",
        "name": "basePath",
        "label": "basePath",
        "type": "string",
        "optional": true,
        "description": "Base Path"
      },
      {
        "id": "{nodeId}-input-modelName-string",
        "name": "modelName",
        "label": "modelName",
        "type": "string",
        "optional": true,
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.9",
        "description": "Temperature"
      },
      {
        "id": "{nodeId}-input-streaming-boolean",
        "name": "streaming",
        "label": "streaming",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "Streaming"
      },
      {
        "id": "{nodeId}-input-maxTokens-number",
        "name": "maxTokens",
        "label": "maxTokens",
        "type": "number",
        "optional": true,
        "description": "Max Tokens"
      },
      {
        "id": "{nodeId}-input-topP-number",
        "name": "topP",
        "label": "topP",
        "type": "number",
        "optional": true,
        "description": "Top Probability"
      },
      {
        "id": "{nodeId}-input-timeout-number",
        "name": "timeout",
        "label": "timeout",
        "type": "number",
        "optional": true,
        "description": "Timeout"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-chatLocalAI-ChatLocalAI|BaseChatModel|BaseChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
        "name": "chatLocalAI",
        "label": "ChatLocalAI",
        "type": "ChatLocalAI | BaseChatModel | BaseChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "3",
    "description": "Use local LLMs like llama.cpp, gpt4all using LocalAI",
    "baseClasses": [
      "ChatLocalAI",
      "BaseChatModel",
      "BaseChatOpenAI",
      "BaseChatModel",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "localAIApi"
    ]
  },
  {
    "node_type": "chatMistralAI",
    "name": "chatMistralAI",
    "label": "ChatMistralAI",
    "category": "Chat Models",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-asyncOptions",
        "name": "modelName",
        "label": "modelName",
        "type": "asyncOptions",
        "optional": true,
        "default": "mistral-tiny",
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.9",
        "description": "What sampling temperature to use, between 0.0 and 1.0. Higher values like 0.8 will make the output m"
      },
      {
        "id": "{nodeId}-input-streaming-boolean",
        "name": "streaming",
        "label": "streaming",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "Streaming"
      },
      {
        "id": "{nodeId}-input-maxOutputTokens-number",
        "name": "maxOutputTokens",
        "label": "maxOutputTokens",
        "type": "number",
        "optional": true,
        "description": "The maximum number of tokens to generate in the completion."
      },
      {
        "id": "{nodeId}-input-topP-number",
        "name": "topP",
        "label": "topP",
        "type": "number",
        "optional": true,
        "description": "Nucleus sampling, where the model considers the results of the tokens with top_p probability mass. S"
      },
      {
        "id": "{nodeId}-input-randomSeed-number",
        "name": "randomSeed",
        "label": "randomSeed",
        "type": "number",
        "optional": true,
        "description": "The seed to use for random sampling. If set, different calls will generate deterministic results."
      },
      {
        "id": "{nodeId}-input-safeMode-boolean",
        "name": "safeMode",
        "label": "safeMode",
        "type": "boolean",
        "optional": true,
        "description": "Whether to inject a safety prompt before all conversations."
      },
      {
        "id": "{nodeId}-input-overrideEndpoint-string",
        "name": "overrideEndpoint",
        "label": "overrideEndpoint",
        "type": "string",
        "optional": true,
        "description": "Override Endpoint"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-chatMistralAI-ChatMistralAI|BaseChatModel|BaseLanguageModel|Runnable",
        "name": "chatMistralAI",
        "label": "ChatMistralAI",
        "type": "ChatMistralAI | BaseChatModel | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "4",
    "description": "Wrapper around Mistral large language models that use the Chat endpoint",
    "baseClasses": [
      "ChatMistralAI",
      "BaseChatModel",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "mistralAIApi"
    ]
  },
  {
    "node_type": "chatMistral_LlamaIndex",
    "name": "chatMistral_LlamaIndex",
    "label": "ChatMistral",
    "category": "Chat Models",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-asyncOptions",
        "name": "modelName",
        "label": "modelName",
        "type": "asyncOptions",
        "optional": true,
        "default": "mistral-tiny",
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.9",
        "description": "Temperature"
      },
      {
        "id": "{nodeId}-input-maxTokensToSample-number",
        "name": "maxTokensToSample",
        "label": "maxTokensToSample",
        "type": "number",
        "optional": true,
        "description": "Max Tokens"
      },
      {
        "id": "{nodeId}-input-topP-number",
        "name": "topP",
        "label": "topP",
        "type": "number",
        "optional": true,
        "description": "Top P"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-chatMistral_LlamaIndex-ChatMistral|BaseChatModel_LlamaIndex|BaseLLM",
        "name": "chatMistral_LlamaIndex",
        "label": "ChatMistral",
        "type": "ChatMistral | BaseChatModel_LlamaIndex | BaseLLM"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Wrapper around ChatMistral LLM specific for LlamaIndex",
    "baseClasses": [
      "ChatMistral",
      "BaseChatModel_LlamaIndex",
      "BaseLLM"
    ],
    "credential_required": [
      "mistralAIApi"
    ]
  },
  {
    "node_type": "chatNemoGuardrails",
    "name": "chatNemoGuardrails",
    "label": "Chat Nemo Guardrails",
    "category": "Chat Models",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-configurationId-string",
        "name": "configurationId",
        "label": "configurationId",
        "type": "string",
        "optional": false,
        "description": "Configuration ID"
      },
      {
        "id": "{nodeId}-input-baseUrl-string",
        "name": "baseUrl",
        "label": "baseUrl",
        "type": "string",
        "optional": false,
        "description": "Base URL"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-chatNemoGuardrails-ChatNemoGuardrails|BaseChatModel|BaseLanguageModel|Runnable",
        "name": "chatNemoGuardrails",
        "label": "Chat Nemo Guardrails",
        "type": "ChatNemoGuardrails | BaseChatModel | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Access models through the Nemo Guardrails API",
    "baseClasses": [
      "ChatNemoGuardrails",
      "BaseChatModel",
      "BaseLanguageModel",
      "Runnable"
    ]
  },
  {
    "node_type": "chatNvidiaNIM",
    "name": "chatNvidiaNIM",
    "label": "Chat NVIDIA NIM",
    "category": "Chat Models",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-string",
        "name": "modelName",
        "label": "modelName",
        "type": "string",
        "optional": true,
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-basePath-string",
        "name": "basePath",
        "label": "basePath",
        "type": "string",
        "optional": true,
        "description": "Specify the URL of the deployed NIM Inference API"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.9",
        "description": "Temperature"
      },
      {
        "id": "{nodeId}-input-streaming-boolean",
        "name": "streaming",
        "label": "streaming",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "Streaming"
      },
      {
        "id": "{nodeId}-input-maxTokens-number",
        "name": "maxTokens",
        "label": "maxTokens",
        "type": "number",
        "optional": true,
        "description": "Max Tokens"
      },
      {
        "id": "{nodeId}-input-topP-number",
        "name": "topP",
        "label": "topP",
        "type": "number",
        "optional": true,
        "description": "Top Probability"
      },
      {
        "id": "{nodeId}-input-frequencyPenalty-number",
        "name": "frequencyPenalty",
        "label": "frequencyPenalty",
        "type": "number",
        "optional": true,
        "description": "Frequency Penalty"
      },
      {
        "id": "{nodeId}-input-presencePenalty-number",
        "name": "presencePenalty",
        "label": "presencePenalty",
        "type": "number",
        "optional": true,
        "description": "Presence Penalty"
      },
      {
        "id": "{nodeId}-input-timeout-number",
        "name": "timeout",
        "label": "timeout",
        "type": "number",
        "optional": true,
        "description": "Timeout"
      },
      {
        "id": "{nodeId}-input-baseOptions-json",
        "name": "baseOptions",
        "label": "baseOptions",
        "type": "json",
        "optional": true,
        "description": "Base Options"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-chatNvidiaNIM-ChatNvidiaNIM|BaseChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
        "name": "chatNvidiaNIM",
        "label": "Chat NVIDIA NIM",
        "type": "ChatNvidiaNIM | BaseChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1.1",
    "description": "Wrapper around NVIDIA NIM Inference API",
    "baseClasses": [
      "ChatNvidiaNIM",
      "BaseChatOpenAI",
      "BaseChatModel",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "nvidiaNIMApi"
    ]
  },
  {
    "node_type": "chatOllama",
    "name": "chatOllama",
    "label": "ChatOllama",
    "category": "Chat Models",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-baseUrl-string",
        "name": "baseUrl",
        "label": "baseUrl",
        "type": "string",
        "optional": true,
        "default": "http://localhost:11434",
        "description": "Base URL"
      },
      {
        "id": "{nodeId}-input-modelName-string",
        "name": "modelName",
        "label": "modelName",
        "type": "string",
        "optional": true,
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.9",
        "description": "The temperature of the model. Increasing the temperature will make the model answer more creatively."
      },
      {
        "id": "{nodeId}-input-allowImageUploads-boolean",
        "name": "allowImageUploads",
        "label": "allowImageUploads",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" tar"
      },
      {
        "id": "{nodeId}-input-streaming-boolean",
        "name": "streaming",
        "label": "streaming",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "Streaming"
      },
      {
        "id": "{nodeId}-input-jsonMode-boolean",
        "name": "jsonMode",
        "label": "jsonMode",
        "type": "boolean",
        "optional": true,
        "description": "Coerces model outputs to only return JSON. Specify in the system prompt to return JSON. Ex: Format a"
      },
      {
        "id": "{nodeId}-input-keepAlive-string",
        "name": "keepAlive",
        "label": "keepAlive",
        "type": "string",
        "optional": true,
        "default": "5m",
        "description": "How long to keep connection alive. A duration string (such as \"10m\" or \"24h\")"
      },
      {
        "id": "{nodeId}-input-topP-number",
        "name": "topP",
        "label": "topP",
        "type": "number",
        "optional": true,
        "description": "Works together with top-k. A higher value (e.g., 0.95) will lead to more diverse text, while a lower"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Reduces the probability of generating nonsense. A higher value (e.g. 100) will give more diverse ans"
      },
      {
        "id": "{nodeId}-input-mirostat-number",
        "name": "mirostat",
        "label": "mirostat",
        "type": "number",
        "optional": true,
        "description": "Enable Mirostat sampling for controlling perplexity. (default: 0, 0 = disabled, 1 = Mirostat, 2 = Mi"
      },
      {
        "id": "{nodeId}-input-mirostatEta-number",
        "name": "mirostatEta",
        "label": "mirostatEta",
        "type": "number",
        "optional": true,
        "description": "Influences how quickly the algorithm responds to feedback from the generated text. A lower learning"
      },
      {
        "id": "{nodeId}-input-mirostatTau-number",
        "name": "mirostatTau",
        "label": "mirostatTau",
        "type": "number",
        "optional": true,
        "description": "Controls the balance between coherence and diversity of the output. A lower value will result in mor"
      },
      {
        "id": "{nodeId}-input-numCtx-number",
        "name": "numCtx",
        "label": "numCtx",
        "type": "number",
        "optional": true,
        "description": "Sets the size of the context window used to generate the next token. (Default: 2048) Refer to <a tar"
      },
      {
        "id": "{nodeId}-input-numGpu-number",
        "name": "numGpu",
        "label": "numGpu",
        "type": "number",
        "optional": true,
        "description": "The number of layers to send to the GPU(s). On macOS it defaults to 1 to enable metal support, 0 to"
      },
      {
        "id": "{nodeId}-input-numThread-number",
        "name": "numThread",
        "label": "numThread",
        "type": "number",
        "optional": true,
        "description": "Sets the number of threads to use during computation. By default, Ollama will detect this for optima"
      },
      {
        "id": "{nodeId}-input-repeatLastN-number",
        "name": "repeatLastN",
        "label": "repeatLastN",
        "type": "number",
        "optional": true,
        "description": "Sets how far back for the model to look back to prevent repetition. (Default: 64, 0 = disabled, -1 ="
      },
      {
        "id": "{nodeId}-input-repeatPenalty-number",
        "name": "repeatPenalty",
        "label": "repeatPenalty",
        "type": "number",
        "optional": true,
        "description": "Sets how strongly to penalize repetitions. A higher value (e.g., 1.5) will penalize repetitions more"
      },
      {
        "id": "{nodeId}-input-stop-string",
        "name": "stop",
        "label": "stop",
        "type": "string",
        "optional": true,
        "description": "Sets the stop sequences to use. Use comma to seperate different sequences. Refer to <a target=\"_blan"
      },
      {
        "id": "{nodeId}-input-tfsZ-number",
        "name": "tfsZ",
        "label": "tfsZ",
        "type": "number",
        "optional": true,
        "description": "Tail free sampling is used to reduce the impact of less probable tokens from the output. A higher va"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-chatOllama-ChatOllama|ChatOllama|BaseChatModel|BaseLanguageModel|Runnable",
        "name": "chatOllama",
        "label": "ChatOllama",
        "type": "ChatOllama | ChatOllama | BaseChatModel | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "5",
    "description": "Chat completion using open-source LLM on Ollama",
    "baseClasses": [
      "ChatOllama",
      "ChatOllama",
      "BaseChatModel",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "ollamaApi"
    ]
  },
  {
    "node_type": "chatOllama_LlamaIndex",
    "name": "chatOllama_LlamaIndex",
    "label": "ChatOllama",
    "category": "Chat Models",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-baseUrl-string",
        "name": "baseUrl",
        "label": "baseUrl",
        "type": "string",
        "optional": true,
        "default": "http://localhost:11434",
        "description": "Base URL"
      },
      {
        "id": "{nodeId}-input-modelName-string",
        "name": "modelName",
        "label": "modelName",
        "type": "string",
        "optional": true,
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.9",
        "description": "The temperature of the model. Increasing the temperature will make the model answer more creatively."
      },
      {
        "id": "{nodeId}-input-topP-number",
        "name": "topP",
        "label": "topP",
        "type": "number",
        "optional": true,
        "description": "Works together with top-k. A higher value (e.g., 0.95) will lead to more diverse text, while a lower"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Reduces the probability of generating nonsense. A higher value (e.g. 100) will give more diverse ans"
      },
      {
        "id": "{nodeId}-input-mirostat-number",
        "name": "mirostat",
        "label": "mirostat",
        "type": "number",
        "optional": true,
        "description": "Enable Mirostat sampling for controlling perplexity. (default: 0, 0 = disabled, 1 = Mirostat, 2 = Mi"
      },
      {
        "id": "{nodeId}-input-mirostatEta-number",
        "name": "mirostatEta",
        "label": "mirostatEta",
        "type": "number",
        "optional": true,
        "description": "Influences how quickly the algorithm responds to feedback from the generated text. A lower learning"
      },
      {
        "id": "{nodeId}-input-mirostatTau-number",
        "name": "mirostatTau",
        "label": "mirostatTau",
        "type": "number",
        "optional": true,
        "description": "Controls the balance between coherence and diversity of the output. A lower value will result in mor"
      },
      {
        "id": "{nodeId}-input-numCtx-number",
        "name": "numCtx",
        "label": "numCtx",
        "type": "number",
        "optional": true,
        "description": "Sets the size of the context window used to generate the next token. (Default: 2048) Refer to <a tar"
      },
      {
        "id": "{nodeId}-input-numGpu-number",
        "name": "numGpu",
        "label": "numGpu",
        "type": "number",
        "optional": true,
        "description": "The number of layers to send to the GPU(s). On macOS it defaults to 1 to enable metal support, 0 to"
      },
      {
        "id": "{nodeId}-input-numThread-number",
        "name": "numThread",
        "label": "numThread",
        "type": "number",
        "optional": true,
        "description": "Sets the number of threads to use during computation. By default, Ollama will detect this for optima"
      },
      {
        "id": "{nodeId}-input-repeatLastN-number",
        "name": "repeatLastN",
        "label": "repeatLastN",
        "type": "number",
        "optional": true,
        "description": "Sets how far back for the model to look back to prevent repetition. (Default: 64, 0 = disabled, -1 ="
      },
      {
        "id": "{nodeId}-input-repeatPenalty-number",
        "name": "repeatPenalty",
        "label": "repeatPenalty",
        "type": "number",
        "optional": true,
        "description": "Sets how strongly to penalize repetitions. A higher value (e.g., 1.5) will penalize repetitions more"
      },
      {
        "id": "{nodeId}-input-stop-string",
        "name": "stop",
        "label": "stop",
        "type": "string",
        "optional": true,
        "description": "Sets the stop sequences to use. Use comma to seperate different sequences. Refer to <a target=\"_blan"
      },
      {
        "id": "{nodeId}-input-tfsZ-number",
        "name": "tfsZ",
        "label": "tfsZ",
        "type": "number",
        "optional": true,
        "description": "Tail free sampling is used to reduce the impact of less probable tokens from the output. A higher va"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-chatOllama_LlamaIndex-ChatOllama|BaseChatModel_LlamaIndex|BaseEmbedding",
        "name": "chatOllama_LlamaIndex",
        "label": "ChatOllama",
        "type": "ChatOllama | BaseChatModel_LlamaIndex | BaseEmbedding"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Wrapper around ChatOllama LLM specific for LlamaIndex",
    "baseClasses": [
      "ChatOllama",
      "BaseChatModel_LlamaIndex",
      "BaseEmbedding"
    ]
  },
  {
    "node_type": "chatOpenAI",
    "name": "chatOpenAI",
    "label": "ChatOpenAI",
    "category": "Chat Models",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-imageResolution-options",
        "name": "imageResolution",
        "label": "imageResolution",
        "type": "options",
        "optional": false,
        "default": "low",
        "description": "This parameter controls the resolution in which the model views the image."
      },
      {
        "id": "{nodeId}-input-modelName-asyncOptions",
        "name": "modelName",
        "label": "modelName",
        "type": "asyncOptions",
        "optional": true,
        "default": "gpt-4o-mini",
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.9",
        "description": "Temperature"
      },
      {
        "id": "{nodeId}-input-allowImageUploads-boolean",
        "name": "allowImageUploads",
        "label": "allowImageUploads",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" tar"
      },
      {
        "id": "{nodeId}-input-streaming-boolean",
        "name": "streaming",
        "label": "streaming",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "Streaming"
      },
      {
        "id": "{nodeId}-input-maxTokens-number",
        "name": "maxTokens",
        "label": "maxTokens",
        "type": "number",
        "optional": true,
        "description": "Max Tokens"
      },
      {
        "id": "{nodeId}-input-topP-number",
        "name": "topP",
        "label": "topP",
        "type": "number",
        "optional": true,
        "description": "Top Probability"
      },
      {
        "id": "{nodeId}-input-frequencyPenalty-number",
        "name": "frequencyPenalty",
        "label": "frequencyPenalty",
        "type": "number",
        "optional": true,
        "description": "Frequency Penalty"
      },
      {
        "id": "{nodeId}-input-presencePenalty-number",
        "name": "presencePenalty",
        "label": "presencePenalty",
        "type": "number",
        "optional": true,
        "description": "Presence Penalty"
      },
      {
        "id": "{nodeId}-input-timeout-number",
        "name": "timeout",
        "label": "timeout",
        "type": "number",
        "optional": true,
        "description": "Timeout"
      },
      {
        "id": "{nodeId}-input-strictToolCalling-boolean",
        "name": "strictToolCalling",
        "label": "strictToolCalling",
        "type": "boolean",
        "optional": true,
        "description": "Whether the model supports the `strict` argument when passing in tools. If not specified, the `stric"
      },
      {
        "id": "{nodeId}-input-stopSequence-string",
        "name": "stopSequence",
        "label": "stopSequence",
        "type": "string",
        "optional": true,
        "description": "List of stop words to use when generating. Use comma to separate multiple stop words."
      },
      {
        "id": "{nodeId}-input-basepath-string",
        "name": "basepath",
        "label": "basepath",
        "type": "string",
        "optional": true,
        "description": "BasePath"
      },
      {
        "id": "{nodeId}-input-proxyUrl-string",
        "name": "proxyUrl",
        "label": "proxyUrl",
        "type": "string",
        "optional": true,
        "description": "Proxy Url"
      },
      {
        "id": "{nodeId}-input-baseOptions-json",
        "name": "baseOptions",
        "label": "baseOptions",
        "type": "json",
        "optional": true,
        "description": "BaseOptions"
      },
      {
        "id": "{nodeId}-input-reasoning-boolean",
        "name": "reasoning",
        "label": "reasoning",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Whether the model supports reasoning. Only applicable for reasoning models."
      },
      {
        "id": "{nodeId}-input-reasoningEffort-options",
        "name": "reasoningEffort",
        "label": "reasoningEffort",
        "type": "options",
        "optional": true,
        "description": "Constrains effort on reasoning for reasoning models"
      },
      {
        "id": "{nodeId}-input-reasoningSummary-options",
        "name": "reasoningSummary",
        "label": "reasoningSummary",
        "type": "options",
        "optional": true,
        "description": "A summary of the reasoning performed by the model. This can be useful for debugging and understandin"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-chatOpenAI-ChatOpenAI|BaseChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
        "name": "chatOpenAI",
        "label": "ChatOpenAI",
        "type": "ChatOpenAI | BaseChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "8.3",
    "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
    "baseClasses": [
      "ChatOpenAI",
      "BaseChatOpenAI",
      "BaseChatModel",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "openAIApi"
    ]
  },
  {
    "node_type": "chatOpenAICustom",
    "name": "chatOpenAICustom",
    "label": "ChatOpenAI Custom",
    "category": "Chat Models",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-string",
        "name": "modelName",
        "label": "modelName",
        "type": "string",
        "optional": true,
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.9",
        "description": "Temperature"
      },
      {
        "id": "{nodeId}-input-streaming-boolean",
        "name": "streaming",
        "label": "streaming",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "Streaming"
      },
      {
        "id": "{nodeId}-input-maxTokens-number",
        "name": "maxTokens",
        "label": "maxTokens",
        "type": "number",
        "optional": true,
        "description": "Max Tokens"
      },
      {
        "id": "{nodeId}-input-topP-number",
        "name": "topP",
        "label": "topP",
        "type": "number",
        "optional": true,
        "description": "Top Probability"
      },
      {
        "id": "{nodeId}-input-frequencyPenalty-number",
        "name": "frequencyPenalty",
        "label": "frequencyPenalty",
        "type": "number",
        "optional": true,
        "description": "Frequency Penalty"
      },
      {
        "id": "{nodeId}-input-presencePenalty-number",
        "name": "presencePenalty",
        "label": "presencePenalty",
        "type": "number",
        "optional": true,
        "description": "Presence Penalty"
      },
      {
        "id": "{nodeId}-input-timeout-number",
        "name": "timeout",
        "label": "timeout",
        "type": "number",
        "optional": true,
        "description": "Timeout"
      },
      {
        "id": "{nodeId}-input-basepath-string",
        "name": "basepath",
        "label": "basepath",
        "type": "string",
        "optional": true,
        "description": "BasePath"
      },
      {
        "id": "{nodeId}-input-baseOptions-json",
        "name": "baseOptions",
        "label": "baseOptions",
        "type": "json",
        "optional": true,
        "description": "BaseOptions"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-chatOpenAICustom-ChatOpenAI-Custom|BaseChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
        "name": "chatOpenAICustom",
        "label": "ChatOpenAI Custom",
        "type": "ChatOpenAI-Custom | BaseChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "4",
    "description": "Custom/FineTuned model using OpenAI Chat compatible API",
    "baseClasses": [
      "ChatOpenAI-Custom",
      "BaseChatOpenAI",
      "BaseChatModel",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "openAIApi"
    ]
  },
  {
    "node_type": "chatOpenAI_LlamaIndex",
    "name": "chatOpenAI_LlamaIndex",
    "label": "ChatOpenAI",
    "category": "Chat Models",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-asyncOptions",
        "name": "modelName",
        "label": "modelName",
        "type": "asyncOptions",
        "optional": true,
        "default": "gpt-3.5-turbo",
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.9",
        "description": "Temperature"
      },
      {
        "id": "{nodeId}-input-maxTokens-number",
        "name": "maxTokens",
        "label": "maxTokens",
        "type": "number",
        "optional": true,
        "description": "Max Tokens"
      },
      {
        "id": "{nodeId}-input-topP-number",
        "name": "topP",
        "label": "topP",
        "type": "number",
        "optional": true,
        "description": "Top Probability"
      },
      {
        "id": "{nodeId}-input-timeout-number",
        "name": "timeout",
        "label": "timeout",
        "type": "number",
        "optional": true,
        "description": "Timeout"
      },
      {
        "id": "{nodeId}-input-basepath-string",
        "name": "basepath",
        "label": "basepath",
        "type": "string",
        "optional": true,
        "description": "BasePath"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-chatOpenAI_LlamaIndex-ChatOpenAI|BaseChatModel_LlamaIndex|ToolCallLLM|BaseLLM",
        "name": "chatOpenAI_LlamaIndex",
        "label": "ChatOpenAI",
        "type": "ChatOpenAI | BaseChatModel_LlamaIndex | ToolCallLLM | BaseLLM"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Wrapper around OpenAI Chat LLM specific for LlamaIndex",
    "baseClasses": [
      "ChatOpenAI",
      "BaseChatModel_LlamaIndex",
      "ToolCallLLM",
      "BaseLLM"
    ],
    "credential_required": [
      "openAIApi"
    ]
  },
  {
    "node_type": "chatOpenRouter",
    "name": "chatOpenRouter",
    "label": "ChatOpenRouter",
    "category": "Chat Models",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-imageResolution-options",
        "name": "imageResolution",
        "label": "imageResolution",
        "type": "options",
        "optional": false,
        "default": "low",
        "description": "This parameter controls the resolution in which the model views the image."
      },
      {
        "id": "{nodeId}-input-modelName-string",
        "name": "modelName",
        "label": "modelName",
        "type": "string",
        "optional": true,
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.9",
        "description": "Temperature"
      },
      {
        "id": "{nodeId}-input-allowImageUploads-boolean",
        "name": "allowImageUploads",
        "label": "allowImageUploads",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" tar"
      },
      {
        "id": "{nodeId}-input-streaming-boolean",
        "name": "streaming",
        "label": "streaming",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "Streaming"
      },
      {
        "id": "{nodeId}-input-maxTokens-number",
        "name": "maxTokens",
        "label": "maxTokens",
        "type": "number",
        "optional": true,
        "description": "Max Tokens"
      },
      {
        "id": "{nodeId}-input-topP-number",
        "name": "topP",
        "label": "topP",
        "type": "number",
        "optional": true,
        "description": "Top Probability"
      },
      {
        "id": "{nodeId}-input-frequencyPenalty-number",
        "name": "frequencyPenalty",
        "label": "frequencyPenalty",
        "type": "number",
        "optional": true,
        "description": "Frequency Penalty"
      },
      {
        "id": "{nodeId}-input-presencePenalty-number",
        "name": "presencePenalty",
        "label": "presencePenalty",
        "type": "number",
        "optional": true,
        "description": "Presence Penalty"
      },
      {
        "id": "{nodeId}-input-timeout-number",
        "name": "timeout",
        "label": "timeout",
        "type": "number",
        "optional": true,
        "description": "Timeout"
      },
      {
        "id": "{nodeId}-input-basepath-string",
        "name": "basepath",
        "label": "basepath",
        "type": "string",
        "optional": true,
        "default": "https://openrouter.ai/api/v1",
        "description": "BasePath"
      },
      {
        "id": "{nodeId}-input-baseOptions-json",
        "name": "baseOptions",
        "label": "baseOptions",
        "type": "json",
        "optional": true,
        "description": "BaseOptions"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-chatOpenRouter-ChatOpenRouter|BaseChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
        "name": "chatOpenRouter",
        "label": "ChatOpenRouter",
        "type": "ChatOpenRouter | BaseChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Wrapper around Open Router Inference API",
    "baseClasses": [
      "ChatOpenRouter",
      "BaseChatOpenAI",
      "BaseChatModel",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "openRouterApi"
    ]
  },
  {
    "node_type": "chatPerplexity",
    "name": "chatPerplexity",
    "label": "ChatPerplexity",
    "category": "Chat Models",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-model-asyncOptions",
        "name": "model",
        "label": "model",
        "type": "asyncOptions",
        "optional": true,
        "default": "sonar",
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "1",
        "description": "Temperature"
      },
      {
        "id": "{nodeId}-input-maxTokens-number",
        "name": "maxTokens",
        "label": "maxTokens",
        "type": "number",
        "optional": true,
        "description": "Max Tokens"
      },
      {
        "id": "{nodeId}-input-topP-number",
        "name": "topP",
        "label": "topP",
        "type": "number",
        "optional": true,
        "description": "Top P"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Top K"
      },
      {
        "id": "{nodeId}-input-presencePenalty-number",
        "name": "presencePenalty",
        "label": "presencePenalty",
        "type": "number",
        "optional": true,
        "description": "Presence Penalty"
      },
      {
        "id": "{nodeId}-input-frequencyPenalty-number",
        "name": "frequencyPenalty",
        "label": "frequencyPenalty",
        "type": "number",
        "optional": true,
        "description": "Frequency Penalty"
      },
      {
        "id": "{nodeId}-input-streaming-boolean",
        "name": "streaming",
        "label": "streaming",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "Streaming"
      },
      {
        "id": "{nodeId}-input-timeout-number",
        "name": "timeout",
        "label": "timeout",
        "type": "number",
        "optional": true,
        "description": "Timeout"
      },
      {
        "id": "{nodeId}-input-proxyUrl-string",
        "name": "proxyUrl",
        "label": "proxyUrl",
        "type": "string",
        "optional": true,
        "description": "Proxy Url"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-chatPerplexity-ChatPerplexity|BaseChatModel|BaseLanguageModel|Runnable",
        "name": "chatPerplexity",
        "label": "ChatPerplexity",
        "type": "ChatPerplexity | BaseChatModel | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "0.1",
    "description": "Wrapper around Perplexity large language models that use the Chat endpoint",
    "baseClasses": [
      "ChatPerplexity",
      "BaseChatModel",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "perplexityApi"
    ]
  },
  {
    "node_type": "chatSambanova",
    "name": "chatSambanova",
    "label": "ChatSambanova",
    "category": "Chat Models",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-string",
        "name": "modelName",
        "label": "modelName",
        "type": "string",
        "optional": true,
        "default": "Meta-Llama-3.3-70B-Instruct",
        "description": "Model"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.9",
        "description": "Temperature"
      },
      {
        "id": "{nodeId}-input-streaming-boolean",
        "name": "streaming",
        "label": "streaming",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "Streaming"
      },
      {
        "id": "{nodeId}-input-basepath-string",
        "name": "basepath",
        "label": "basepath",
        "type": "string",
        "optional": true,
        "default": "htps://api.sambanova.ai/v1",
        "description": "BasePath"
      },
      {
        "id": "{nodeId}-input-baseOptions-json",
        "name": "baseOptions",
        "label": "baseOptions",
        "type": "json",
        "optional": true,
        "description": "BaseOptions"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-chatSambanova-ChatSambanova|BaseChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
        "name": "chatSambanova",
        "label": "ChatSambanova",
        "type": "ChatSambanova | BaseChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Wrapper around Sambanova Chat Endpoints",
    "baseClasses": [
      "ChatSambanova",
      "BaseChatOpenAI",
      "BaseChatModel",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "sambanovaApi"
    ]
  },
  {
    "node_type": "chatTogetherAI",
    "name": "chatTogetherAI",
    "label": "ChatTogetherAI",
    "category": "Chat Models",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-string",
        "name": "modelName",
        "label": "modelName",
        "type": "string",
        "optional": true,
        "description": "Refer to models page"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.9",
        "description": "Temperature"
      },
      {
        "id": "{nodeId}-input-streaming-boolean",
        "name": "streaming",
        "label": "streaming",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "Streaming"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-chatTogetherAI-ChatTogetherAI|ChatOpenAICompletions|BaseChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
        "name": "chatTogetherAI",
        "label": "ChatTogetherAI",
        "type": "ChatTogetherAI | ChatOpenAICompletions | BaseChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Wrapper around TogetherAI large language models",
    "baseClasses": [
      "ChatTogetherAI",
      "ChatOpenAICompletions",
      "BaseChatOpenAI",
      "BaseChatModel",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "togetherAIApi"
    ]
  },
  {
    "node_type": "chatTogetherAI_LlamaIndex",
    "name": "chatTogetherAI_LlamaIndex",
    "label": "ChatTogetherAI",
    "category": "Chat Models",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-string",
        "name": "modelName",
        "label": "modelName",
        "type": "string",
        "optional": true,
        "description": "Refer to models page"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.9",
        "description": "Temperature"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-chatTogetherAI_LlamaIndex-ChatTogetherAI|BaseChatModel_LlamaIndex|OpenAI|ToolCallLLM|BaseLLM",
        "name": "chatTogetherAI_LlamaIndex",
        "label": "ChatTogetherAI",
        "type": "ChatTogetherAI | BaseChatModel_LlamaIndex | OpenAI | ToolCallLLM | BaseLLM"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Wrapper around ChatTogetherAI LLM specific for LlamaIndex",
    "baseClasses": [
      "ChatTogetherAI",
      "BaseChatModel_LlamaIndex",
      "OpenAI",
      "ToolCallLLM",
      "BaseLLM"
    ],
    "credential_required": [
      "togetherAIApi"
    ]
  },
  {
    "node_type": "chatXAI",
    "name": "chatXAI",
    "label": "ChatXAI",
    "category": "Chat Models",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-string",
        "name": "modelName",
        "label": "modelName",
        "type": "string",
        "optional": true,
        "description": "Model"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.9",
        "description": "Temperature"
      },
      {
        "id": "{nodeId}-input-allowImageUploads-boolean",
        "name": "allowImageUploads",
        "label": "allowImageUploads",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" tar"
      },
      {
        "id": "{nodeId}-input-streaming-boolean",
        "name": "streaming",
        "label": "streaming",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "Streaming"
      },
      {
        "id": "{nodeId}-input-maxTokens-number",
        "name": "maxTokens",
        "label": "maxTokens",
        "type": "number",
        "optional": true,
        "description": "Max Tokens"
      },
      {
        "id": "{nodeId}-input-maxTokens-number",
        "name": "maxTokens",
        "label": "maxTokens",
        "type": "number",
        "optional": true,
        "description": "Max Tokens"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-chatXAI-ChatXAI|ChatXAI|ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
        "name": "chatXAI",
        "label": "ChatXAI",
        "type": "ChatXAI | ChatXAI | ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Wrapper around Grok from XAI",
    "baseClasses": [
      "ChatXAI",
      "ChatXAI",
      "ChatOpenAI",
      "BaseChatModel",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "xaiApi"
    ]
  },
  {
    "node_type": "cisChat",
    "name": "cisChat",
    "label": "[Experimental] CIS (Chat)",
    "category": "Chat Models",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-endpoint-string",
        "name": "endpoint",
        "label": "endpoint",
        "type": "string",
        "optional": true,
        "description": "Endpoint URL"
      },
      {
        "id": "{nodeId}-input-featureKey-string",
        "name": "featureKey",
        "label": "featureKey",
        "type": "string",
        "optional": true,
        "description": "Wd-PCA-Feature-Key header value (e.g., tiare.balbi, )"
      },
      {
        "id": "{nodeId}-input-model-string",
        "name": "model",
        "label": "model",
        "type": "string",
        "optional": true,
        "default": "gemini-1.5-pro-002",
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0",
        "description": "Temperature"
      },
      {
        "id": "{nodeId}-input-systemPrompt-string",
        "name": "systemPrompt",
        "label": "systemPrompt",
        "type": "string",
        "optional": true,
        "description": "System Prompt"
      },
      {
        "id": "{nodeId}-input-additionalHeaders-string",
        "name": "additionalHeaders",
        "label": "additionalHeaders",
        "type": "string",
        "optional": true,
        "description": "Additional headers in \"key1=value1,key2=value2\" format"
      },
      {
        "id": "{nodeId}-input-topP-number",
        "name": "topP",
        "label": "topP",
        "type": "number",
        "optional": true,
        "default": "0.98",
        "description": "Top P"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "default": "40",
        "description": "Top K"
      },
      {
        "id": "{nodeId}-input-maxOutputTokens-number",
        "name": "maxOutputTokens",
        "label": "maxOutputTokens",
        "type": "number",
        "optional": true,
        "default": "4096",
        "description": "Max Output Tokens"
      },
      {
        "id": "{nodeId}-input-candidateCount-number",
        "name": "candidateCount",
        "label": "candidateCount",
        "type": "number",
        "optional": true,
        "default": "1",
        "description": "Candidate Count"
      },
      {
        "id": "{nodeId}-input-provider-string",
        "name": "provider",
        "label": "provider",
        "type": "string",
        "optional": true,
        "default": "gcp",
        "description": "Provider"
      },
      {
        "id": "{nodeId}-input-predictionType-string",
        "name": "predictionType",
        "label": "predictionType",
        "type": "string",
        "optional": true,
        "default": "gcp-multimodal-v1",
        "description": "Prediction Type"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-cisChat-CISChat|BaseChatModel|BaseLanguageModel|Runnable",
        "name": "cisChat",
        "label": "[Experimental] CIS (Chat)",
        "type": "CISChat | BaseChatModel | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Chat with CIS inference endpoint (Gemini-compatible response mapping)",
    "baseClasses": [
      "CISChat",
      "BaseChatModel",
      "BaseLanguageModel",
      "Runnable"
    ]
  },
  {
    "node_type": "groqChat",
    "name": "groqChat",
    "label": "GroqChat",
    "category": "Chat Models",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-asyncOptions",
        "name": "modelName",
        "label": "modelName",
        "type": "asyncOptions",
        "optional": true,
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.9",
        "description": "Temperature"
      },
      {
        "id": "{nodeId}-input-streaming-boolean",
        "name": "streaming",
        "label": "streaming",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "Streaming"
      },
      {
        "id": "{nodeId}-input-maxTokens-number",
        "name": "maxTokens",
        "label": "maxTokens",
        "type": "number",
        "optional": true,
        "description": "Max Tokens"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-groqChat-GroqChat|BaseChatModel|BaseLanguageModel|Runnable",
        "name": "groqChat",
        "label": "GroqChat",
        "type": "GroqChat | BaseChatModel | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "4",
    "description": "Wrapper around Groq API with LPU Inference Engine",
    "baseClasses": [
      "GroqChat",
      "BaseChatModel",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "groqApi"
    ]
  },
  {
    "node_type": "S3",
    "name": "S3",
    "label": "S3",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-unstructuredAPIUrl-string",
        "name": "unstructuredAPIUrl",
        "label": "unstructuredAPIUrl",
        "type": "string",
        "optional": false,
        "description": "Your Unstructured.io URL. Read <a target=\"_blank\" href=\"https://unstructured-io.github.io/unstructur"
      },
      {
        "id": "{nodeId}-input-bucketName-string",
        "name": "bucketName",
        "label": "bucketName",
        "type": "string",
        "optional": true,
        "description": "Bucket"
      },
      {
        "id": "{nodeId}-input-keyName-string",
        "name": "keyName",
        "label": "keyName",
        "type": "string",
        "optional": true,
        "description": "The object key (or key name) that uniquely identifies object in an Amazon S3 bucket"
      },
      {
        "id": "{nodeId}-input-region-asyncOptions",
        "name": "region",
        "label": "region",
        "type": "asyncOptions",
        "optional": true,
        "default": "us-east-1",
        "description": "Region"
      },
      {
        "id": "{nodeId}-input-fileProcessingMethod-options",
        "name": "fileProcessingMethod",
        "label": "fileProcessingMethod",
        "type": "options",
        "optional": true,
        "default": "builtIn",
        "description": "File Processing Method"
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      },
      {
        "id": "{nodeId}-input-unstructuredAPIUrl-string",
        "name": "unstructuredAPIUrl",
        "label": "unstructuredAPIUrl",
        "type": "string",
        "optional": true,
        "description": "Your Unstructured.io URL. Read <a target=\"_blank\" href=\"https://unstructured-io.github.io/unstructur"
      },
      {
        "id": "{nodeId}-input-unstructuredAPIKey-password",
        "name": "unstructuredAPIKey",
        "label": "unstructuredAPIKey",
        "type": "password",
        "optional": true,
        "description": "Unstructured API KEY"
      },
      {
        "id": "{nodeId}-input-strategy-options",
        "name": "strategy",
        "label": "strategy",
        "type": "options",
        "optional": true,
        "default": "auto",
        "description": "The strategy to use for partitioning PDF/image. Options are fast, hi_res, auto. Default: auto."
      },
      {
        "id": "{nodeId}-input-encoding-string",
        "name": "encoding",
        "label": "encoding",
        "type": "string",
        "optional": true,
        "default": "utf-8",
        "description": "The encoding method used to decode the text input. Default: utf-8."
      },
      {
        "id": "{nodeId}-input-skipInferTableTypes-multiOptions",
        "name": "skipInferTableTypes",
        "label": "skipInferTableTypes",
        "type": "multiOptions",
        "optional": true,
        "default": "[\"pdf\", \"jpg\", \"png\"]",
        "description": "The document types that you want to skip table extraction with. Default: pdf, jpg, png."
      },
      {
        "id": "{nodeId}-input-hiResModelName-options",
        "name": "hiResModelName",
        "label": "hiResModelName",
        "type": "options",
        "optional": true,
        "default": "detectron2_onnx",
        "description": "The name of the inference model used when strategy is hi_res. Default: detectron2_onnx."
      },
      {
        "id": "{nodeId}-input-chunkingStrategy-options",
        "name": "chunkingStrategy",
        "label": "chunkingStrategy",
        "type": "options",
        "optional": true,
        "default": "by_title",
        "description": "Use one of the supported strategies to chunk the returned elements. When omitted, no chunking is per"
      },
      {
        "id": "{nodeId}-input-ocrLanguages-multiOptions",
        "name": "ocrLanguages",
        "label": "ocrLanguages",
        "type": "multiOptions",
        "optional": true,
        "description": "The languages to use for OCR. Note: Being depricated as languages is the new type. Pending langchain"
      },
      {
        "id": "{nodeId}-input-sourceIdKey-string",
        "name": "sourceIdKey",
        "label": "sourceIdKey",
        "type": "string",
        "optional": true,
        "default": "source",
        "description": "Key used to get the true source of document, to be compared against the record. Document metadata mu"
      },
      {
        "id": "{nodeId}-input-coordinates-boolean",
        "name": "coordinates",
        "label": "coordinates",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "If true, return coordinates for each element. Default: false."
      },
      {
        "id": "{nodeId}-input-xmlKeepTags-boolean",
        "name": "xmlKeepTags",
        "label": "xmlKeepTags",
        "type": "boolean",
        "optional": true,
        "description": "If True, will retain the XML tags in the output. Otherwise it will simply extract the text from with"
      },
      {
        "id": "{nodeId}-input-includePageBreaks-boolean",
        "name": "includePageBreaks",
        "label": "includePageBreaks",
        "type": "boolean",
        "optional": true,
        "description": "When true, the output will include page break elements when the filetype supports it."
      },
      {
        "id": "{nodeId}-input-multiPageSections-boolean",
        "name": "multiPageSections",
        "label": "multiPageSections",
        "type": "boolean",
        "optional": true,
        "description": "Whether to treat multi-page documents as separate sections."
      },
      {
        "id": "{nodeId}-input-combineUnderNChars-number",
        "name": "combineUnderNChars",
        "label": "combineUnderNChars",
        "type": "number",
        "optional": true,
        "description": "If chunking strategy is set, combine elements until a section reaches a length of n chars. Default:"
      },
      {
        "id": "{nodeId}-input-newAfterNChars-number",
        "name": "newAfterNChars",
        "label": "newAfterNChars",
        "type": "number",
        "optional": true,
        "description": "If chunking strategy is set, cut off new sections after reaching a length of n chars (soft max). val"
      },
      {
        "id": "{nodeId}-input-maxCharacters-number",
        "name": "maxCharacters",
        "label": "maxCharacters",
        "type": "number",
        "optional": true,
        "default": "500",
        "description": "If chunking strategy is set, cut off new sections after reaching a length of n chars (hard max). Def"
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-S3-Document",
        "name": "S3",
        "label": "S3",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "5",
    "description": "Load Data from S3 Buckets",
    "baseClasses": [
      "Document"
    ],
    "credential_required": [
      "awsApi"
    ]
  },
  {
    "node_type": "airtable",
    "name": "airtable",
    "label": "Airtable",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-baseId-string",
        "name": "baseId",
        "label": "baseId",
        "type": "string",
        "optional": true,
        "description": "If your table URL looks like: https://airtable.com/app11RobdGoX0YNsC/tblJdmvbrgizbYICO/viw9UrP77Id0C"
      },
      {
        "id": "{nodeId}-input-tableId-string",
        "name": "tableId",
        "label": "tableId",
        "type": "string",
        "optional": true,
        "description": "If your table URL looks like: https://airtable.com/app11RobdGoX0YNsC/tblJdmvbrgizbYICO/viw9UrP77Id0C"
      },
      {
        "id": "{nodeId}-input-viewId-string",
        "name": "viewId",
        "label": "viewId",
        "type": "string",
        "optional": true,
        "description": "If your view URL looks like: https://airtable.com/app11RobdGoX0YNsC/tblJdmvbrgizbYICO/viw9UrP77Id0CE"
      },
      {
        "id": "{nodeId}-input-fields-string",
        "name": "fields",
        "label": "fields",
        "type": "string",
        "optional": true,
        "description": "Comma-separated list of field names or IDs to include. If empty, then ALL fields are used. Use field"
      },
      {
        "id": "{nodeId}-input-returnAll-boolean",
        "name": "returnAll",
        "label": "returnAll",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "If all results should be returned or only up to a given limit"
      },
      {
        "id": "{nodeId}-input-limit-number",
        "name": "limit",
        "label": "limit",
        "type": "number",
        "optional": true,
        "default": "100",
        "description": "Number of results to return. Ignored when Return All is enabled."
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      },
      {
        "id": "{nodeId}-input-filterByFormula-string",
        "name": "filterByFormula",
        "label": "filterByFormula",
        "type": "string",
        "optional": true,
        "description": "A formula used to filter records. The formula will be evaluated for each record, and if the result i"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-airtable-Document",
        "name": "airtable",
        "label": "Airtable",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "3.02",
    "description": "Load data from Airtable table",
    "baseClasses": [
      "Document"
    ],
    "credential_required": [
      "airtableApi"
    ]
  },
  {
    "node_type": "apiLoader",
    "name": "apiLoader",
    "label": "API Loader",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-method-options",
        "name": "method",
        "label": "method",
        "type": "options",
        "optional": true,
        "description": "Method"
      },
      {
        "id": "{nodeId}-input-url-string",
        "name": "url",
        "label": "url",
        "type": "string",
        "optional": true,
        "description": "URL"
      },
      {
        "id": "{nodeId}-input-headers-json",
        "name": "headers",
        "label": "headers",
        "type": "json",
        "optional": true,
        "description": "Headers"
      },
      {
        "id": "{nodeId}-input-caFile-file",
        "name": "caFile",
        "label": "caFile",
        "type": "file",
        "optional": true,
        "description": "Please upload a SSL certificate file in either .pem or .crt"
      },
      {
        "id": "{nodeId}-input-body-json",
        "name": "body",
        "label": "body",
        "type": "json",
        "optional": true,
        "description": "JSON body for the POST request. If not specified, agent will try to figure out itself from AIPlugin"
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-apiLoader-Document",
        "name": "apiLoader",
        "label": "API Loader",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2.1",
    "description": "Load data from an API",
    "baseClasses": [
      "Document"
    ]
  },
  {
    "node_type": "apifyWebsiteContentCrawler",
    "name": "apifyWebsiteContentCrawler",
    "label": "Apify Website Content Crawler",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-urls-string",
        "name": "urls",
        "label": "urls",
        "type": "string",
        "optional": true,
        "description": "One or more URLs of pages where the crawler will start, separated by commas."
      },
      {
        "id": "{nodeId}-input-crawlerType-options",
        "name": "crawlerType",
        "label": "crawlerType",
        "type": "options",
        "optional": true,
        "default": "playwright:firefox",
        "description": "Select the crawling engine, see <a target=\"_blank\" href=\"https://apify.com/apify/website-content-cra"
      },
      {
        "id": "{nodeId}-input-maxCrawlDepth-number",
        "name": "maxCrawlDepth",
        "label": "maxCrawlDepth",
        "type": "number",
        "optional": true,
        "default": "1",
        "description": "Max crawling depth"
      },
      {
        "id": "{nodeId}-input-maxCrawlPages-number",
        "name": "maxCrawlPages",
        "label": "maxCrawlPages",
        "type": "number",
        "optional": true,
        "default": "3",
        "description": "Max crawl pages"
      },
      {
        "id": "{nodeId}-input-additionalInput-json",
        "name": "additionalInput",
        "label": "additionalInput",
        "type": "json",
        "optional": true,
        "default": "{}",
        "description": "For additional input options for the crawler see <a target=\"_blank\" href=\"https://apify.com/apify/we"
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-apifyWebsiteContentCrawler-Document",
        "name": "apifyWebsiteContentCrawler",
        "label": "Apify Website Content Crawler",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "3",
    "description": "Load data from Apify Website Content Crawler",
    "baseClasses": [
      "Document"
    ],
    "credential_required": [
      "apifyApi"
    ]
  },
  {
    "node_type": "braveSearchApiLoader",
    "name": "braveSearchApiLoader",
    "label": "BraveSearch API Document Loader",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-query-string",
        "name": "query",
        "label": "query",
        "type": "string",
        "optional": true,
        "description": "Query"
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-braveSearchApiLoader-Document",
        "name": "braveSearchApiLoader",
        "label": "BraveSearch API Document Loader",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Load and process data from BraveSearch results",
    "baseClasses": [
      "Document"
    ],
    "credential_required": [
      "braveSearchApi"
    ]
  },
  {
    "node_type": "cheerioWebScraper",
    "name": "cheerioWebScraper",
    "label": "Cheerio Web Scraper",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-url-string",
        "name": "url",
        "label": "url",
        "type": "string",
        "optional": true,
        "description": "URL"
      },
      {
        "id": "{nodeId}-input-relativeLinksMethod-options",
        "name": "relativeLinksMethod",
        "label": "relativeLinksMethod",
        "type": "options",
        "optional": true,
        "default": "webCrawl",
        "description": "Select a method to retrieve relative links"
      },
      {
        "id": "{nodeId}-input-limit-number",
        "name": "limit",
        "label": "limit",
        "type": "number",
        "optional": true,
        "default": "10",
        "description": "Only used when \"Get Relative Links Method\" is selected. Set 0 to retrieve all relative links, defaul"
      },
      {
        "id": "{nodeId}-input-selector-string",
        "name": "selector",
        "label": "selector",
        "type": "string",
        "optional": true,
        "description": "Specify a CSS selector to select the content to be extracted"
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-cheerioWebScraper-Document",
        "name": "cheerioWebScraper",
        "label": "Cheerio Web Scraper",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Load data from webpages",
    "baseClasses": [
      "Document"
    ]
  },
  {
    "node_type": "confluence",
    "name": "confluence",
    "label": "Confluence",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-baseUrl-string",
        "name": "baseUrl",
        "label": "baseUrl",
        "type": "string",
        "optional": true,
        "description": "Base URL"
      },
      {
        "id": "{nodeId}-input-spaceKey-string",
        "name": "spaceKey",
        "label": "spaceKey",
        "type": "string",
        "optional": true,
        "description": "Refer to <a target=\"_blank\" href=\"https://community.atlassian.com/t5/Confluence-questions/How-to-fin"
      },
      {
        "id": "{nodeId}-input-limit-number",
        "name": "limit",
        "label": "limit",
        "type": "number",
        "optional": true,
        "default": "0",
        "description": "Limit"
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-confluence-Document",
        "name": "confluence",
        "label": "Confluence",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Load data from a Confluence Document",
    "baseClasses": [
      "Document"
    ],
    "credential_required": [
      "confluenceCloudApi",
      "confluenceServerDCApi"
    ]
  },
  {
    "node_type": "csvFile",
    "name": "csvFile",
    "label": "Csv File",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-csvFile-file",
        "name": "csvFile",
        "label": "csvFile",
        "type": "file",
        "optional": true,
        "description": "Csv File"
      },
      {
        "id": "{nodeId}-input-columnName-string",
        "name": "columnName",
        "label": "columnName",
        "type": "string",
        "optional": true,
        "description": "Extracting a single column"
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-csvFile-Document",
        "name": "csvFile",
        "label": "Csv File",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "3",
    "description": "Load data from CSV files",
    "baseClasses": [
      "Document"
    ]
  },
  {
    "node_type": "customDocumentLoader",
    "name": "customDocumentLoader",
    "label": "Custom Document Loader",
    "category": "Document Loaders",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-functionInputVariables-json",
        "name": "functionInputVariables",
        "label": "functionInputVariables",
        "type": "json",
        "optional": true,
        "description": "Input variables can be used in the function with prefix $. For example: $var"
      },
      {
        "id": "{nodeId}-input-javascriptFunction-code",
        "name": "javascriptFunction",
        "label": "javascriptFunction",
        "type": "code",
        "optional": true,
        "description": "Must return an array of document objects containing metadata and pageContent if \"Document\" is select"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-customDocumentLoader-Document",
        "name": "customDocumentLoader",
        "label": "Custom Document Loader",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Custom function for loading documents",
    "baseClasses": [
      "Document"
    ]
  },
  {
    "node_type": "documentStore",
    "name": "documentStore",
    "label": "Document Store",
    "category": "Document Loaders",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-selectedStore-asyncOptions",
        "name": "selectedStore",
        "label": "selectedStore",
        "type": "asyncOptions",
        "optional": true,
        "description": "Select Store"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-documentStore-Document",
        "name": "documentStore",
        "label": "Document Store",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Load data from pre-configured document stores",
    "baseClasses": [
      "Document"
    ]
  },
  {
    "node_type": "docxFile",
    "name": "docxFile",
    "label": "Docx File",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-docxFile-file",
        "name": "docxFile",
        "label": "docxFile",
        "type": "file",
        "optional": true,
        "description": "Docx File"
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-docxFile-Document",
        "name": "docxFile",
        "label": "Docx File",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Load data from DOCX files",
    "baseClasses": [
      "Document"
    ]
  },
  {
    "node_type": "epubFile",
    "name": "epubFile",
    "label": "Epub File",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-epubFile-file",
        "name": "epubFile",
        "label": "epubFile",
        "type": "file",
        "optional": true,
        "description": "Epub File"
      },
      {
        "id": "{nodeId}-input-usage-options",
        "name": "usage",
        "label": "usage",
        "type": "options",
        "optional": true,
        "default": "perChapter",
        "description": "Usage"
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Metadata keys to omit, comma-separated"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-epubFile-Document",
        "name": "epubFile",
        "label": "Epub File",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Load data from EPUB files",
    "baseClasses": [
      "Document"
    ]
  },
  {
    "node_type": "figma",
    "name": "figma",
    "label": "Figma",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-fileKey-string",
        "name": "fileKey",
        "label": "fileKey",
        "type": "string",
        "optional": true,
        "description": "The file key can be read from any Figma file URL: https://www.figma.com/file/:key/:title. For exampl"
      },
      {
        "id": "{nodeId}-input-nodeIds-string",
        "name": "nodeIds",
        "label": "nodeIds",
        "type": "string",
        "optional": true,
        "description": "A list of Node IDs, seperated by comma. Refer to <a target=\"_blank\" href=\"https://www.figma.com/comm"
      },
      {
        "id": "{nodeId}-input-recursive-boolean",
        "name": "recursive",
        "label": "recursive",
        "type": "boolean",
        "optional": true,
        "description": "Recursive"
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-figma-Document",
        "name": "figma",
        "label": "Figma",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Load data from a Figma file",
    "baseClasses": [
      "Document"
    ],
    "credential_required": [
      "figmaApi"
    ]
  },
  {
    "node_type": "fileLoader",
    "name": "fileLoader",
    "label": "File Loader",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-file-file",
        "name": "file",
        "label": "file",
        "type": "file",
        "optional": true,
        "description": "File"
      },
      {
        "id": "{nodeId}-input-usage-options",
        "name": "usage",
        "label": "usage",
        "type": "options",
        "optional": true,
        "default": "perPage",
        "description": "Only when loading PDF files"
      },
      {
        "id": "{nodeId}-input-legacyBuild-boolean",
        "name": "legacyBuild",
        "label": "legacyBuild",
        "type": "boolean",
        "optional": true,
        "description": "Use legacy build for PDF compatibility issues"
      },
      {
        "id": "{nodeId}-input-pointerName-string",
        "name": "pointerName",
        "label": "pointerName",
        "type": "string",
        "optional": true,
        "description": "Only when loading JSONL files"
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-fileLoader-Document",
        "name": "fileLoader",
        "label": "File Loader",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "A generic file loader that can load different file types",
    "baseClasses": [
      "Document"
    ]
  },
  {
    "node_type": "fireCrawl",
    "name": "fireCrawl",
    "label": "FireCrawl",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-crawlerType-options",
        "name": "crawlerType",
        "label": "crawlerType",
        "type": "options",
        "optional": true,
        "default": "crawl",
        "description": "Type"
      },
      {
        "id": "{nodeId}-input-url-string",
        "name": "url",
        "label": "url",
        "type": "string",
        "optional": true,
        "description": "URL to be crawled/scraped/extracted"
      },
      {
        "id": "{nodeId}-input-searchQuery-string",
        "name": "searchQuery",
        "label": "searchQuery",
        "type": "string",
        "optional": true,
        "description": "Search query to find relevant content"
      },
      {
        "id": "{nodeId}-input-includeTags-string",
        "name": "includeTags",
        "label": "includeTags",
        "type": "string",
        "optional": true,
        "description": "Tags to include in the output. Use comma to separate multiple tags."
      },
      {
        "id": "{nodeId}-input-excludeTags-string",
        "name": "excludeTags",
        "label": "excludeTags",
        "type": "string",
        "optional": true,
        "description": "Tags to exclude from the output. Use comma to separate multiple tags."
      },
      {
        "id": "{nodeId}-input-onlyMainContent-boolean",
        "name": "onlyMainContent",
        "label": "onlyMainContent",
        "type": "boolean",
        "optional": true,
        "description": "Extract only the main content of the page"
      },
      {
        "id": "{nodeId}-input-limit-string",
        "name": "limit",
        "label": "limit",
        "type": "string",
        "optional": true,
        "default": "10000",
        "description": "Maximum number of pages to crawl"
      },
      {
        "id": "{nodeId}-input-includePaths-string",
        "name": "includePaths",
        "label": "includePaths",
        "type": "string",
        "optional": true,
        "description": "URL pathname regex patterns that include matching URLs in the crawl. Only the paths that match the s"
      },
      {
        "id": "{nodeId}-input-excludePaths-string",
        "name": "excludePaths",
        "label": "excludePaths",
        "type": "string",
        "optional": true,
        "description": "URL pathname regex patterns that exclude matching URLs from the crawl."
      },
      {
        "id": "{nodeId}-input-extractSchema-json",
        "name": "extractSchema",
        "label": "extractSchema",
        "type": "json",
        "optional": true,
        "description": "JSON schema for data extraction"
      },
      {
        "id": "{nodeId}-input-extractPrompt-string",
        "name": "extractPrompt",
        "label": "extractPrompt",
        "type": "string",
        "optional": true,
        "description": "Prompt for data extraction"
      },
      {
        "id": "{nodeId}-input-searchLimit-string",
        "name": "searchLimit",
        "label": "searchLimit",
        "type": "string",
        "optional": true,
        "default": "5",
        "description": "Maximum number of results to return"
      },
      {
        "id": "{nodeId}-input-searchLang-string",
        "name": "searchLang",
        "label": "searchLang",
        "type": "string",
        "optional": true,
        "default": "en",
        "description": "Language code for search results (e.g., en, es, fr)"
      },
      {
        "id": "{nodeId}-input-searchCountry-string",
        "name": "searchCountry",
        "label": "searchCountry",
        "type": "string",
        "optional": true,
        "default": "us",
        "description": "Country code for search results (e.g., us, uk, ca)"
      },
      {
        "id": "{nodeId}-input-searchTimeout-number",
        "name": "searchTimeout",
        "label": "searchTimeout",
        "type": "number",
        "optional": true,
        "default": "60000",
        "description": "Timeout in milliseconds for search operation"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-fireCrawl-Document",
        "name": "fireCrawl",
        "label": "FireCrawl",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "4",
    "description": "Load data from URL using FireCrawl",
    "baseClasses": [
      "Document"
    ],
    "credential_required": [
      "fireCrawlApi"
    ]
  },
  {
    "node_type": "folderFiles",
    "name": "folderFiles",
    "label": "Folder with Files",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-folderPath-string",
        "name": "folderPath",
        "label": "folderPath",
        "type": "string",
        "optional": true,
        "description": "Folder Path"
      },
      {
        "id": "{nodeId}-input-recursive-boolean",
        "name": "recursive",
        "label": "recursive",
        "type": "boolean",
        "optional": true,
        "description": "Recursive"
      },
      {
        "id": "{nodeId}-input-pdfUsage-options",
        "name": "pdfUsage",
        "label": "pdfUsage",
        "type": "options",
        "optional": true,
        "default": "perPage",
        "description": "Only when loading PDF files"
      },
      {
        "id": "{nodeId}-input-pointerName-string",
        "name": "pointerName",
        "label": "pointerName",
        "type": "string",
        "optional": true,
        "description": "Only when loading JSONL files"
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-folderFiles-Document",
        "name": "folderFiles",
        "label": "Folder with Files",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "4",
    "description": "Load data from folder with multiple files",
    "baseClasses": [
      "Document"
    ]
  },
  {
    "node_type": "gitbook",
    "name": "gitbook",
    "label": "GitBook",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-webPath-string",
        "name": "webPath",
        "label": "webPath",
        "type": "string",
        "optional": true,
        "description": "If want to load all paths from the GitBook provide only root path e.g.https://docs.gitbook.com/"
      },
      {
        "id": "{nodeId}-input-shouldLoadAllPaths-boolean",
        "name": "shouldLoadAllPaths",
        "label": "shouldLoadAllPaths",
        "type": "boolean",
        "optional": true,
        "description": "Load from all paths in a given GitBook"
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-gitbook-Document",
        "name": "gitbook",
        "label": "GitBook",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Load data from GitBook",
    "baseClasses": [
      "Document"
    ]
  },
  {
    "node_type": "github",
    "name": "github",
    "label": "Github",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-repoLink-string",
        "name": "repoLink",
        "label": "repoLink",
        "type": "string",
        "optional": true,
        "description": "Repo Link"
      },
      {
        "id": "{nodeId}-input-branch-string",
        "name": "branch",
        "label": "branch",
        "type": "string",
        "optional": true,
        "default": "main",
        "description": "Branch"
      },
      {
        "id": "{nodeId}-input-recursive-boolean",
        "name": "recursive",
        "label": "recursive",
        "type": "boolean",
        "optional": true,
        "description": "Recursive"
      },
      {
        "id": "{nodeId}-input-maxConcurrency-number",
        "name": "maxConcurrency",
        "label": "maxConcurrency",
        "type": "number",
        "optional": true,
        "description": "Max Concurrency"
      },
      {
        "id": "{nodeId}-input-githubBaseUrl-string",
        "name": "githubBaseUrl",
        "label": "githubBaseUrl",
        "type": "string",
        "optional": true,
        "description": "Custom Github Base Url (e.g. Enterprise)"
      },
      {
        "id": "{nodeId}-input-githubInstanceApi-string",
        "name": "githubInstanceApi",
        "label": "githubInstanceApi",
        "type": "string",
        "optional": true,
        "description": "Custom Github API Url (e.g. Enterprise)"
      },
      {
        "id": "{nodeId}-input-ignorePath-string",
        "name": "ignorePath",
        "label": "ignorePath",
        "type": "string",
        "optional": true,
        "description": "An array of paths to be ignored"
      },
      {
        "id": "{nodeId}-input-maxRetries-number",
        "name": "maxRetries",
        "label": "maxRetries",
        "type": "number",
        "optional": true,
        "description": "The maximum number of retries that can be made for a single call, with an exponential backoff betwee"
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-github-Document",
        "name": "github",
        "label": "Github",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "3",
    "description": "Load data from a GitHub repository",
    "baseClasses": [
      "Document"
    ],
    "credential_required": [
      "githubApi"
    ]
  },
  {
    "node_type": "googleDrive",
    "name": "googleDrive",
    "label": "Google Drive",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-selectedFiles-asyncMultiOptions",
        "name": "selectedFiles",
        "label": "selectedFiles",
        "type": "asyncMultiOptions",
        "optional": true,
        "description": "Select files from your Google Drive"
      },
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-folderId-string",
        "name": "folderId",
        "label": "folderId",
        "type": "string",
        "optional": true,
        "description": "Google Drive folder ID to load all files from (alternative to selecting specific files)"
      },
      {
        "id": "{nodeId}-input-fileTypes-multiOptions",
        "name": "fileTypes",
        "label": "fileTypes",
        "type": "multiOptions",
        "optional": true,
        "default": "['application/vnd.google-apps.document', 'application/vnd.google-apps.spreadsheet', 'application/vnd.google-apps.presentation', 'text/plain', 'application/pdf', 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'application/vnd.openxmlformats-officedocument.presentationml.pr",
        "description": "Types of files to load"
      },
      {
        "id": "{nodeId}-input-includeSubfolders-boolean",
        "name": "includeSubfolders",
        "label": "includeSubfolders",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Whether to include files from subfolders when loading from a folder"
      },
      {
        "id": "{nodeId}-input-includeSharedDrives-boolean",
        "name": "includeSharedDrives",
        "label": "includeSharedDrives",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Whether to include files from shared drives (Team Drives) that you have access to"
      },
      {
        "id": "{nodeId}-input-maxFiles-number",
        "name": "maxFiles",
        "label": "maxFiles",
        "type": "number",
        "optional": true,
        "default": "50",
        "description": "Maximum number of files to load (default: 50)"
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-googleDrive-Document",
        "name": "googleDrive",
        "label": "Google Drive",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Load documents from Google Drive files",
    "baseClasses": [
      "Document"
    ],
    "credential_required": [
      "googleDriveOAuth2"
    ]
  },
  {
    "node_type": "googleSheets",
    "name": "googleSheets",
    "label": "Google Sheets",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-spreadsheetIds-asyncMultiOptions",
        "name": "spreadsheetIds",
        "label": "spreadsheetIds",
        "type": "asyncMultiOptions",
        "optional": true,
        "description": "Select spreadsheet from your Google Drive"
      },
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-sheetNames-string",
        "name": "sheetNames",
        "label": "sheetNames",
        "type": "string",
        "optional": true,
        "description": "Comma-separated list of sheet names to load. If empty, loads all sheets."
      },
      {
        "id": "{nodeId}-input-range-string",
        "name": "range",
        "label": "range",
        "type": "string",
        "optional": true,
        "description": "Range to load (e.g., A1:E10). If empty, loads entire sheet."
      },
      {
        "id": "{nodeId}-input-includeHeaders-boolean",
        "name": "includeHeaders",
        "label": "includeHeaders",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "Whether to include the first row as headers"
      },
      {
        "id": "{nodeId}-input-valueRenderOption-options",
        "name": "valueRenderOption",
        "label": "valueRenderOption",
        "type": "options",
        "optional": true,
        "default": "FORMATTED_VALUE",
        "description": "How values should be represented in the output"
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-googleSheets-Document",
        "name": "googleSheets",
        "label": "Google Sheets",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Load data from Google Sheets as documents",
    "baseClasses": [
      "Document"
    ],
    "credential_required": [
      "googleSheetsOAuth2"
    ]
  },
  {
    "node_type": "jira",
    "name": "jira",
    "label": "Jira",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-host-string",
        "name": "host",
        "label": "host",
        "type": "string",
        "optional": true,
        "description": "Host"
      },
      {
        "id": "{nodeId}-input-projectKey-string",
        "name": "projectKey",
        "label": "projectKey",
        "type": "string",
        "optional": true,
        "default": "main",
        "description": "Project Key"
      },
      {
        "id": "{nodeId}-input-limitPerRequest-number",
        "name": "limitPerRequest",
        "label": "limitPerRequest",
        "type": "number",
        "optional": true,
        "description": "Limit per request"
      },
      {
        "id": "{nodeId}-input-createdAfter-string",
        "name": "createdAfter",
        "label": "createdAfter",
        "type": "string",
        "optional": true,
        "description": "Created after"
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-jira-Document",
        "name": "jira",
        "label": "Jira",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Load issues from Jira",
    "baseClasses": [
      "Document"
    ],
    "credential_required": [
      "jiraApi"
    ]
  },
  {
    "node_type": "jsonFile",
    "name": "jsonFile",
    "label": "Json File",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-jsonFile-file",
        "name": "jsonFile",
        "label": "jsonFile",
        "type": "file",
        "optional": true,
        "description": "Json File"
      },
      {
        "id": "{nodeId}-input-pointersName-string",
        "name": "pointersName",
        "label": "pointersName",
        "type": "string",
        "optional": true,
        "description": "Ex: { \"key\": \"value\" }, Pointer Extraction = \"key\", \"value\" will be extracted as pageContent of the"
      },
      {
        "id": "{nodeId}-input-separateByObject-boolean",
        "name": "separateByObject",
        "label": "separateByObject",
        "type": "boolean",
        "optional": true,
        "description": "If enabled and the file is a JSON Array, each JSON object will be extracted as a chunk"
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents. You can add metadata dynamically from th"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-jsonFile-Document",
        "name": "jsonFile",
        "label": "Json File",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "3.1",
    "description": "Load data from JSON files",
    "baseClasses": [
      "Document"
    ]
  },
  {
    "node_type": "jsonlinesFile",
    "name": "jsonlinesFile",
    "label": "Json Lines File",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-pointerName-string",
        "name": "pointerName",
        "label": "pointerName",
        "type": "string",
        "optional": false,
        "description": "Ex: { \"key\": \"value\" }, Pointer Extraction = \"key\", \"value\" will be extracted as pageContent of the"
      },
      {
        "id": "{nodeId}-input-jsonlinesFile-file",
        "name": "jsonlinesFile",
        "label": "jsonlinesFile",
        "type": "file",
        "optional": true,
        "description": "Jsonlines File"
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents. You can add metadata dynamically from th"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-jsonlinesFile-Document",
        "name": "jsonlinesFile",
        "label": "Json Lines File",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "3",
    "description": "Load data from JSON Lines files",
    "baseClasses": [
      "Document"
    ]
  },
  {
    "node_type": "microsoftExcel",
    "name": "microsoftExcel",
    "label": "Microsoft Excel",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-excelFile-file",
        "name": "excelFile",
        "label": "excelFile",
        "type": "file",
        "optional": true,
        "description": "Excel File"
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-microsoftExcel-Document",
        "name": "microsoftExcel",
        "label": "Microsoft Excel",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Load data from Microsoft Excel files",
    "baseClasses": [
      "Document"
    ]
  },
  {
    "node_type": "microsoftPowerpoint",
    "name": "microsoftPowerpoint",
    "label": "Microsoft PowerPoint",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-powerpointFile-file",
        "name": "powerpointFile",
        "label": "powerpointFile",
        "type": "file",
        "optional": true,
        "description": "PowerPoint File"
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-microsoftPowerpoint-Document",
        "name": "microsoftPowerpoint",
        "label": "Microsoft PowerPoint",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Load data from Microsoft PowerPoint files",
    "baseClasses": [
      "Document"
    ]
  },
  {
    "node_type": "microsoftWord",
    "name": "microsoftWord",
    "label": "Microsoft Word",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-docxFile-file",
        "name": "docxFile",
        "label": "docxFile",
        "type": "file",
        "optional": true,
        "description": "Word File"
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-microsoftWord-Document",
        "name": "microsoftWord",
        "label": "Microsoft Word",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Load data from Microsoft Word files",
    "baseClasses": [
      "Document"
    ]
  },
  {
    "node_type": "notionDB",
    "name": "notionDB",
    "label": "Notion Database",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-databaseId-string",
        "name": "databaseId",
        "label": "databaseId",
        "type": "string",
        "optional": true,
        "description": "If your URL looks like - https://www.notion.so/abcdefh?v=long_hash_2, then abcdefh is the database I"
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-notionDB-Document",
        "name": "notionDB",
        "label": "Notion Database",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Load data from Notion Database (each row is a separate document with all properties as metadata)",
    "baseClasses": [
      "Document"
    ],
    "credential_required": [
      "notionApi"
    ]
  },
  {
    "node_type": "notionFolder",
    "name": "notionFolder",
    "label": "Notion Folder",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-notionFolder-string",
        "name": "notionFolder",
        "label": "notionFolder",
        "type": "string",
        "optional": true,
        "description": "Get folder path"
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-notionFolder-Document",
        "name": "notionFolder",
        "label": "Notion Folder",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Load data from the exported and unzipped Notion folder",
    "baseClasses": [
      "Document"
    ]
  },
  {
    "node_type": "notionPage",
    "name": "notionPage",
    "label": "Notion Page",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-pageId-string",
        "name": "pageId",
        "label": "pageId",
        "type": "string",
        "optional": true,
        "description": "The last The 32 char hex in the url path. For example: https://www.notion.so/skarard/LangChain-Notio"
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-notionPage-Document",
        "name": "notionPage",
        "label": "Notion Page",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Load data from Notion Page (including child pages all as separate documents)",
    "baseClasses": [
      "Document"
    ],
    "credential_required": [
      "notionApi"
    ]
  },
  {
    "node_type": "oxylabs",
    "name": "oxylabs",
    "label": "Oxylabs",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": false,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-query-string",
        "name": "query",
        "label": "query",
        "type": "string",
        "optional": true,
        "description": "Website URL of query keyword."
      },
      {
        "id": "{nodeId}-input-source-options",
        "name": "source",
        "label": "source",
        "type": "options",
        "optional": true,
        "default": "universal",
        "description": "Target website to scrape."
      },
      {
        "id": "{nodeId}-input-geo_location-string",
        "name": "geo_location",
        "label": "geo_location",
        "type": "string",
        "optional": true,
        "description": "Sets the proxy's geo location to retrieve data. Check Oxylabs documentation for more details."
      },
      {
        "id": "{nodeId}-input-render-boolean",
        "name": "render",
        "label": "render",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Enables JavaScript rendering when set to true."
      },
      {
        "id": "{nodeId}-input-parse-boolean",
        "name": "parse",
        "label": "parse",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Returns parsed data when set to true, as long as a dedicated parser exists for the submitted URL's p"
      },
      {
        "id": "{nodeId}-input-user_agent_type-options",
        "name": "user_agent_type",
        "label": "user_agent_type",
        "type": "options",
        "optional": true,
        "description": "Device type and browser."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-oxylabs-Document",
        "name": "oxylabs",
        "label": "Oxylabs",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Extract data from URLs using Oxylabs",
    "baseClasses": [
      "Document"
    ],
    "credential_required": [
      "oxylabsApi"
    ]
  },
  {
    "node_type": "pdfFile",
    "name": "pdfFile",
    "label": "Pdf File",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-pdfFile-file",
        "name": "pdfFile",
        "label": "pdfFile",
        "type": "file",
        "optional": true,
        "description": "Pdf File"
      },
      {
        "id": "{nodeId}-input-usage-options",
        "name": "usage",
        "label": "usage",
        "type": "options",
        "optional": true,
        "default": "perPage",
        "description": "Usage"
      },
      {
        "id": "{nodeId}-input-legacyBuild-boolean",
        "name": "legacyBuild",
        "label": "legacyBuild",
        "type": "boolean",
        "optional": true,
        "description": "Use Legacy Build"
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-pdfFile-Document",
        "name": "pdfFile",
        "label": "Pdf File",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Load data from PDF files",
    "baseClasses": [
      "Document"
    ]
  },
  {
    "node_type": "plainText",
    "name": "plainText",
    "label": "Plain Text",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-text-string",
        "name": "text",
        "label": "text",
        "type": "string",
        "optional": true,
        "description": "Text"
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-plainText-Document",
        "name": "plainText",
        "label": "Plain Text",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Load data from plain text",
    "baseClasses": [
      "Document"
    ]
  },
  {
    "node_type": "playwrightWebScraper",
    "name": "playwrightWebScraper",
    "label": "Playwright Web Scraper",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-url-string",
        "name": "url",
        "label": "url",
        "type": "string",
        "optional": true,
        "description": "URL"
      },
      {
        "id": "{nodeId}-input-relativeLinksMethod-options",
        "name": "relativeLinksMethod",
        "label": "relativeLinksMethod",
        "type": "options",
        "optional": true,
        "default": "webCrawl",
        "description": "Select a method to retrieve relative links"
      },
      {
        "id": "{nodeId}-input-limit-number",
        "name": "limit",
        "label": "limit",
        "type": "number",
        "optional": true,
        "default": "10",
        "description": "Only used when \"Get Relative Links Method\" is selected. Set 0 to retrieve all relative links, defaul"
      },
      {
        "id": "{nodeId}-input-waitUntilGoToOption-options",
        "name": "waitUntilGoToOption",
        "label": "waitUntilGoToOption",
        "type": "options",
        "optional": true,
        "description": "Select a go to wait until option"
      },
      {
        "id": "{nodeId}-input-waitForSelector-string",
        "name": "waitForSelector",
        "label": "waitForSelector",
        "type": "string",
        "optional": true,
        "description": "CSS selectors like .div or #div"
      },
      {
        "id": "{nodeId}-input-cssSelector-string",
        "name": "cssSelector",
        "label": "cssSelector",
        "type": "string",
        "optional": true,
        "description": "Only content inside this selector will be extracted. Leave empty to use the entire page body."
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-playwrightWebScraper-Document",
        "name": "playwrightWebScraper",
        "label": "Playwright Web Scraper",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Load data from webpages",
    "baseClasses": [
      "Document"
    ]
  },
  {
    "node_type": "puppeteerWebScraper",
    "name": "puppeteerWebScraper",
    "label": "Puppeteer Web Scraper",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-url-string",
        "name": "url",
        "label": "url",
        "type": "string",
        "optional": true,
        "description": "URL"
      },
      {
        "id": "{nodeId}-input-relativeLinksMethod-options",
        "name": "relativeLinksMethod",
        "label": "relativeLinksMethod",
        "type": "options",
        "optional": true,
        "default": "webCrawl",
        "description": "Select a method to retrieve relative links"
      },
      {
        "id": "{nodeId}-input-limit-number",
        "name": "limit",
        "label": "limit",
        "type": "number",
        "optional": true,
        "default": "10",
        "description": "Only used when \"Get Relative Links Method\" is selected. Set 0 to retrieve all relative links, defaul"
      },
      {
        "id": "{nodeId}-input-waitUntilGoToOption-options",
        "name": "waitUntilGoToOption",
        "label": "waitUntilGoToOption",
        "type": "options",
        "optional": true,
        "description": "Select a go to wait until option"
      },
      {
        "id": "{nodeId}-input-waitForSelector-string",
        "name": "waitForSelector",
        "label": "waitForSelector",
        "type": "string",
        "optional": true,
        "description": "CSS selectors like .div or #div"
      },
      {
        "id": "{nodeId}-input-cssSelector-string",
        "name": "cssSelector",
        "label": "cssSelector",
        "type": "string",
        "optional": true,
        "description": "Only content inside this selector will be extracted. Leave empty to use the entire page body."
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-puppeteerWebScraper-Document",
        "name": "puppeteerWebScraper",
        "label": "Puppeteer Web Scraper",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Load data from webpages",
    "baseClasses": [
      "Document"
    ]
  },
  {
    "node_type": "s3Directory",
    "name": "s3Directory",
    "label": "S3 Directory",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-bucketName-string",
        "name": "bucketName",
        "label": "bucketName",
        "type": "string",
        "optional": true,
        "description": "Bucket"
      },
      {
        "id": "{nodeId}-input-region-asyncOptions",
        "name": "region",
        "label": "region",
        "type": "asyncOptions",
        "optional": true,
        "default": "us-east-1",
        "description": "Region"
      },
      {
        "id": "{nodeId}-input-serverUrl-string",
        "name": "serverUrl",
        "label": "serverUrl",
        "type": "string",
        "optional": true,
        "description": "The fully qualified endpoint of the webservice. This is only for using a custom endpoint (for exampl"
      },
      {
        "id": "{nodeId}-input-prefix-string",
        "name": "prefix",
        "label": "prefix",
        "type": "string",
        "optional": true,
        "description": "Limits the response to keys that begin with the specified prefix"
      },
      {
        "id": "{nodeId}-input-pdfUsage-options",
        "name": "pdfUsage",
        "label": "pdfUsage",
        "type": "options",
        "optional": true,
        "default": "perPage",
        "description": "Pdf Usage"
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-s3Directory-Document",
        "name": "s3Directory",
        "label": "S3 Directory",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "4",
    "description": "Load Data from S3 Buckets",
    "baseClasses": [
      "Document"
    ],
    "credential_required": [
      "awsApi"
    ]
  },
  {
    "node_type": "searchApi",
    "name": "searchApi",
    "label": "SearchApi For Web Search",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-query-string",
        "name": "query",
        "label": "query",
        "type": "string",
        "optional": true,
        "description": "Query"
      },
      {
        "id": "{nodeId}-input-customParameters-json",
        "name": "customParameters",
        "label": "customParameters",
        "type": "json",
        "optional": true,
        "description": "Custom Parameters"
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-searchApi-Document",
        "name": "searchApi",
        "label": "SearchApi For Web Search",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Load data from real-time search results",
    "baseClasses": [
      "Document"
    ],
    "credential_required": [
      "searchApi"
    ]
  },
  {
    "node_type": "serpApi",
    "name": "serpApi",
    "label": "SerpApi For Web Search",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-query-string",
        "name": "query",
        "label": "query",
        "type": "string",
        "optional": true,
        "description": "Query"
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-serpApi-Document",
        "name": "serpApi",
        "label": "SerpApi For Web Search",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Load and process data from web search results",
    "baseClasses": [
      "Document"
    ],
    "credential_required": [
      "serpApi"
    ]
  },
  {
    "node_type": "spiderDocumentLoaders",
    "name": "spiderDocumentLoaders",
    "label": "Spider Document Loaders",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-mode-options",
        "name": "mode",
        "label": "mode",
        "type": "options",
        "optional": true,
        "default": "scrape",
        "description": "Mode"
      },
      {
        "id": "{nodeId}-input-url-string",
        "name": "url",
        "label": "url",
        "type": "string",
        "optional": true,
        "description": "Web Page URL"
      },
      {
        "id": "{nodeId}-input-limit-number",
        "name": "limit",
        "label": "limit",
        "type": "number",
        "optional": true,
        "default": "25",
        "description": "Limit"
      },
      {
        "id": "{nodeId}-input-additional_metadata-json",
        "name": "additional_metadata",
        "label": "additional_metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents"
      },
      {
        "id": "{nodeId}-input-params-json",
        "name": "params",
        "label": "params",
        "type": "json",
        "optional": true,
        "description": "Find all the available parameters in the Spi"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-spiderDocumentLoaders-Document",
        "name": "spiderDocumentLoaders",
        "label": "Spider Document Loaders",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Scrape & Crawl the web with Spider",
    "baseClasses": [
      "Document"
    ],
    "credential_required": [
      "spiderApi"
    ]
  },
  {
    "node_type": "textFile",
    "name": "textFile",
    "label": "Text File",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-textSplitter-TextSplitter",
        "name": "textSplitter",
        "label": "textSplitter",
        "type": "TextSplitter",
        "optional": true,
        "description": "Text Splitter"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-txtFile-file",
        "name": "txtFile",
        "label": "txtFile",
        "type": "file",
        "optional": true,
        "description": "Txt File"
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-textFile-Document",
        "name": "textFile",
        "label": "Text File",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "3",
    "description": "Load data from text files",
    "baseClasses": [
      "Document"
    ]
  },
  {
    "node_type": "unstructuredFileLoader",
    "name": "unstructuredFileLoader",
    "label": "Unstructured File Loader",
    "category": "Document Loaders",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-unstructuredAPIUrl-string",
        "name": "unstructuredAPIUrl",
        "label": "unstructuredAPIUrl",
        "type": "string",
        "optional": false,
        "description": "Unstructured API URL. Read <a target=\"_blank\" href=\"https://docs.unstructured.io/api-reference/api-s"
      },
      {
        "id": "{nodeId}-input-fileObject-file",
        "name": "fileObject",
        "label": "fileObject",
        "type": "file",
        "optional": true,
        "description": "Files to be processed. Multiple files can be uploaded."
      },
      {
        "id": "{nodeId}-input-strategy-options",
        "name": "strategy",
        "label": "strategy",
        "type": "options",
        "optional": true,
        "default": "auto",
        "description": "The strategy to use for partitioning PDF/image. Options are fast, hi_res, auto. Default: auto."
      },
      {
        "id": "{nodeId}-input-encoding-string",
        "name": "encoding",
        "label": "encoding",
        "type": "string",
        "optional": true,
        "default": "utf-8",
        "description": "The encoding method used to decode the text input. Default: utf-8."
      },
      {
        "id": "{nodeId}-input-skipInferTableTypes-multiOptions",
        "name": "skipInferTableTypes",
        "label": "skipInferTableTypes",
        "type": "multiOptions",
        "optional": true,
        "default": "[\"pdf\", \"jpg\", \"png\"]",
        "description": "The document types that you want to skip table extraction with. Default: pdf, jpg, png."
      },
      {
        "id": "{nodeId}-input-hiResModelName-options",
        "name": "hiResModelName",
        "label": "hiResModelName",
        "type": "options",
        "optional": true,
        "description": "The name of the inference model used when strategy is hi_res"
      },
      {
        "id": "{nodeId}-input-chunkingStrategy-options",
        "name": "chunkingStrategy",
        "label": "chunkingStrategy",
        "type": "options",
        "optional": true,
        "default": "by_title",
        "description": "Use one of the supported strategies to chunk the returned elements. When omitted, no chunking is per"
      },
      {
        "id": "{nodeId}-input-ocrLanguages-multiOptions",
        "name": "ocrLanguages",
        "label": "ocrLanguages",
        "type": "multiOptions",
        "optional": true,
        "description": "The languages to use for OCR. Note: Being depricated as languages is the new type. Pending langchain"
      },
      {
        "id": "{nodeId}-input-sourceIdKey-string",
        "name": "sourceIdKey",
        "label": "sourceIdKey",
        "type": "string",
        "optional": true,
        "default": "source",
        "description": "Key used to get the true source of document, to be compared against the record. Document metadata mu"
      },
      {
        "id": "{nodeId}-input-coordinates-boolean",
        "name": "coordinates",
        "label": "coordinates",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "If true, return coordinates for each element. Default: false."
      },
      {
        "id": "{nodeId}-input-xmlKeepTags-boolean",
        "name": "xmlKeepTags",
        "label": "xmlKeepTags",
        "type": "boolean",
        "optional": true,
        "description": "If True, will retain the XML tags in the output. Otherwise it will simply extract the text from with"
      },
      {
        "id": "{nodeId}-input-includePageBreaks-boolean",
        "name": "includePageBreaks",
        "label": "includePageBreaks",
        "type": "boolean",
        "optional": true,
        "description": "When true, the output will include page break elements when the filetype supports it."
      },
      {
        "id": "{nodeId}-input-xmlKeepTags-boolean",
        "name": "xmlKeepTags",
        "label": "xmlKeepTags",
        "type": "boolean",
        "optional": true,
        "description": "Whether to keep XML tags in the output."
      },
      {
        "id": "{nodeId}-input-multiPageSections-boolean",
        "name": "multiPageSections",
        "label": "multiPageSections",
        "type": "boolean",
        "optional": true,
        "description": "Whether to treat multi-page documents as separate sections."
      },
      {
        "id": "{nodeId}-input-combineUnderNChars-number",
        "name": "combineUnderNChars",
        "label": "combineUnderNChars",
        "type": "number",
        "optional": true,
        "description": "If chunking strategy is set, combine elements until a section reaches a length of n chars. Default:"
      },
      {
        "id": "{nodeId}-input-newAfterNChars-number",
        "name": "newAfterNChars",
        "label": "newAfterNChars",
        "type": "number",
        "optional": true,
        "description": "If chunking strategy is set, cut off new sections after reaching a length of n chars (soft max). val"
      },
      {
        "id": "{nodeId}-input-maxCharacters-number",
        "name": "maxCharacters",
        "label": "maxCharacters",
        "type": "number",
        "optional": true,
        "default": "500",
        "description": "If chunking strategy is set, cut off new sections after reaching a length of n chars (hard max). Def"
      },
      {
        "id": "{nodeId}-input-metadata-json",
        "name": "metadata",
        "label": "metadata",
        "type": "json",
        "optional": true,
        "description": "Additional metadata to be added to the extracted documents"
      },
      {
        "id": "{nodeId}-input-omitMetadataKeys-string",
        "name": "omitMetadataKeys",
        "label": "omitMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Each document loader comes with a default set of metadata keys that are extracted from the document."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-unstructuredFileLoader-Document",
        "name": "unstructuredFileLoader",
        "label": "Unstructured File Loader",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "4",
    "description": "Use Unstructured.io to load data from a file path",
    "baseClasses": [
      "Document"
    ],
    "credential_required": [
      "unstructuredApi"
    ]
  },
  {
    "node_type": "vectorStoreToDocument",
    "name": "vectorStoreToDocument",
    "label": "VectorStore To Document",
    "category": "Document Loaders",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-vectorStore-VectorStore",
        "name": "vectorStore",
        "label": "vectorStore",
        "type": "VectorStore",
        "optional": true,
        "description": "Vector Store"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-query-string",
        "name": "query",
        "label": "query",
        "type": "string",
        "optional": true,
        "description": "Query to retrieve documents from vector database. If not specified, user question will be used"
      },
      {
        "id": "{nodeId}-input-minScore-number",
        "name": "minScore",
        "label": "minScore",
        "type": "number",
        "optional": true,
        "description": "Minumum score for embeddings documents to be included"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-vectorStoreToDocument-Document",
        "name": "vectorStoreToDocument",
        "label": "VectorStore To Document",
        "type": "Document"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Search documents with scores from vector store",
    "baseClasses": [
      "Document"
    ]
  },
  {
    "node_type": "AWSBedrockEmbeddings",
    "name": "AWSBedrockEmbeddings",
    "label": "AWS Bedrock Embeddings",
    "category": "Embeddings",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-region-asyncOptions",
        "name": "region",
        "label": "region",
        "type": "asyncOptions",
        "optional": true,
        "default": "us-east-1",
        "description": "Region"
      },
      {
        "id": "{nodeId}-input-model-asyncOptions",
        "name": "model",
        "label": "model",
        "type": "asyncOptions",
        "optional": true,
        "default": "amazon.titan-embed-text-v1",
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-customModel-string",
        "name": "customModel",
        "label": "customModel",
        "type": "string",
        "optional": true,
        "description": "If provided, will override model selected from Model Name option"
      },
      {
        "id": "{nodeId}-input-inputType-options",
        "name": "inputType",
        "label": "inputType",
        "type": "options",
        "optional": true,
        "description": "Specifies the type of input passed to the model. Required for cohere embedding models v3 and higher."
      },
      {
        "id": "{nodeId}-input-batchSize-number",
        "name": "batchSize",
        "label": "batchSize",
        "type": "number",
        "optional": true,
        "default": "50",
        "description": "Documents batch size to send to AWS API for Titan model embeddings. Used to avoid throttling."
      },
      {
        "id": "{nodeId}-input-maxRetries-number",
        "name": "maxRetries",
        "label": "maxRetries",
        "type": "number",
        "optional": true,
        "default": "5",
        "description": "This will limit the number of AWS API for Titan model embeddings call retries. Used to avoid throttl"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-AWSBedrockEmbeddings-AWSBedrockEmbeddings|Embeddings",
        "name": "AWSBedrockEmbeddings",
        "label": "AWS Bedrock Embeddings",
        "type": "AWSBedrockEmbeddings | Embeddings"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "5",
    "description": "AWSBedrock embedding models to generate embeddings for a given text",
    "baseClasses": [
      "AWSBedrockEmbeddings",
      "Embeddings"
    ],
    "credential_required": [
      "awsApi"
    ]
  },
  {
    "node_type": "azureOpenAIEmbeddings",
    "name": "azureOpenAIEmbeddings",
    "label": "Azure OpenAI Embeddings",
    "category": "Embeddings",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-batchSize-number",
        "name": "batchSize",
        "label": "batchSize",
        "type": "number",
        "optional": true,
        "default": "100",
        "description": "Batch Size"
      },
      {
        "id": "{nodeId}-input-timeout-number",
        "name": "timeout",
        "label": "timeout",
        "type": "number",
        "optional": true,
        "description": "Timeout"
      },
      {
        "id": "{nodeId}-input-basepath-string",
        "name": "basepath",
        "label": "basepath",
        "type": "string",
        "optional": true,
        "description": "BasePath"
      },
      {
        "id": "{nodeId}-input-baseOptions-json",
        "name": "baseOptions",
        "label": "baseOptions",
        "type": "json",
        "optional": true,
        "description": "BaseOptions"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-azureOpenAIEmbeddings-AzureOpenAIEmbeddings|OpenAIEmbeddings|Embeddings",
        "name": "azureOpenAIEmbeddings",
        "label": "Azure OpenAI Embeddings",
        "type": "AzureOpenAIEmbeddings | OpenAIEmbeddings | Embeddings"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Azure OpenAI API to generate embeddings for a given text",
    "baseClasses": [
      "AzureOpenAIEmbeddings",
      "OpenAIEmbeddings",
      "Embeddings"
    ],
    "credential_required": [
      "azureOpenAIApi"
    ]
  },
  {
    "node_type": "azureOpenAIEmbeddingsLlamaIndex",
    "name": "azureOpenAIEmbeddingsLlamaIndex",
    "label": "Azure OpenAI Embeddings",
    "category": "Embeddings",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-timeout-number",
        "name": "timeout",
        "label": "timeout",
        "type": "number",
        "optional": true,
        "description": "Timeout"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-azureOpenAIEmbeddingsLlamaIndex-AzureOpenAIEmbeddings|BaseEmbedding_LlamaIndex|BaseEmbedding",
        "name": "azureOpenAIEmbeddingsLlamaIndex",
        "label": "Azure OpenAI Embeddings",
        "type": "AzureOpenAIEmbeddings | BaseEmbedding_LlamaIndex | BaseEmbedding"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Azure OpenAI API embeddings specific for LlamaIndex",
    "baseClasses": [
      "AzureOpenAIEmbeddings",
      "BaseEmbedding_LlamaIndex",
      "BaseEmbedding"
    ],
    "credential_required": [
      "azureOpenAIApi"
    ]
  },
  {
    "node_type": "cohereEmbeddings",
    "name": "cohereEmbeddings",
    "label": "Cohere Embeddings",
    "category": "Embeddings",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-asyncOptions",
        "name": "modelName",
        "label": "modelName",
        "type": "asyncOptions",
        "optional": true,
        "default": "embed-english-v2.0",
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-inputType-options",
        "name": "inputType",
        "label": "inputType",
        "type": "options",
        "optional": true,
        "default": "search_query",
        "description": "Specifies the type of input passed to the model. Required for embedding models v3 and higher. <a tar"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-cohereEmbeddings-CohereEmbeddings|Embeddings",
        "name": "cohereEmbeddings",
        "label": "Cohere Embeddings",
        "type": "CohereEmbeddings | Embeddings"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "3",
    "description": "Cohere API to generate embeddings for a given text",
    "baseClasses": [
      "CohereEmbeddings",
      "Embeddings"
    ],
    "credential_required": [
      "cohereApi"
    ]
  },
  {
    "node_type": "googleGenerativeAiEmbeddings",
    "name": "googleGenerativeAiEmbeddings",
    "label": "GoogleGenerativeAI Embeddings",
    "category": "Embeddings",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-asyncOptions",
        "name": "modelName",
        "label": "modelName",
        "type": "asyncOptions",
        "optional": true,
        "default": "embedding-001",
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-tasktype-options",
        "name": "tasktype",
        "label": "tasktype",
        "type": "options",
        "optional": true,
        "default": "TASK_TYPE_UNSPECIFIED",
        "description": "Type of task for which the embedding will be used"
      },
      {
        "id": "{nodeId}-input-stripNewLines-boolean",
        "name": "stripNewLines",
        "label": "stripNewLines",
        "type": "boolean",
        "optional": true,
        "description": "Remove new lines from input text before embedding to reduce token count"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-googleGenerativeAiEmbeddings-GoogleGenerativeAiEmbeddings|GoogleGenerativeAIEmbeddings|Embeddings",
        "name": "googleGenerativeAiEmbeddings",
        "label": "GoogleGenerativeAI Embeddings",
        "type": "GoogleGenerativeAiEmbeddings | GoogleGenerativeAIEmbeddings | Embeddings"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Google Generative API to generate embeddings for a given text",
    "baseClasses": [
      "GoogleGenerativeAiEmbeddings",
      "GoogleGenerativeAIEmbeddings",
      "Embeddings"
    ],
    "credential_required": [
      "googleGenerativeAI"
    ]
  },
  {
    "node_type": "googlevertexaiEmbeddings",
    "name": "googlevertexaiEmbeddings",
    "label": "GoogleVertexAI Embeddings",
    "category": "Embeddings",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-asyncOptions",
        "name": "modelName",
        "label": "modelName",
        "type": "asyncOptions",
        "optional": true,
        "default": "text-embedding-004",
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-region-asyncOptions",
        "name": "region",
        "label": "region",
        "type": "asyncOptions",
        "optional": true,
        "description": "Region to use for the model."
      },
      {
        "id": "{nodeId}-input-stripNewLines-boolean",
        "name": "stripNewLines",
        "label": "stripNewLines",
        "type": "boolean",
        "optional": true,
        "description": "Remove new lines from input text before embedding to reduce token count"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-googlevertexaiEmbeddings-GoogleVertexAIEmbeddings|VertexAIEmbeddings|GoogleEmbeddings|BaseGoogleEmbeddings|Embeddings",
        "name": "googlevertexaiEmbeddings",
        "label": "GoogleVertexAI Embeddings",
        "type": "GoogleVertexAIEmbeddings | VertexAIEmbeddings | GoogleEmbeddings | BaseGoogleEmbeddings | Embeddings"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2.1",
    "description": "Google vertexAI API to generate embeddings for a given text",
    "baseClasses": [
      "GoogleVertexAIEmbeddings",
      "VertexAIEmbeddings",
      "GoogleEmbeddings",
      "BaseGoogleEmbeddings",
      "Embeddings"
    ],
    "credential_required": [
      "googleVertexAuth"
    ]
  },
  {
    "node_type": "huggingFaceInferenceEmbeddings",
    "name": "huggingFaceInferenceEmbeddings",
    "label": "HuggingFace Inference Embeddings",
    "category": "Embeddings",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-string",
        "name": "modelName",
        "label": "modelName",
        "type": "string",
        "optional": true,
        "description": "If using own inference endpoint, leave this blank"
      },
      {
        "id": "{nodeId}-input-endpoint-string",
        "name": "endpoint",
        "label": "endpoint",
        "type": "string",
        "optional": true,
        "description": "Using your own inference endpoint"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-huggingFaceInferenceEmbeddings-HuggingFaceInferenceEmbeddings|Embeddings",
        "name": "huggingFaceInferenceEmbeddings",
        "label": "HuggingFace Inference Embeddings",
        "type": "HuggingFaceInferenceEmbeddings | Embeddings"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "HuggingFace Inference API to generate embeddings for a given text",
    "baseClasses": [
      "HuggingFaceInferenceEmbeddings",
      "Embeddings"
    ],
    "credential_required": [
      "huggingFaceApi"
    ]
  },
  {
    "node_type": "ibmEmbedding",
    "name": "ibmEmbedding",
    "label": "IBM Watsonx Embeddings",
    "category": "Embeddings",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-string",
        "name": "modelName",
        "label": "modelName",
        "type": "string",
        "optional": true,
        "default": "ibm/slate-30m-english-rtrvr",
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-truncateInputTokens-number",
        "name": "truncateInputTokens",
        "label": "truncateInputTokens",
        "type": "number",
        "optional": true,
        "description": "Truncate the input tokens."
      },
      {
        "id": "{nodeId}-input-maxRetries-number",
        "name": "maxRetries",
        "label": "maxRetries",
        "type": "number",
        "optional": true,
        "description": "The maximum number of retries."
      },
      {
        "id": "{nodeId}-input-maxConcurrency-number",
        "name": "maxConcurrency",
        "label": "maxConcurrency",
        "type": "number",
        "optional": true,
        "description": "The maximum number of concurrencies."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-ibmEmbedding-WatsonxEmbeddings|Embeddings",
        "name": "ibmEmbedding",
        "label": "IBM Watsonx Embeddings",
        "type": "WatsonxEmbeddings | Embeddings"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Generate embeddings for a given text using open source model on IBM Watsonx",
    "baseClasses": [
      "WatsonxEmbeddings",
      "Embeddings"
    ],
    "credential_required": [
      "ibmWatsonx"
    ]
  },
  {
    "node_type": "jinaEmbeddings",
    "name": "jinaEmbeddings",
    "label": "Jina Embeddings",
    "category": "Embeddings",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-string",
        "name": "modelName",
        "label": "modelName",
        "type": "string",
        "optional": true,
        "default": "jina-embeddings-v3",
        "description": "Refer to JinaAI documentation for availabl"
      },
      {
        "id": "{nodeId}-input-modelDimensions-number",
        "name": "modelDimensions",
        "label": "modelDimensions",
        "type": "number",
        "optional": true,
        "default": "1024",
        "description": "Refer to JinaAI documentation for availabl"
      },
      {
        "id": "{nodeId}-input-allowLateChunking-boolean",
        "name": "allowLateChunking",
        "label": "allowLateChunking",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Refer to JinaAI documentation guidance on"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-jinaEmbeddings-JinaEmbeddings|Embeddings",
        "name": "jinaEmbeddings",
        "label": "Jina Embeddings",
        "type": "JinaEmbeddings | Embeddings"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "3",
    "description": "JinaAI API to generate embeddings for a given text",
    "baseClasses": [
      "JinaEmbeddings",
      "Embeddings"
    ],
    "credential_required": [
      "jinaAIApi"
    ]
  },
  {
    "node_type": "localAIEmbeddings",
    "name": "localAIEmbeddings",
    "label": "LocalAI Embeddings",
    "category": "Embeddings",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-basePath-string",
        "name": "basePath",
        "label": "basePath",
        "type": "string",
        "optional": true,
        "description": "Base Path"
      },
      {
        "id": "{nodeId}-input-modelName-string",
        "name": "modelName",
        "label": "modelName",
        "type": "string",
        "optional": true,
        "description": "Model Name"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-localAIEmbeddings-LocalAI Embeddings|Embeddings",
        "name": "localAIEmbeddings",
        "label": "LocalAI Embeddings",
        "type": "LocalAI Embeddings | Embeddings"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Use local embeddings models like llama.cpp",
    "baseClasses": [
      "LocalAI Embeddings",
      "Embeddings"
    ],
    "credential_required": [
      "localAIApi"
    ]
  },
  {
    "node_type": "mistralAIEmbeddings",
    "name": "mistralAIEmbeddings",
    "label": "MistralAI Embeddings",
    "category": "Embeddings",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-asyncOptions",
        "name": "modelName",
        "label": "modelName",
        "type": "asyncOptions",
        "optional": true,
        "default": "mistral-embed",
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-batchSize-number",
        "name": "batchSize",
        "label": "batchSize",
        "type": "number",
        "optional": true,
        "default": "512",
        "description": "Batch Size"
      },
      {
        "id": "{nodeId}-input-stripNewLines-boolean",
        "name": "stripNewLines",
        "label": "stripNewLines",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "Strip New Lines"
      },
      {
        "id": "{nodeId}-input-overrideEndpoint-string",
        "name": "overrideEndpoint",
        "label": "overrideEndpoint",
        "type": "string",
        "optional": true,
        "description": "Override Endpoint"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-mistralAIEmbeddings-MistralAIEmbeddings|Embeddings",
        "name": "mistralAIEmbeddings",
        "label": "MistralAI Embeddings",
        "type": "MistralAIEmbeddings | Embeddings"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "MistralAI API to generate embeddings for a given text",
    "baseClasses": [
      "MistralAIEmbeddings",
      "Embeddings"
    ],
    "credential_required": [
      "mistralAIApi"
    ]
  },
  {
    "node_type": "ollamaEmbedding",
    "name": "ollamaEmbedding",
    "label": "Ollama Embeddings",
    "category": "Embeddings",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-baseUrl-string",
        "name": "baseUrl",
        "label": "baseUrl",
        "type": "string",
        "optional": true,
        "default": "http://localhost:11434",
        "description": "Base URL"
      },
      {
        "id": "{nodeId}-input-modelName-string",
        "name": "modelName",
        "label": "modelName",
        "type": "string",
        "optional": true,
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-numGpu-number",
        "name": "numGpu",
        "label": "numGpu",
        "type": "number",
        "optional": true,
        "description": "The number of layers to send to the GPU(s). On macOS it defaults to 1 to enable metal support, 0 to"
      },
      {
        "id": "{nodeId}-input-numThread-number",
        "name": "numThread",
        "label": "numThread",
        "type": "number",
        "optional": true,
        "description": "Sets the number of threads to use during computation. By default, Ollama will detect this for optima"
      },
      {
        "id": "{nodeId}-input-useMMap-boolean",
        "name": "useMMap",
        "label": "useMMap",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "Use MMap"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-ollamaEmbedding-OllamaEmbeddings|Embeddings",
        "name": "ollamaEmbedding",
        "label": "Ollama Embeddings",
        "type": "OllamaEmbeddings | Embeddings"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Generate embeddings for a given text using open source model on Ollama",
    "baseClasses": [
      "OllamaEmbeddings",
      "Embeddings"
    ]
  },
  {
    "node_type": "openAIEmbedding_LlamaIndex",
    "name": "openAIEmbedding_LlamaIndex",
    "label": "OpenAI Embedding",
    "category": "Embeddings",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-asyncOptions",
        "name": "modelName",
        "label": "modelName",
        "type": "asyncOptions",
        "optional": true,
        "default": "text-embedding-ada-002",
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-timeout-number",
        "name": "timeout",
        "label": "timeout",
        "type": "number",
        "optional": true,
        "description": "Timeout"
      },
      {
        "id": "{nodeId}-input-basepath-string",
        "name": "basepath",
        "label": "basepath",
        "type": "string",
        "optional": true,
        "description": "BasePath"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-openAIEmbedding_LlamaIndex-OpenAIEmbedding|BaseEmbedding_LlamaIndex|BaseEmbedding",
        "name": "openAIEmbedding_LlamaIndex",
        "label": "OpenAI Embedding",
        "type": "OpenAIEmbedding | BaseEmbedding_LlamaIndex | BaseEmbedding"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "OpenAI Embedding specific for LlamaIndex",
    "baseClasses": [
      "OpenAIEmbedding",
      "BaseEmbedding_LlamaIndex",
      "BaseEmbedding"
    ],
    "credential_required": [
      "openAIApi"
    ]
  },
  {
    "node_type": "openAIEmbeddings",
    "name": "openAIEmbeddings",
    "label": "OpenAI Embeddings",
    "category": "Embeddings",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-asyncOptions",
        "name": "modelName",
        "label": "modelName",
        "type": "asyncOptions",
        "optional": true,
        "default": "text-embedding-ada-002",
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-stripNewLines-boolean",
        "name": "stripNewLines",
        "label": "stripNewLines",
        "type": "boolean",
        "optional": true,
        "description": "Strip New Lines"
      },
      {
        "id": "{nodeId}-input-batchSize-number",
        "name": "batchSize",
        "label": "batchSize",
        "type": "number",
        "optional": true,
        "description": "Batch Size"
      },
      {
        "id": "{nodeId}-input-timeout-number",
        "name": "timeout",
        "label": "timeout",
        "type": "number",
        "optional": true,
        "description": "Timeout"
      },
      {
        "id": "{nodeId}-input-basepath-string",
        "name": "basepath",
        "label": "basepath",
        "type": "string",
        "optional": true,
        "description": "BasePath"
      },
      {
        "id": "{nodeId}-input-dimensions-number",
        "name": "dimensions",
        "label": "dimensions",
        "type": "number",
        "optional": true,
        "description": "Dimensions"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings",
        "name": "openAIEmbeddings",
        "label": "OpenAI Embeddings",
        "type": "OpenAIEmbeddings | Embeddings"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "4",
    "description": "OpenAI API to generate embeddings for a given text",
    "baseClasses": [
      "OpenAIEmbeddings",
      "Embeddings"
    ],
    "credential_required": [
      "openAIApi"
    ]
  },
  {
    "node_type": "openAIEmbeddingsCustom",
    "name": "openAIEmbeddingsCustom",
    "label": "OpenAI Embeddings Custom",
    "category": "Embeddings",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-string",
        "name": "modelName",
        "label": "modelName",
        "type": "string",
        "optional": true,
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-stripNewLines-boolean",
        "name": "stripNewLines",
        "label": "stripNewLines",
        "type": "boolean",
        "optional": true,
        "description": "Strip New Lines"
      },
      {
        "id": "{nodeId}-input-batchSize-number",
        "name": "batchSize",
        "label": "batchSize",
        "type": "number",
        "optional": true,
        "description": "Batch Size"
      },
      {
        "id": "{nodeId}-input-timeout-number",
        "name": "timeout",
        "label": "timeout",
        "type": "number",
        "optional": true,
        "description": "Timeout"
      },
      {
        "id": "{nodeId}-input-basepath-string",
        "name": "basepath",
        "label": "basepath",
        "type": "string",
        "optional": true,
        "description": "BasePath"
      },
      {
        "id": "{nodeId}-input-baseOptions-json",
        "name": "baseOptions",
        "label": "baseOptions",
        "type": "json",
        "optional": true,
        "description": "BaseOptions"
      },
      {
        "id": "{nodeId}-input-dimensions-number",
        "name": "dimensions",
        "label": "dimensions",
        "type": "number",
        "optional": true,
        "description": "Dimensions"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-openAIEmbeddingsCustom-OpenAIEmbeddingsCustom|Embeddings",
        "name": "openAIEmbeddingsCustom",
        "label": "OpenAI Embeddings Custom",
        "type": "OpenAIEmbeddingsCustom | Embeddings"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "3",
    "description": "OpenAI API to generate embeddings for a given text",
    "baseClasses": [
      "OpenAIEmbeddingsCustom",
      "Embeddings"
    ],
    "credential_required": [
      "openAIApi"
    ]
  },
  {
    "node_type": "togetherAIEmbedding",
    "name": "togetherAIEmbedding",
    "label": "TogetherAIEmbedding",
    "category": "Embeddings",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-string",
        "name": "modelName",
        "label": "modelName",
        "type": "string",
        "optional": true,
        "description": "Refer to embedding models</"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-togetherAIEmbedding-TogetherAIEmbedding|Embeddings",
        "name": "togetherAIEmbedding",
        "label": "TogetherAIEmbedding",
        "type": "TogetherAIEmbedding | Embeddings"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "TogetherAI Embedding models to generate embeddings for a given text",
    "baseClasses": [
      "TogetherAIEmbedding",
      "Embeddings"
    ],
    "credential_required": [
      "togetherAIApi"
    ]
  },
  {
    "node_type": "voyageAIEmbeddings",
    "name": "voyageAIEmbeddings",
    "label": "VoyageAI Embeddings",
    "category": "Embeddings",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-asyncOptions",
        "name": "modelName",
        "label": "modelName",
        "type": "asyncOptions",
        "optional": true,
        "default": "voyage-2",
        "description": "Model Name"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-voyageAIEmbeddings-VoyageAIEmbeddings|Embeddings",
        "name": "voyageAIEmbeddings",
        "label": "VoyageAI Embeddings",
        "type": "VoyageAIEmbeddings | Embeddings"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Voyage AI API to generate embeddings for a given text",
    "baseClasses": [
      "VoyageAIEmbeddings",
      "Embeddings"
    ],
    "credential_required": [
      "voyageAIApi"
    ]
  },
  {
    "node_type": "contextChatEngine",
    "name": "contextChatEngine",
    "label": "Context Chat Engine",
    "category": "Engine",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-model-BaseChatModel_LlamaIndex",
        "name": "model",
        "label": "model",
        "type": "BaseChatModel_LlamaIndex",
        "optional": true,
        "description": "Chat Model"
      },
      {
        "id": "{nodeId}-input-vectorStoreRetriever-VectorIndexRetriever",
        "name": "vectorStoreRetriever",
        "label": "vectorStoreRetriever",
        "type": "VectorIndexRetriever",
        "optional": true,
        "description": "Vector Store Retriever"
      },
      {
        "id": "{nodeId}-input-memory-BaseChatMemory",
        "name": "memory",
        "label": "memory",
        "type": "BaseChatMemory",
        "optional": true,
        "description": "Memory"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-returnSourceDocuments-boolean",
        "name": "returnSourceDocuments",
        "label": "returnSourceDocuments",
        "type": "boolean",
        "optional": true,
        "description": "Return Source Documents"
      },
      {
        "id": "{nodeId}-input-systemMessagePrompt-string",
        "name": "systemMessagePrompt",
        "label": "systemMessagePrompt",
        "type": "string",
        "optional": true,
        "description": "System Message"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-contextChatEngine-ContextChatEngine",
        "name": "contextChatEngine",
        "label": "Context Chat Engine",
        "type": "ContextChatEngine"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Answer question based on retrieved documents (context) with built-in memory to remember conversation",
    "baseClasses": [
      "ContextChatEngine"
    ]
  },
  {
    "node_type": "queryEngine",
    "name": "queryEngine",
    "label": "Query Engine",
    "category": "Engine",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-vectorStoreRetriever-VectorIndexRetriever",
        "name": "vectorStoreRetriever",
        "label": "vectorStoreRetriever",
        "type": "VectorIndexRetriever",
        "optional": true,
        "description": "Vector Store Retriever"
      },
      {
        "id": "{nodeId}-input-responseSynthesizer-ResponseSynthesizer",
        "name": "responseSynthesizer",
        "label": "responseSynthesizer",
        "type": "ResponseSynthesizer",
        "optional": true,
        "description": "ResponseSynthesizer is responsible for sending the query, nodes, and prompt templates to the LLM to"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-returnSourceDocuments-boolean",
        "name": "returnSourceDocuments",
        "label": "returnSourceDocuments",
        "type": "boolean",
        "optional": true,
        "description": "Return Source Documents"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-queryEngine-QueryEngine|BaseQueryEngine",
        "name": "queryEngine",
        "label": "Query Engine",
        "type": "QueryEngine | BaseQueryEngine"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Simple query engine built to answer question over your data, without memory",
    "baseClasses": [
      "QueryEngine",
      "BaseQueryEngine"
    ]
  },
  {
    "node_type": "simpleChatEngine",
    "name": "simpleChatEngine",
    "label": "Simple Chat Engine",
    "category": "Engine",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-model-BaseChatModel_LlamaIndex",
        "name": "model",
        "label": "model",
        "type": "BaseChatModel_LlamaIndex",
        "optional": true,
        "description": "Chat Model"
      },
      {
        "id": "{nodeId}-input-memory-BaseChatMemory",
        "name": "memory",
        "label": "memory",
        "type": "BaseChatMemory",
        "optional": true,
        "description": "Memory"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-systemMessagePrompt-string",
        "name": "systemMessagePrompt",
        "label": "systemMessagePrompt",
        "type": "string",
        "optional": true,
        "description": "System Message"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-simpleChatEngine-SimpleChatEngine",
        "name": "simpleChatEngine",
        "label": "Simple Chat Engine",
        "type": "SimpleChatEngine"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Simple engine to handle back and forth conversations",
    "baseClasses": [
      "SimpleChatEngine"
    ]
  },
  {
    "node_type": "subQuestionQueryEngine",
    "name": "subQuestionQueryEngine",
    "label": "Sub Question Query Engine",
    "category": "Engine",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-queryEngineTools-QueryEngineTool",
        "name": "queryEngineTools",
        "label": "queryEngineTools",
        "type": "QueryEngineTool",
        "optional": true,
        "description": "QueryEngine Tools"
      },
      {
        "id": "{nodeId}-input-model-BaseChatModel_LlamaIndex",
        "name": "model",
        "label": "model",
        "type": "BaseChatModel_LlamaIndex",
        "optional": true,
        "description": "Chat Model"
      },
      {
        "id": "{nodeId}-input-embeddings-BaseEmbedding_LlamaIndex",
        "name": "embeddings",
        "label": "embeddings",
        "type": "BaseEmbedding_LlamaIndex",
        "optional": true,
        "description": "Embeddings"
      },
      {
        "id": "{nodeId}-input-responseSynthesizer-ResponseSynthesizer",
        "name": "responseSynthesizer",
        "label": "responseSynthesizer",
        "type": "ResponseSynthesizer",
        "optional": true,
        "description": "ResponseSynthesizer is responsible for sending the query, nodes, and prompt templates to the LLM to"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-returnSourceDocuments-boolean",
        "name": "returnSourceDocuments",
        "label": "returnSourceDocuments",
        "type": "boolean",
        "optional": true,
        "description": "Return Source Documents"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-subQuestionQueryEngine-SubQuestionQueryEngine|BaseQueryEngine",
        "name": "subQuestionQueryEngine",
        "label": "Sub Question Query Engine",
        "type": "SubQuestionQueryEngine | BaseQueryEngine"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Breaks complex query into sub questions for each relevant data source, then gather all the intermediate responses and synthesizes a final response",
    "baseClasses": [
      "SubQuestionQueryEngine",
      "BaseQueryEngine"
    ]
  },
  {
    "node_type": "Neo4j",
    "name": "Neo4j",
    "label": "Neo4j",
    "category": "Graph",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-database-string",
        "name": "database",
        "label": "database",
        "type": "string",
        "optional": true,
        "description": "Database"
      },
      {
        "id": "{nodeId}-input-timeoutMs-number",
        "name": "timeoutMs",
        "label": "timeoutMs",
        "type": "number",
        "optional": true,
        "default": "5000",
        "description": "Timeout (ms)"
      },
      {
        "id": "{nodeId}-input-enhancedSchema-boolean",
        "name": "enhancedSchema",
        "label": "enhancedSchema",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Enhanced Schema"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-Neo4j-Neo4j",
        "name": "Neo4j",
        "label": "Neo4j",
        "type": "Neo4j"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Connect with Neo4j graph database",
    "baseClasses": [
      "Neo4j"
    ],
    "credential_required": [
      "neo4jApi"
    ]
  },
  {
    "node_type": "awsBedrock",
    "name": "awsBedrock",
    "label": "AWS Bedrock",
    "category": "LLMs",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-region-asyncOptions",
        "name": "region",
        "label": "region",
        "type": "asyncOptions",
        "optional": true,
        "default": "us-east-1",
        "description": "Region"
      },
      {
        "id": "{nodeId}-input-model-asyncOptions",
        "name": "model",
        "label": "model",
        "type": "asyncOptions",
        "optional": true,
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-customModel-string",
        "name": "customModel",
        "label": "customModel",
        "type": "string",
        "optional": true,
        "description": "If provided, will override model selected from Model Name option"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.7",
        "description": "Temperature parameter may not apply to certain model. Please check available model parameters"
      },
      {
        "id": "{nodeId}-input-max_tokens_to_sample-number",
        "name": "max_tokens_to_sample",
        "label": "max_tokens_to_sample",
        "type": "number",
        "optional": true,
        "default": "200",
        "description": "Max Tokens parameter may not apply to certain model. Please check available model parameters"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-awsBedrock-AWSBedrock|Bedrock|LLM|BaseLLM|BaseLanguageModel|Runnable",
        "name": "awsBedrock",
        "label": "AWS Bedrock",
        "type": "AWSBedrock | Bedrock | LLM | BaseLLM | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "4",
    "description": "Wrapper around AWS Bedrock large language models",
    "baseClasses": [
      "AWSBedrock",
      "Bedrock",
      "LLM",
      "BaseLLM",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "awsApi"
    ]
  },
  {
    "node_type": "azureOpenAI",
    "name": "azureOpenAI",
    "label": "Azure OpenAI",
    "category": "LLMs",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-asyncOptions",
        "name": "modelName",
        "label": "modelName",
        "type": "asyncOptions",
        "optional": true,
        "default": "text-davinci-003",
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.9",
        "description": "Temperature"
      },
      {
        "id": "{nodeId}-input-maxTokens-number",
        "name": "maxTokens",
        "label": "maxTokens",
        "type": "number",
        "optional": true,
        "description": "Max Tokens"
      },
      {
        "id": "{nodeId}-input-topP-number",
        "name": "topP",
        "label": "topP",
        "type": "number",
        "optional": true,
        "description": "Top Probability"
      },
      {
        "id": "{nodeId}-input-bestOf-number",
        "name": "bestOf",
        "label": "bestOf",
        "type": "number",
        "optional": true,
        "description": "Best Of"
      },
      {
        "id": "{nodeId}-input-frequencyPenalty-number",
        "name": "frequencyPenalty",
        "label": "frequencyPenalty",
        "type": "number",
        "optional": true,
        "description": "Frequency Penalty"
      },
      {
        "id": "{nodeId}-input-presencePenalty-number",
        "name": "presencePenalty",
        "label": "presencePenalty",
        "type": "number",
        "optional": true,
        "description": "Presence Penalty"
      },
      {
        "id": "{nodeId}-input-timeout-number",
        "name": "timeout",
        "label": "timeout",
        "type": "number",
        "optional": true,
        "description": "Timeout"
      },
      {
        "id": "{nodeId}-input-basepath-string",
        "name": "basepath",
        "label": "basepath",
        "type": "string",
        "optional": true,
        "description": "BasePath"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-azureOpenAI-AzureOpenAI|OpenAI|BaseLLM|BaseLanguageModel|Runnable",
        "name": "azureOpenAI",
        "label": "Azure OpenAI",
        "type": "AzureOpenAI | OpenAI | BaseLLM | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "4",
    "description": "Wrapper around Azure OpenAI large language models",
    "baseClasses": [
      "AzureOpenAI",
      "OpenAI",
      "BaseLLM",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "azureOpenAIApi"
    ]
  },
  {
    "node_type": "cis",
    "name": "cis",
    "label": "[Experimental] CIS",
    "category": "LLMs",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-endpoint-string",
        "name": "endpoint",
        "label": "endpoint",
        "type": "string",
        "optional": true,
        "description": "Endpoint URL"
      },
      {
        "id": "{nodeId}-input-featureKey-string",
        "name": "featureKey",
        "label": "featureKey",
        "type": "string",
        "optional": true,
        "description": "Wd-PCA-Feature-Key header value (e.g., tiare.balbi, )"
      },
      {
        "id": "{nodeId}-input-model-string",
        "name": "model",
        "label": "model",
        "type": "string",
        "optional": true,
        "default": "gemini-1.5-pro-002",
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0",
        "description": "Temperature"
      },
      {
        "id": "{nodeId}-input-systemPrompt-string",
        "name": "systemPrompt",
        "label": "systemPrompt",
        "type": "string",
        "optional": true,
        "description": "System Prompt"
      },
      {
        "id": "{nodeId}-input-additionalHeaders-string",
        "name": "additionalHeaders",
        "label": "additionalHeaders",
        "type": "string",
        "optional": true,
        "description": "Additional headers in \"key1=value1,key2=value2\" format"
      },
      {
        "id": "{nodeId}-input-topP-number",
        "name": "topP",
        "label": "topP",
        "type": "number",
        "optional": true,
        "default": "0.98",
        "description": "Top P"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "default": "40",
        "description": "Top K"
      },
      {
        "id": "{nodeId}-input-maxOutputTokens-number",
        "name": "maxOutputTokens",
        "label": "maxOutputTokens",
        "type": "number",
        "optional": true,
        "default": "4096",
        "description": "Max Output Tokens"
      },
      {
        "id": "{nodeId}-input-candidateCount-number",
        "name": "candidateCount",
        "label": "candidateCount",
        "type": "number",
        "optional": true,
        "default": "1",
        "description": "Candidate Count"
      },
      {
        "id": "{nodeId}-input-provider-string",
        "name": "provider",
        "label": "provider",
        "type": "string",
        "optional": true,
        "default": "gcp",
        "description": "Provider"
      },
      {
        "id": "{nodeId}-input-predictionType-string",
        "name": "predictionType",
        "label": "predictionType",
        "type": "string",
        "optional": true,
        "default": "gcp-multimodal-v1",
        "description": "Prediction Type"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-cis-CIS|LLM|BaseLLM|BaseLanguageModel|Runnable",
        "name": "cis",
        "label": "[Experimental] CIS",
        "type": "CIS | LLM | BaseLLM | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "CIS LLM through CIS inference endpoint (Gemini-compatible response mapping)",
    "baseClasses": [
      "CIS",
      "LLM",
      "BaseLLM",
      "BaseLanguageModel",
      "Runnable"
    ]
  },
  {
    "node_type": "cohere",
    "name": "cohere",
    "label": "Cohere",
    "category": "LLMs",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-asyncOptions",
        "name": "modelName",
        "label": "modelName",
        "type": "asyncOptions",
        "optional": true,
        "default": "command",
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.7",
        "description": "Temperature"
      },
      {
        "id": "{nodeId}-input-maxTokens-number",
        "name": "maxTokens",
        "label": "maxTokens",
        "type": "number",
        "optional": true,
        "description": "Max Tokens"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-cohere-Cohere|LLM|BaseLLM|BaseLanguageModel|Runnable",
        "name": "cohere",
        "label": "Cohere",
        "type": "Cohere | LLM | BaseLLM | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "3",
    "description": "Wrapper around Cohere large language models",
    "baseClasses": [
      "Cohere",
      "LLM",
      "BaseLLM",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "cohereApi"
    ]
  },
  {
    "node_type": "fireworks",
    "name": "fireworks",
    "label": "Fireworks",
    "category": "LLMs",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-string",
        "name": "modelName",
        "label": "modelName",
        "type": "string",
        "optional": true,
        "default": "accounts/fireworks/models/llama-v3-70b-instruct-hf",
        "description": "For more details see https://fireworks.ai/models"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-fireworks-Fireworks|OpenAI|BaseLLM|BaseLanguageModel|Runnable",
        "name": "fireworks",
        "label": "Fireworks",
        "type": "Fireworks | OpenAI | BaseLLM | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Wrapper around Fireworks API for large language models",
    "baseClasses": [
      "Fireworks",
      "OpenAI",
      "BaseLLM",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "fireworksApi"
    ]
  },
  {
    "node_type": "googlevertexai",
    "name": "googlevertexai",
    "label": "GoogleVertexAI",
    "category": "LLMs",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-asyncOptions",
        "name": "modelName",
        "label": "modelName",
        "type": "asyncOptions",
        "optional": true,
        "default": "text-bison",
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.7",
        "description": "Temperature"
      },
      {
        "id": "{nodeId}-input-maxOutputTokens-number",
        "name": "maxOutputTokens",
        "label": "maxOutputTokens",
        "type": "number",
        "optional": true,
        "description": "max Output Tokens"
      },
      {
        "id": "{nodeId}-input-topP-number",
        "name": "topP",
        "label": "topP",
        "type": "number",
        "optional": true,
        "description": "Top Probability"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-googlevertexai-GoogleVertexAI|GoogleLLM|GoogleBaseLLM|LLM|BaseLLM|BaseLanguageModel|Runnable",
        "name": "googlevertexai",
        "label": "GoogleVertexAI",
        "type": "GoogleVertexAI | GoogleLLM | GoogleBaseLLM | LLM | BaseLLM | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "3",
    "description": "Wrapper around GoogleVertexAI large language models",
    "baseClasses": [
      "GoogleVertexAI",
      "GoogleLLM",
      "GoogleBaseLLM",
      "LLM",
      "BaseLLM",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "googleVertexAuth"
    ]
  },
  {
    "node_type": "huggingFaceInference_LLMs",
    "name": "huggingFaceInference_LLMs",
    "label": "HuggingFace Inference",
    "category": "LLMs",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-model-string",
        "name": "model",
        "label": "model",
        "type": "string",
        "optional": true,
        "description": "If using own inference endpoint, leave this blank"
      },
      {
        "id": "{nodeId}-input-endpoint-string",
        "name": "endpoint",
        "label": "endpoint",
        "type": "string",
        "optional": true,
        "description": "Using your own inference endpoint"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "description": "Temperature parameter may not apply to certain model. Please check available model parameters"
      },
      {
        "id": "{nodeId}-input-maxTokens-number",
        "name": "maxTokens",
        "label": "maxTokens",
        "type": "number",
        "optional": true,
        "description": "Max Tokens parameter may not apply to certain model. Please check available model parameters"
      },
      {
        "id": "{nodeId}-input-topP-number",
        "name": "topP",
        "label": "topP",
        "type": "number",
        "optional": true,
        "description": "Top Probability parameter may not apply to certain model. Please check available model parameters"
      },
      {
        "id": "{nodeId}-input-hfTopK-number",
        "name": "hfTopK",
        "label": "hfTopK",
        "type": "number",
        "optional": true,
        "description": "Top K parameter may not apply to certain model. Please check available model parameters"
      },
      {
        "id": "{nodeId}-input-frequencyPenalty-number",
        "name": "frequencyPenalty",
        "label": "frequencyPenalty",
        "type": "number",
        "optional": true,
        "description": "Frequency Penalty parameter may not apply to certain model. Please check available model parameters"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-huggingFaceInference_LLMs-HuggingFaceInference|LLM|BaseLLM|BaseLanguageModel|Runnable",
        "name": "huggingFaceInference_LLMs",
        "label": "HuggingFace Inference",
        "type": "HuggingFaceInference | LLM | BaseLLM | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Wrapper around HuggingFace large language models",
    "baseClasses": [
      "HuggingFaceInference",
      "LLM",
      "BaseLLM",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "huggingFaceApi"
    ]
  },
  {
    "node_type": "ibmWatsonx",
    "name": "ibmWatsonx",
    "label": "IBMWatsonx",
    "category": "LLMs",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelId-string",
        "name": "modelId",
        "label": "modelId",
        "type": "string",
        "optional": true,
        "default": "ibm/granite-13b-instruct-v2",
        "description": "The name of the model to query."
      },
      {
        "id": "{nodeId}-input-streaming-boolean",
        "name": "streaming",
        "label": "streaming",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Whether or not to stream tokens as they are generated."
      },
      {
        "id": "{nodeId}-input-decodingMethod-options",
        "name": "decodingMethod",
        "label": "decodingMethod",
        "type": "options",
        "optional": true,
        "default": "greedy",
        "description": "Set decoding to Greedy to always select words with the highest probability. Set decoding to Sampling"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "default": "50",
        "description": "The topK parameter is used to limit the number of choices for the next predicted word or token. It s"
      },
      {
        "id": "{nodeId}-input-topP-number",
        "name": "topP",
        "label": "topP",
        "type": "number",
        "optional": true,
        "default": "0.7",
        "description": "The topP (nucleus) parameter is used to dynamically adjust the number of choices for each predicted"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.7",
        "description": "A decimal number that determines the degree of randomness in the response. A value of 1 will always"
      },
      {
        "id": "{nodeId}-input-repetitionPenalty-number",
        "name": "repetitionPenalty",
        "label": "repetitionPenalty",
        "type": "number",
        "optional": true,
        "default": "1",
        "description": "A number that controls the diversity of generated text by reducing the likelihood of repeated sequen"
      },
      {
        "id": "{nodeId}-input-maxNewTokens-number",
        "name": "maxNewTokens",
        "label": "maxNewTokens",
        "type": "number",
        "optional": true,
        "default": "100",
        "description": "The maximum number of new tokens to be generated. The maximum supported value for this field depends"
      },
      {
        "id": "{nodeId}-input-minNewTokens-number",
        "name": "minNewTokens",
        "label": "minNewTokens",
        "type": "number",
        "optional": true,
        "default": "1",
        "description": "If stop sequences are given, they are ignored until minimum tokens are generated."
      },
      {
        "id": "{nodeId}-input-stopSequence-string",
        "name": "stopSequence",
        "label": "stopSequence",
        "type": "string",
        "optional": true,
        "description": "A list of tokens at which the generation should stop."
      },
      {
        "id": "{nodeId}-input-includeStopSequence-boolean",
        "name": "includeStopSequence",
        "label": "includeStopSequence",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Pass false to omit matched stop sequences from the end of the output text. The default is true, mean"
      },
      {
        "id": "{nodeId}-input-randomSeed-number",
        "name": "randomSeed",
        "label": "randomSeed",
        "type": "number",
        "optional": true,
        "description": "Random number generator seed to use in sampling mode for experimental repeatability."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-ibmWatsonx-IBMWatsonx|BaseLLM|BaseLanguageModel|Runnable",
        "name": "ibmWatsonx",
        "label": "IBMWatsonx",
        "type": "IBMWatsonx | BaseLLM | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Wrapper around IBM watsonx.ai foundation models",
    "baseClasses": [
      "IBMWatsonx",
      "BaseLLM",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "ibmWatsonx"
    ]
  },
  {
    "node_type": "ollama",
    "name": "ollama",
    "label": "Ollama",
    "category": "LLMs",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-baseUrl-string",
        "name": "baseUrl",
        "label": "baseUrl",
        "type": "string",
        "optional": true,
        "default": "http://localhost:11434",
        "description": "Base URL"
      },
      {
        "id": "{nodeId}-input-modelName-string",
        "name": "modelName",
        "label": "modelName",
        "type": "string",
        "optional": true,
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.9",
        "description": "The temperature of the model. Increasing the temperature will make the model answer more creatively."
      },
      {
        "id": "{nodeId}-input-topP-number",
        "name": "topP",
        "label": "topP",
        "type": "number",
        "optional": true,
        "description": "Works together with top-k. A higher value (e.g., 0.95) will lead to more diverse text, while a lower"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Reduces the probability of generating nonsense. A higher value (e.g. 100) will give more diverse ans"
      },
      {
        "id": "{nodeId}-input-mirostat-number",
        "name": "mirostat",
        "label": "mirostat",
        "type": "number",
        "optional": true,
        "description": "Enable Mirostat sampling for controlling perplexity. (default: 0, 0 = disabled, 1 = Mirostat, 2 = Mi"
      },
      {
        "id": "{nodeId}-input-mirostatEta-number",
        "name": "mirostatEta",
        "label": "mirostatEta",
        "type": "number",
        "optional": true,
        "description": "Influences how quickly the algorithm responds to feedback from the generated text. A lower learning"
      },
      {
        "id": "{nodeId}-input-mirostatTau-number",
        "name": "mirostatTau",
        "label": "mirostatTau",
        "type": "number",
        "optional": true,
        "description": "Controls the balance between coherence and diversity of the output. A lower value will result in mor"
      },
      {
        "id": "{nodeId}-input-numCtx-number",
        "name": "numCtx",
        "label": "numCtx",
        "type": "number",
        "optional": true,
        "description": "Sets the size of the context window used to generate the next token. (Default: 2048) Refer to <a tar"
      },
      {
        "id": "{nodeId}-input-numGqa-number",
        "name": "numGqa",
        "label": "numGqa",
        "type": "number",
        "optional": true,
        "description": "The number of GQA groups in the transformer layer. Required for some models, for example it is 8 for"
      },
      {
        "id": "{nodeId}-input-numGpu-number",
        "name": "numGpu",
        "label": "numGpu",
        "type": "number",
        "optional": true,
        "description": "The number of layers to send to the GPU(s). On macOS it defaults to 1 to enable metal support, 0 to"
      },
      {
        "id": "{nodeId}-input-numThread-number",
        "name": "numThread",
        "label": "numThread",
        "type": "number",
        "optional": true,
        "description": "Sets the number of threads to use during computation. By default, Ollama will detect this for optima"
      },
      {
        "id": "{nodeId}-input-repeatLastN-number",
        "name": "repeatLastN",
        "label": "repeatLastN",
        "type": "number",
        "optional": true,
        "description": "Sets how far back for the model to look back to prevent repetition. (Default: 64, 0 = disabled, -1 ="
      },
      {
        "id": "{nodeId}-input-repeatPenalty-number",
        "name": "repeatPenalty",
        "label": "repeatPenalty",
        "type": "number",
        "optional": true,
        "description": "Sets how strongly to penalize repetitions. A higher value (e.g., 1.5) will penalize repetitions more"
      },
      {
        "id": "{nodeId}-input-stop-string",
        "name": "stop",
        "label": "stop",
        "type": "string",
        "optional": true,
        "description": "Sets the stop sequences to use. Use comma to seperate different sequences. Refer to <a target=\"_blan"
      },
      {
        "id": "{nodeId}-input-tfsZ-number",
        "name": "tfsZ",
        "label": "tfsZ",
        "type": "number",
        "optional": true,
        "description": "Tail free sampling is used to reduce the impact of less probable tokens from the output. A higher va"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-ollama-Ollama|LLM|BaseLLM|BaseLanguageModel|Runnable",
        "name": "ollama",
        "label": "Ollama",
        "type": "Ollama | LLM | BaseLLM | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Wrapper around open source large language models on Ollama",
    "baseClasses": [
      "Ollama",
      "LLM",
      "BaseLLM",
      "BaseLanguageModel",
      "Runnable"
    ]
  },
  {
    "node_type": "openAI",
    "name": "openAI",
    "label": "OpenAI",
    "category": "LLMs",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-asyncOptions",
        "name": "modelName",
        "label": "modelName",
        "type": "asyncOptions",
        "optional": true,
        "default": "gpt-3.5-turbo-instruct",
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.7",
        "description": "Temperature"
      },
      {
        "id": "{nodeId}-input-maxTokens-number",
        "name": "maxTokens",
        "label": "maxTokens",
        "type": "number",
        "optional": true,
        "description": "Max Tokens"
      },
      {
        "id": "{nodeId}-input-topP-number",
        "name": "topP",
        "label": "topP",
        "type": "number",
        "optional": true,
        "description": "Top Probability"
      },
      {
        "id": "{nodeId}-input-bestOf-number",
        "name": "bestOf",
        "label": "bestOf",
        "type": "number",
        "optional": true,
        "description": "Best Of"
      },
      {
        "id": "{nodeId}-input-frequencyPenalty-number",
        "name": "frequencyPenalty",
        "label": "frequencyPenalty",
        "type": "number",
        "optional": true,
        "description": "Frequency Penalty"
      },
      {
        "id": "{nodeId}-input-presencePenalty-number",
        "name": "presencePenalty",
        "label": "presencePenalty",
        "type": "number",
        "optional": true,
        "description": "Presence Penalty"
      },
      {
        "id": "{nodeId}-input-batchSize-number",
        "name": "batchSize",
        "label": "batchSize",
        "type": "number",
        "optional": true,
        "description": "Batch Size"
      },
      {
        "id": "{nodeId}-input-timeout-number",
        "name": "timeout",
        "label": "timeout",
        "type": "number",
        "optional": true,
        "description": "Timeout"
      },
      {
        "id": "{nodeId}-input-basepath-string",
        "name": "basepath",
        "label": "basepath",
        "type": "string",
        "optional": true,
        "description": "BasePath"
      },
      {
        "id": "{nodeId}-input-baseOptions-json",
        "name": "baseOptions",
        "label": "baseOptions",
        "type": "json",
        "optional": true,
        "description": "BaseOptions"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-openAI-OpenAI|BaseLLM|BaseLanguageModel|Runnable",
        "name": "openAI",
        "label": "OpenAI",
        "type": "OpenAI | BaseLLM | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "4",
    "description": "Wrapper around OpenAI large language models",
    "baseClasses": [
      "OpenAI",
      "BaseLLM",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "openAIApi"
    ]
  },
  {
    "node_type": "replicate",
    "name": "replicate",
    "label": "Replicate",
    "category": "LLMs",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-model-string",
        "name": "model",
        "label": "model",
        "type": "string",
        "optional": true,
        "description": "Model"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.7",
        "description": "Adjusts randomness of outputs, greater than 1 is random and 0 is deterministic, 0.75 is a good start"
      },
      {
        "id": "{nodeId}-input-maxTokens-number",
        "name": "maxTokens",
        "label": "maxTokens",
        "type": "number",
        "optional": true,
        "description": "Maximum number of tokens to generate. A word is generally 2-3 tokens"
      },
      {
        "id": "{nodeId}-input-topP-number",
        "name": "topP",
        "label": "topP",
        "type": "number",
        "optional": true,
        "description": "When decoding text, samples from the top p percentage of most likely tokens; lower to ignore less li"
      },
      {
        "id": "{nodeId}-input-repetitionPenalty-number",
        "name": "repetitionPenalty",
        "label": "repetitionPenalty",
        "type": "number",
        "optional": true,
        "description": "Penalty for repeated words in generated text; 1 is no penalty, values greater than 1 discourage repe"
      },
      {
        "id": "{nodeId}-input-additionalInputs-json",
        "name": "additionalInputs",
        "label": "additionalInputs",
        "type": "json",
        "optional": true,
        "description": "Each model has different parameters, refer to the specific model accepted inputs. For example: <a ta"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-replicate-Replicate|BaseChatModel|LLM|BaseLLM|BaseLanguageModel|Runnable",
        "name": "replicate",
        "label": "Replicate",
        "type": "Replicate | BaseChatModel | LLM | BaseLLM | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Use Replicate to run open source models on cloud",
    "baseClasses": [
      "Replicate",
      "BaseChatModel",
      "LLM",
      "BaseLLM",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "replicateApi"
    ]
  },
  {
    "node_type": "sambanova",
    "name": "sambanova",
    "label": "Sambanova",
    "category": "LLMs",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-string",
        "name": "modelName",
        "label": "modelName",
        "type": "string",
        "optional": true,
        "default": "Meta-Llama-3.3-70B-Instruct",
        "description": "For more details see https://docs.sambanova.ai/cloud/docs/get-started/supported-models"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-sambanova-Sambanova|BaseLLM|BaseLanguageModel|Runnable",
        "name": "sambanova",
        "label": "Sambanova",
        "type": "Sambanova | BaseLLM | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Wrapper around Sambanova API for large language models",
    "baseClasses": [
      "Sambanova",
      "BaseLLM",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "sambanovaApi"
    ]
  },
  {
    "node_type": "togetherAI",
    "name": "togetherAI",
    "label": "TogetherAI",
    "category": "LLMs",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-cache-BaseCache",
        "name": "cache",
        "label": "cache",
        "type": "BaseCache",
        "optional": true,
        "description": "Cache"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelName-string",
        "name": "modelName",
        "label": "modelName",
        "type": "string",
        "optional": true,
        "description": "The name of the model to query."
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "default": "50",
        "description": "The topK parameter is used to limit the number of choices for the next predicted word or token. It s"
      },
      {
        "id": "{nodeId}-input-topP-number",
        "name": "topP",
        "label": "topP",
        "type": "number",
        "optional": true,
        "default": "0.7",
        "description": "The topP (nucleus) parameter is used to dynamically adjust the number of choices for each predicted"
      },
      {
        "id": "{nodeId}-input-temperature-number",
        "name": "temperature",
        "label": "temperature",
        "type": "number",
        "optional": true,
        "default": "0.7",
        "description": "A decimal number that determines the degree of randomness in the response. A value of 1 will always"
      },
      {
        "id": "{nodeId}-input-repeatPenalty-number",
        "name": "repeatPenalty",
        "label": "repeatPenalty",
        "type": "number",
        "optional": true,
        "default": "1",
        "description": "A number that controls the diversity of generated text by reducing the likelihood of repeated sequen"
      },
      {
        "id": "{nodeId}-input-streaming-boolean",
        "name": "streaming",
        "label": "streaming",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Whether or not to stream tokens as they are generated"
      },
      {
        "id": "{nodeId}-input-maxTokens-number",
        "name": "maxTokens",
        "label": "maxTokens",
        "type": "number",
        "optional": true,
        "description": "Limit the number of tokens generated."
      },
      {
        "id": "{nodeId}-input-stop-string",
        "name": "stop",
        "label": "stop",
        "type": "string",
        "optional": true,
        "description": "A list of tokens at which the generation should stop."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-togetherAI-TogetherAI|LLM|BaseLLM|BaseLanguageModel|Runnable",
        "name": "togetherAI",
        "label": "TogetherAI",
        "type": "TogetherAI | LLM | BaseLLM | BaseLanguageModel | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Wrapper around TogetherAI large language models",
    "baseClasses": [
      "TogetherAI",
      "LLM",
      "BaseLLM",
      "BaseLanguageModel",
      "Runnable"
    ],
    "credential_required": [
      "togetherAIApi"
    ]
  },
  {
    "node_type": "DynamoDBChatMemory",
    "name": "DynamoDBChatMemory",
    "label": "DynamoDB Chat Memory",
    "category": "Memory",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-tableName-string",
        "name": "tableName",
        "label": "tableName",
        "type": "string",
        "optional": true,
        "description": "Table Name"
      },
      {
        "id": "{nodeId}-input-partitionKey-string",
        "name": "partitionKey",
        "label": "partitionKey",
        "type": "string",
        "optional": true,
        "description": "Partition Key"
      },
      {
        "id": "{nodeId}-input-region-string",
        "name": "region",
        "label": "region",
        "type": "string",
        "optional": true,
        "description": "The aws region in which table is located"
      },
      {
        "id": "{nodeId}-input-sessionId-string",
        "name": "sessionId",
        "label": "sessionId",
        "type": "string",
        "optional": true,
        "description": "If not specified, a random id will be used. Learn <a target=\"_blank\" href=\"https://docs.flowiseai.co"
      },
      {
        "id": "{nodeId}-input-memoryKey-string",
        "name": "memoryKey",
        "label": "memoryKey",
        "type": "string",
        "optional": true,
        "default": "chat_history",
        "description": "Memory Key"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-DynamoDBChatMemory-DynamoDBChatMemory|BaseChatMemory|BaseMemory",
        "name": "DynamoDBChatMemory",
        "label": "DynamoDB Chat Memory",
        "type": "DynamoDBChatMemory | BaseChatMemory | BaseMemory"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Stores the conversation in dynamo db table",
    "baseClasses": [
      "DynamoDBChatMemory",
      "BaseChatMemory",
      "BaseMemory"
    ],
    "credential_required": [
      "dynamodbMemoryApi"
    ]
  },
  {
    "node_type": "MongoDBAtlasChatMemory",
    "name": "MongoDBAtlasChatMemory",
    "label": "MongoDB Atlas Chat Memory",
    "category": "Memory",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-databaseName-string",
        "name": "databaseName",
        "label": "databaseName",
        "type": "string",
        "optional": true,
        "description": "Database"
      },
      {
        "id": "{nodeId}-input-collectionName-string",
        "name": "collectionName",
        "label": "collectionName",
        "type": "string",
        "optional": true,
        "description": "Collection Name"
      },
      {
        "id": "{nodeId}-input-sessionId-string",
        "name": "sessionId",
        "label": "sessionId",
        "type": "string",
        "optional": true,
        "description": "If not specified, a random id will be used. Learn <a target=\"_blank\" href=\"https://docs.flowiseai.co"
      },
      {
        "id": "{nodeId}-input-memoryKey-string",
        "name": "memoryKey",
        "label": "memoryKey",
        "type": "string",
        "optional": true,
        "default": "chat_history",
        "description": "Memory Key"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-MongoDBAtlasChatMemory-MongoDBAtlasChatMemory|BaseChatMemory|BaseMemory",
        "name": "MongoDBAtlasChatMemory",
        "label": "MongoDB Atlas Chat Memory",
        "type": "MongoDBAtlasChatMemory | BaseChatMemory | BaseMemory"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Stores the conversation in MongoDB Atlas",
    "baseClasses": [
      "MongoDBAtlasChatMemory",
      "BaseChatMemory",
      "BaseMemory"
    ],
    "credential_required": [
      "mongoDBUrlApi"
    ]
  },
  {
    "node_type": "RedisBackedChatMemory",
    "name": "RedisBackedChatMemory",
    "label": "Redis-Backed Chat Memory",
    "category": "Memory",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-sessionId-string",
        "name": "sessionId",
        "label": "sessionId",
        "type": "string",
        "optional": true,
        "description": "If not specified, a random id will be used. Learn <a target=\"_blank\" href=\"https://docs.flowiseai.co"
      },
      {
        "id": "{nodeId}-input-sessionTTL-number",
        "name": "sessionTTL",
        "label": "sessionTTL",
        "type": "number",
        "optional": true,
        "description": "Seconds till a session expires. If not specified, the session will never expire."
      },
      {
        "id": "{nodeId}-input-memoryKey-string",
        "name": "memoryKey",
        "label": "memoryKey",
        "type": "string",
        "optional": true,
        "default": "chat_history",
        "description": "Memory Key"
      },
      {
        "id": "{nodeId}-input-windowSize-number",
        "name": "windowSize",
        "label": "windowSize",
        "type": "number",
        "optional": true,
        "description": "Window of size k to surface the last k back-and-forth to use as memory."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-RedisBackedChatMemory-RedisBackedChatMemory|BaseChatMemory|BaseMemory",
        "name": "RedisBackedChatMemory",
        "label": "Redis-Backed Chat Memory",
        "type": "RedisBackedChatMemory | BaseChatMemory | BaseMemory"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Summarizes the conversation and stores the memory in Redis server",
    "baseClasses": [
      "RedisBackedChatMemory",
      "BaseChatMemory",
      "BaseMemory"
    ],
    "credential_required": [
      "redisCacheApi",
      "redisCacheUrlApi"
    ]
  },
  {
    "node_type": "ZepMemory",
    "name": "ZepMemory",
    "label": "Zep Memory - Open Source",
    "category": "Memory",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-baseURL-string",
        "name": "baseURL",
        "label": "baseURL",
        "type": "string",
        "optional": true,
        "default": "http://127.0.0.1:8000",
        "description": "Base URL"
      },
      {
        "id": "{nodeId}-input-sessionId-string",
        "name": "sessionId",
        "label": "sessionId",
        "type": "string",
        "optional": true,
        "description": "If not specified, a random id will be used. Learn <a target=\"_blank\" href=\"https://docs.flowiseai.co"
      },
      {
        "id": "{nodeId}-input-k-number",
        "name": "k",
        "label": "k",
        "type": "number",
        "optional": true,
        "default": "10",
        "description": "Window of size k to surface the last k back-and-forth to use as memory."
      },
      {
        "id": "{nodeId}-input-aiPrefix-string",
        "name": "aiPrefix",
        "label": "aiPrefix",
        "type": "string",
        "optional": true,
        "default": "ai",
        "description": "AI Prefix"
      },
      {
        "id": "{nodeId}-input-humanPrefix-string",
        "name": "humanPrefix",
        "label": "humanPrefix",
        "type": "string",
        "optional": true,
        "default": "human",
        "description": "Human Prefix"
      },
      {
        "id": "{nodeId}-input-memoryKey-string",
        "name": "memoryKey",
        "label": "memoryKey",
        "type": "string",
        "optional": true,
        "default": "chat_history",
        "description": "Memory Key"
      },
      {
        "id": "{nodeId}-input-inputKey-string",
        "name": "inputKey",
        "label": "inputKey",
        "type": "string",
        "optional": true,
        "default": "input",
        "description": "Input Key"
      },
      {
        "id": "{nodeId}-input-outputKey-string",
        "name": "outputKey",
        "label": "outputKey",
        "type": "string",
        "optional": true,
        "default": "text",
        "description": "Output Key"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-ZepMemory-ZepMemory|BaseChatMemory|BaseMemory",
        "name": "ZepMemory",
        "label": "Zep Memory - Open Source",
        "type": "ZepMemory | BaseChatMemory | BaseMemory"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Summarizes the conversation and stores the memory in zep server",
    "baseClasses": [
      "ZepMemory",
      "BaseChatMemory",
      "BaseMemory"
    ],
    "credential_required": [
      "zepMemoryApi"
    ]
  },
  {
    "node_type": "ZepMemoryCloud",
    "name": "ZepMemoryCloud",
    "label": "Zep Memory - Cloud",
    "category": "Memory",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-sessionId-string",
        "name": "sessionId",
        "label": "sessionId",
        "type": "string",
        "optional": true,
        "description": "If not specified, a random id will be used. Learn <a target=\"_blank\" href=\"https://docs.flowiseai.co"
      },
      {
        "id": "{nodeId}-input-memoryType-string",
        "name": "memoryType",
        "label": "memoryType",
        "type": "string",
        "optional": true,
        "default": "perpetual",
        "description": "Zep Memory Type, can be perpetual or message_window"
      },
      {
        "id": "{nodeId}-input-aiPrefix-string",
        "name": "aiPrefix",
        "label": "aiPrefix",
        "type": "string",
        "optional": true,
        "default": "ai",
        "description": "AI Prefix"
      },
      {
        "id": "{nodeId}-input-humanPrefix-string",
        "name": "humanPrefix",
        "label": "humanPrefix",
        "type": "string",
        "optional": true,
        "default": "human",
        "description": "Human Prefix"
      },
      {
        "id": "{nodeId}-input-memoryKey-string",
        "name": "memoryKey",
        "label": "memoryKey",
        "type": "string",
        "optional": true,
        "default": "chat_history",
        "description": "Memory Key"
      },
      {
        "id": "{nodeId}-input-inputKey-string",
        "name": "inputKey",
        "label": "inputKey",
        "type": "string",
        "optional": true,
        "default": "input",
        "description": "Input Key"
      },
      {
        "id": "{nodeId}-input-outputKey-string",
        "name": "outputKey",
        "label": "outputKey",
        "type": "string",
        "optional": true,
        "default": "text",
        "description": "Output Key"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-ZepMemoryCloud-ZepMemory|BaseChatMemory|BaseMemory",
        "name": "ZepMemoryCloud",
        "label": "Zep Memory - Cloud",
        "type": "ZepMemory | BaseChatMemory | BaseMemory"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Summarizes the conversation and stores the memory in zep server",
    "baseClasses": [
      "ZepMemory",
      "BaseChatMemory",
      "BaseMemory"
    ],
    "credential_required": [
      "zepMemoryApi"
    ]
  },
  {
    "node_type": "agentMemory",
    "name": "agentMemory",
    "label": "Agent Memory",
    "category": "Memory",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-databaseType-options",
        "name": "databaseType",
        "label": "databaseType",
        "type": "options",
        "optional": true,
        "default": "sqlite",
        "description": "Database"
      },
      {
        "id": "{nodeId}-input-databaseFilePath-string",
        "name": "databaseFilePath",
        "label": "databaseFilePath",
        "type": "string",
        "optional": true,
        "description": "If SQLite is selected, provide the path to the SQLite database file. Leave empty to use default appl"
      },
      {
        "id": "{nodeId}-input-host-string",
        "name": "host",
        "label": "host",
        "type": "string",
        "optional": true,
        "description": "If PostgresQL/MySQL is selected, provide the host of the database"
      },
      {
        "id": "{nodeId}-input-database-string",
        "name": "database",
        "label": "database",
        "type": "string",
        "optional": true,
        "description": "If PostgresQL/MySQL is selected, provide the name of the database"
      },
      {
        "id": "{nodeId}-input-port-number",
        "name": "port",
        "label": "port",
        "type": "number",
        "optional": true,
        "description": "If PostgresQL/MySQL is selected, provide the port of the database"
      },
      {
        "id": "{nodeId}-input-additionalConfig-json",
        "name": "additionalConfig",
        "label": "additionalConfig",
        "type": "json",
        "optional": true,
        "description": "Additional Connection Configuration"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-agentMemory-AgentMemory|BaseCheckpointSaver",
        "name": "agentMemory",
        "label": "Agent Memory",
        "type": "AgentMemory | BaseCheckpointSaver"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Memory for agentflow to remember the state of the conversation",
    "baseClasses": [
      "AgentMemory",
      "BaseCheckpointSaver"
    ],
    "credential_required": [
      "PostgresApi",
      "MySQLApi"
    ]
  },
  {
    "node_type": "bufferMemory",
    "name": "bufferMemory",
    "label": "Buffer Memory",
    "category": "Memory",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-sessionId-string",
        "name": "sessionId",
        "label": "sessionId",
        "type": "string",
        "optional": true,
        "description": "If not specified, a random id will be used. Learn <a target=\"_blank\" href=\"https://docs.flowiseai.co"
      },
      {
        "id": "{nodeId}-input-memoryKey-string",
        "name": "memoryKey",
        "label": "memoryKey",
        "type": "string",
        "optional": true,
        "default": "chat_history",
        "description": "Memory Key"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory",
        "name": "bufferMemory",
        "label": "Buffer Memory",
        "type": "BufferMemory | BaseChatMemory | BaseMemory"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Retrieve chat messages stored in database",
    "baseClasses": [
      "BufferMemory",
      "BaseChatMemory",
      "BaseMemory"
    ]
  },
  {
    "node_type": "bufferWindowMemory",
    "name": "bufferWindowMemory",
    "label": "Buffer Window Memory",
    "category": "Memory",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-k-number",
        "name": "k",
        "label": "k",
        "type": "number",
        "optional": true,
        "default": "4",
        "description": "Window of size k to surface the last k back-and-forth to use as memory."
      },
      {
        "id": "{nodeId}-input-sessionId-string",
        "name": "sessionId",
        "label": "sessionId",
        "type": "string",
        "optional": true,
        "description": "If not specified, a random id will be used. Learn <a target=\"_blank\" href=\"https://docs.flowiseai.co"
      },
      {
        "id": "{nodeId}-input-memoryKey-string",
        "name": "memoryKey",
        "label": "memoryKey",
        "type": "string",
        "optional": true,
        "default": "chat_history",
        "description": "Memory Key"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-bufferWindowMemory-BufferWindowMemory|BaseChatMemory|BaseMemory",
        "name": "bufferWindowMemory",
        "label": "Buffer Window Memory",
        "type": "BufferWindowMemory | BaseChatMemory | BaseMemory"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Uses a window of size k to surface the last k back-and-forth to use as memory",
    "baseClasses": [
      "BufferWindowMemory",
      "BaseChatMemory",
      "BaseMemory"
    ]
  },
  {
    "node_type": "conversationSummaryBufferMemory",
    "name": "conversationSummaryBufferMemory",
    "label": "Conversation Summary Buffer Memory",
    "category": "Memory",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-model-BaseChatModel",
        "name": "model",
        "label": "model",
        "type": "BaseChatModel",
        "optional": true,
        "description": "Chat Model"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-maxTokenLimit-number",
        "name": "maxTokenLimit",
        "label": "maxTokenLimit",
        "type": "number",
        "optional": true,
        "default": "2000",
        "description": "Summarize conversations once token limit is reached. Default to 2000"
      },
      {
        "id": "{nodeId}-input-sessionId-string",
        "name": "sessionId",
        "label": "sessionId",
        "type": "string",
        "optional": true,
        "description": "If not specified, a random id will be used. Learn <a target=\"_blank\" href=\"https://docs.flowiseai.co"
      },
      {
        "id": "{nodeId}-input-memoryKey-string",
        "name": "memoryKey",
        "label": "memoryKey",
        "type": "string",
        "optional": true,
        "default": "chat_history",
        "description": "Memory Key"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-conversationSummaryBufferMemory-ConversationSummaryBufferMemory|BaseConversationSummaryMemory|BaseChatMemory|BaseMemory",
        "name": "conversationSummaryBufferMemory",
        "label": "Conversation Summary Buffer Memory",
        "type": "ConversationSummaryBufferMemory | BaseConversationSummaryMemory | BaseChatMemory | BaseMemory"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Uses token length to decide when to summarize conversations",
    "baseClasses": [
      "ConversationSummaryBufferMemory",
      "BaseConversationSummaryMemory",
      "BaseChatMemory",
      "BaseMemory"
    ]
  },
  {
    "node_type": "conversationSummaryMemory",
    "name": "conversationSummaryMemory",
    "label": "Conversation Summary Memory",
    "category": "Memory",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-model-BaseChatModel",
        "name": "model",
        "label": "model",
        "type": "BaseChatModel",
        "optional": true,
        "description": "Chat Model"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-sessionId-string",
        "name": "sessionId",
        "label": "sessionId",
        "type": "string",
        "optional": true,
        "description": "If not specified, a random id will be used. Learn <a target=\"_blank\" href=\"https://docs.flowiseai.co"
      },
      {
        "id": "{nodeId}-input-memoryKey-string",
        "name": "memoryKey",
        "label": "memoryKey",
        "type": "string",
        "optional": true,
        "default": "chat_history",
        "description": "Memory Key"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-conversationSummaryMemory-ConversationSummaryMemory|BaseConversationSummaryMemory|BaseChatMemory|BaseMemory",
        "name": "conversationSummaryMemory",
        "label": "Conversation Summary Memory",
        "type": "ConversationSummaryMemory | BaseConversationSummaryMemory | BaseChatMemory | BaseMemory"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Summarizes the conversation and stores the current summary in memory",
    "baseClasses": [
      "ConversationSummaryMemory",
      "BaseConversationSummaryMemory",
      "BaseChatMemory",
      "BaseMemory"
    ]
  },
  {
    "node_type": "mem0",
    "name": "mem0",
    "label": "Mem0",
    "category": "Memory",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-user_id-string",
        "name": "user_id",
        "label": "user_id",
        "type": "string",
        "optional": true,
        "default": "flowise-default-user",
        "description": "Unique identifier for the user. Required only if \"Use Flowise Chat ID\" is OFF."
      },
      {
        "id": "{nodeId}-input-useFlowiseChatId-boolean",
        "name": "useFlowiseChatId",
        "label": "useFlowiseChatId",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Use the Flowise internal Chat ID as the Mem0 User ID, overriding the \"User ID\" field above."
      },
      {
        "id": "{nodeId}-input-searchOnly-boolean",
        "name": "searchOnly",
        "label": "searchOnly",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Search only mode"
      },
      {
        "id": "{nodeId}-input-run_id-string",
        "name": "run_id",
        "label": "run_id",
        "type": "string",
        "optional": true,
        "description": "Unique identifier for the run session"
      },
      {
        "id": "{nodeId}-input-agent_id-string",
        "name": "agent_id",
        "label": "agent_id",
        "type": "string",
        "optional": true,
        "description": "Identifier for the agent"
      },
      {
        "id": "{nodeId}-input-app_id-string",
        "name": "app_id",
        "label": "app_id",
        "type": "string",
        "optional": true,
        "description": "Identifier for the application"
      },
      {
        "id": "{nodeId}-input-project_id-string",
        "name": "project_id",
        "label": "project_id",
        "type": "string",
        "optional": true,
        "description": "Identifier for the project"
      },
      {
        "id": "{nodeId}-input-org_id-string",
        "name": "org_id",
        "label": "org_id",
        "type": "string",
        "optional": true,
        "description": "Identifier for the organization"
      },
      {
        "id": "{nodeId}-input-memoryKey-string",
        "name": "memoryKey",
        "label": "memoryKey",
        "type": "string",
        "optional": true,
        "default": "history",
        "description": "Memory Key"
      },
      {
        "id": "{nodeId}-input-inputKey-string",
        "name": "inputKey",
        "label": "inputKey",
        "type": "string",
        "optional": true,
        "default": "input",
        "description": "Input Key"
      },
      {
        "id": "{nodeId}-input-outputKey-string",
        "name": "outputKey",
        "label": "outputKey",
        "type": "string",
        "optional": true,
        "default": "text",
        "description": "Output Key"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-mem0-Mem0|BaseChatMemory|BaseMemory",
        "name": "mem0",
        "label": "Mem0",
        "type": "Mem0 | BaseChatMemory | BaseMemory"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1.1",
    "description": "Stores and manages chat memory using Mem0 service",
    "baseClasses": [
      "Mem0",
      "BaseChatMemory",
      "BaseMemory"
    ],
    "credential_required": [
      "mem0MemoryApi"
    ]
  },
  {
    "node_type": "mySQLAgentMemory",
    "name": "mySQLAgentMemory",
    "label": "MySQL Agent Memory",
    "category": "Memory",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-host-string",
        "name": "host",
        "label": "host",
        "type": "string",
        "optional": true,
        "description": "Host"
      },
      {
        "id": "{nodeId}-input-database-string",
        "name": "database",
        "label": "database",
        "type": "string",
        "optional": true,
        "description": "Database"
      },
      {
        "id": "{nodeId}-input-port-number",
        "name": "port",
        "label": "port",
        "type": "number",
        "optional": true,
        "default": "3306",
        "description": "Port"
      },
      {
        "id": "{nodeId}-input-additionalConfig-json",
        "name": "additionalConfig",
        "label": "additionalConfig",
        "type": "json",
        "optional": true,
        "description": "Additional Connection Configuration"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-mySQLAgentMemory-AgentMemory|BaseCheckpointSaver",
        "name": "mySQLAgentMemory",
        "label": "MySQL Agent Memory",
        "type": "AgentMemory | BaseCheckpointSaver"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Memory for agentflow to remember the state of the conversation using MySQL database",
    "baseClasses": [
      "AgentMemory",
      "BaseCheckpointSaver"
    ],
    "credential_required": [
      "MySQLApi"
    ]
  },
  {
    "node_type": "postgresAgentMemory",
    "name": "postgresAgentMemory",
    "label": "Postgres Agent Memory",
    "category": "Memory",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-host-string",
        "name": "host",
        "label": "host",
        "type": "string",
        "optional": true,
        "description": "Host"
      },
      {
        "id": "{nodeId}-input-database-string",
        "name": "database",
        "label": "database",
        "type": "string",
        "optional": true,
        "description": "Database"
      },
      {
        "id": "{nodeId}-input-port-number",
        "name": "port",
        "label": "port",
        "type": "number",
        "optional": true,
        "default": "5432",
        "description": "Port"
      },
      {
        "id": "{nodeId}-input-additionalConfig-json",
        "name": "additionalConfig",
        "label": "additionalConfig",
        "type": "json",
        "optional": true,
        "description": "Additional Connection Configuration"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-postgresAgentMemory-AgentMemory|BaseCheckpointSaver",
        "name": "postgresAgentMemory",
        "label": "Postgres Agent Memory",
        "type": "AgentMemory | BaseCheckpointSaver"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Memory for agentflow to remember the state of the conversation using Postgres database",
    "baseClasses": [
      "AgentMemory",
      "BaseCheckpointSaver"
    ],
    "credential_required": [
      "PostgresApi"
    ]
  },
  {
    "node_type": "sqliteAgentMemory",
    "name": "sqliteAgentMemory",
    "label": "SQLite Agent Memory",
    "category": "Memory",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-additionalConfig-json",
        "name": "additionalConfig",
        "label": "additionalConfig",
        "type": "json",
        "optional": true,
        "description": "Additional Connection Configuration"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-sqliteAgentMemory-SQLiteAgentMemory|BaseCheckpointSaver",
        "name": "sqliteAgentMemory",
        "label": "SQLite Agent Memory",
        "type": "SQLiteAgentMemory | BaseCheckpointSaver"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Memory for agentflow to remember the state of the conversation using SQLite database",
    "baseClasses": [
      "SQLiteAgentMemory",
      "BaseCheckpointSaver"
    ]
  },
  {
    "node_type": "upstashRedisBackedChatMemory",
    "name": "upstashRedisBackedChatMemory",
    "label": "Upstash Redis-Backed Chat Memory",
    "category": "Memory",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-baseURL-string",
        "name": "baseURL",
        "label": "baseURL",
        "type": "string",
        "optional": true,
        "description": "Upstash Redis REST URL"
      },
      {
        "id": "{nodeId}-input-sessionId-string",
        "name": "sessionId",
        "label": "sessionId",
        "type": "string",
        "optional": true,
        "description": "If not specified, a random id will be used. Learn <a target=\"_blank\" href=\"https://docs.flowiseai.co"
      },
      {
        "id": "{nodeId}-input-sessionTTL-number",
        "name": "sessionTTL",
        "label": "sessionTTL",
        "type": "number",
        "optional": true,
        "description": "Seconds till a session expires. If not specified, the session will never expire."
      },
      {
        "id": "{nodeId}-input-memoryKey-string",
        "name": "memoryKey",
        "label": "memoryKey",
        "type": "string",
        "optional": true,
        "default": "chat_history",
        "description": "Memory Key"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-upstashRedisBackedChatMemory-UpstashRedisBackedChatMemory|BaseChatMemory|BaseMemory",
        "name": "upstashRedisBackedChatMemory",
        "label": "Upstash Redis-Backed Chat Memory",
        "type": "UpstashRedisBackedChatMemory | BaseChatMemory | BaseMemory"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Summarizes the conversation and stores the memory in Upstash Redis server",
    "baseClasses": [
      "UpstashRedisBackedChatMemory",
      "BaseChatMemory",
      "BaseMemory"
    ],
    "credential_required": [
      "upstashRedisMemoryApi"
    ]
  },
  {
    "node_type": "inputModerationOpenAI",
    "name": "inputModerationOpenAI",
    "label": "OpenAI Moderation",
    "category": "Moderation",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-moderationErrorMessage-string",
        "name": "moderationErrorMessage",
        "label": "moderationErrorMessage",
        "type": "string",
        "optional": true,
        "default": "Cannot Process! Input violates OpenAI's content moderation policies.",
        "description": "Error Message"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-inputModerationOpenAI-Moderation",
        "name": "inputModerationOpenAI",
        "label": "OpenAI Moderation",
        "type": "Moderation"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Check whether content complies with OpenAI usage policies.",
    "baseClasses": [
      "Moderation"
    ],
    "credential_required": [
      "openAIApi"
    ]
  },
  {
    "node_type": "inputModerationSimple",
    "name": "inputModerationSimple",
    "label": "Simple Prompt Moderation",
    "category": "Moderation",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-model-BaseChatModel",
        "name": "model",
        "label": "model",
        "type": "BaseChatModel",
        "optional": true,
        "description": "Use LLM to detect if the input is similar to those specified in Deny List"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-denyList-string",
        "name": "denyList",
        "label": "denyList",
        "type": "string",
        "optional": true,
        "description": "An array of string literals (enter one per line) that should not appear in the prompt text."
      },
      {
        "id": "{nodeId}-input-moderationErrorMessage-string",
        "name": "moderationErrorMessage",
        "label": "moderationErrorMessage",
        "type": "string",
        "optional": true,
        "default": "Cannot Process! Input violates content moderation policies.",
        "description": "Error Message"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-inputModerationSimple-Moderation",
        "name": "inputModerationSimple",
        "label": "Simple Prompt Moderation",
        "type": "Moderation"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Check whether input consists of any text from Deny list, and prevent being sent to LLM",
    "baseClasses": [
      "Moderation"
    ]
  },
  {
    "node_type": "supervisor",
    "name": "supervisor",
    "label": "Supervisor",
    "category": "Multi Agents",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-model-BaseChatModel",
        "name": "model",
        "label": "model",
        "type": "BaseChatModel",
        "optional": true,
        "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthr"
      },
      {
        "id": "{nodeId}-input-agentMemory-BaseCheckpointSaver",
        "name": "agentMemory",
        "label": "agentMemory",
        "type": "BaseCheckpointSaver",
        "optional": true,
        "description": "Save the state of the agent"
      },
      {
        "id": "{nodeId}-input-inputModeration-Moderation",
        "name": "inputModeration",
        "label": "inputModeration",
        "type": "Moderation",
        "optional": true,
        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-supervisorName-string",
        "name": "supervisorName",
        "label": "supervisorName",
        "type": "string",
        "optional": true,
        "default": "Supervisor",
        "description": "Supervisor Name"
      },
      {
        "id": "{nodeId}-input-supervisorPrompt-string",
        "name": "supervisorPrompt",
        "label": "supervisorPrompt",
        "type": "string",
        "optional": true,
        "description": "Given the following user request, respond with the worker to act next. Each worker will perform a task and respond with their results and status. When finished, respond with FINISH. Select strategical"
      },
      {
        "id": "{nodeId}-input-summarization-boolean",
        "name": "summarization",
        "label": "summarization",
        "type": "boolean",
        "optional": true,
        "description": "Return final output as a summarization of the conversation"
      },
      {
        "id": "{nodeId}-input-recursionLimit-number",
        "name": "recursionLimit",
        "label": "recursionLimit",
        "type": "number",
        "optional": true,
        "default": "100",
        "description": "Maximum number of times a call can recurse. If not provided, defaults to 100."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-supervisor-Supervisor",
        "name": "supervisor",
        "label": "Supervisor",
        "type": "Supervisor"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "3",
    "description": "No description",
    "baseClasses": [
      "Supervisor"
    ]
  },
  {
    "node_type": "worker",
    "name": "worker",
    "label": "Worker",
    "category": "Multi Agents",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-tools-Tool",
        "name": "tools",
        "label": "tools",
        "type": "Tool",
        "optional": true,
        "description": "Tools"
      },
      {
        "id": "{nodeId}-input-supervisor-Supervisor",
        "name": "supervisor",
        "label": "supervisor",
        "type": "Supervisor",
        "optional": true,
        "description": "Supervisor"
      },
      {
        "id": "{nodeId}-input-model-BaseChatModel",
        "name": "model",
        "label": "model",
        "type": "BaseChatModel",
        "optional": true,
        "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthr"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-workerName-string",
        "name": "workerName",
        "label": "workerName",
        "type": "string",
        "optional": true,
        "description": "Worker Name"
      },
      {
        "id": "{nodeId}-input-workerPrompt-string",
        "name": "workerPrompt",
        "label": "workerPrompt",
        "type": "string",
        "optional": true,
        "default": "You are a research assistant who can search for up-to-date info using search engine.",
        "description": "Worker Prompt"
      },
      {
        "id": "{nodeId}-input-promptValues-json",
        "name": "promptValues",
        "label": "promptValues",
        "type": "json",
        "optional": true,
        "description": "Format Prompt Values"
      },
      {
        "id": "{nodeId}-input-maxIterations-number",
        "name": "maxIterations",
        "label": "maxIterations",
        "type": "number",
        "optional": true,
        "description": "Max Iterations"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-worker-Worker",
        "name": "worker",
        "label": "Worker",
        "type": "Worker"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "No description",
    "baseClasses": [
      "Worker"
    ]
  },
  {
    "node_type": "advancedStructuredOutputParser",
    "name": "advancedStructuredOutputParser",
    "label": "Advanced Structured Output Parser",
    "category": "Output Parsers",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-autofixParser-boolean",
        "name": "autofixParser",
        "label": "autofixParser",
        "type": "boolean",
        "optional": true,
        "description": "In the event that the first call fails, will make another call to the model to fix any errors."
      },
      {
        "id": "{nodeId}-input-exampleJson-string",
        "name": "exampleJson",
        "label": "exampleJson",
        "type": "string",
        "optional": true,
        "description": "title: z.string(), // Title of the movie as a string yearOfRelease: z.number().int(), // Release year as an integer number, genres: z.enum([ \"Action\", \"Comedy\", \"Drama\", \"Fantasy\", \"Horror\", \"Mystery\""
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-advancedStructuredOutputParser-AdvancedStructuredOutputParser|BaseLLMOutputParser|Runnable",
        "name": "advancedStructuredOutputParser",
        "label": "Advanced Structured Output Parser",
        "type": "AdvancedStructuredOutputParser | BaseLLMOutputParser | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Parse the output of an LLM call into a given structure by providing a Zod schema.",
    "baseClasses": [
      "AdvancedStructuredOutputParser",
      "BaseLLMOutputParser",
      "Runnable"
    ]
  },
  {
    "node_type": "csvOutputParser",
    "name": "csvOutputParser",
    "label": "CSV Output Parser",
    "category": "Output Parsers",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-autofixParser-boolean",
        "name": "autofixParser",
        "label": "autofixParser",
        "type": "boolean",
        "optional": true,
        "description": "In the event that the first call fails, will make another call to the model to fix any errors."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-csvOutputParser-CSVListOutputParser|BaseLLMOutputParser|Runnable",
        "name": "csvOutputParser",
        "label": "CSV Output Parser",
        "type": "CSVListOutputParser | BaseLLMOutputParser | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Parse the output of an LLM call as a comma-separated list of values",
    "baseClasses": [
      "CSVListOutputParser",
      "BaseLLMOutputParser",
      "Runnable"
    ]
  },
  {
    "node_type": "customListOutputParser",
    "name": "customListOutputParser",
    "label": "Custom List Output Parser",
    "category": "Output Parsers",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-length-number",
        "name": "length",
        "label": "length",
        "type": "number",
        "optional": true,
        "description": "Number of values to return"
      },
      {
        "id": "{nodeId}-input-separator-string",
        "name": "separator",
        "label": "separator",
        "type": "string",
        "optional": true,
        "default": ",",
        "description": "Separator between values"
      },
      {
        "id": "{nodeId}-input-autofixParser-boolean",
        "name": "autofixParser",
        "label": "autofixParser",
        "type": "boolean",
        "optional": true,
        "description": "In the event that the first call fails, will make another call to the model to fix any errors."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-customListOutputParser-CustomListOutputParser|BaseLLMOutputParser|Runnable",
        "name": "customListOutputParser",
        "label": "Custom List Output Parser",
        "type": "CustomListOutputParser | BaseLLMOutputParser | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Parse the output of an LLM call as a list of values.",
    "baseClasses": [
      "CustomListOutputParser",
      "BaseLLMOutputParser",
      "Runnable"
    ]
  },
  {
    "node_type": "structuredOutputParser",
    "name": "structuredOutputParser",
    "label": "Structured Output Parser",
    "category": "Output Parsers",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-autofixParser-boolean",
        "name": "autofixParser",
        "label": "autofixParser",
        "type": "boolean",
        "optional": true,
        "description": "In the event that the first call fails, will make another call to the model to fix any errors."
      },
      {
        "id": "{nodeId}-input-jsonStructure-datagrid",
        "name": "jsonStructure",
        "label": "jsonStructure",
        "type": "datagrid",
        "optional": true,
        "default": "[{'property': 'answer', 'type': 'string', 'description': \"answer to the user's question\"}, {'property': 'source', 'type': 'string', 'description': 'sources used to answer the question, should be websites'}]",
        "description": "JSON structure for LLM to return"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-structuredOutputParser-StructuredOutputParser|BaseLLMOutputParser|Runnable",
        "name": "structuredOutputParser",
        "label": "Structured Output Parser",
        "type": "StructuredOutputParser | BaseLLMOutputParser | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Parse the output of an LLM call into a given (JSON) structure.",
    "baseClasses": [
      "StructuredOutputParser",
      "BaseLLMOutputParser",
      "Runnable"
    ]
  },
  {
    "node_type": "chatPromptTemplate",
    "name": "chatPromptTemplate",
    "label": "Chat Prompt Template",
    "category": "Prompts",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-systemMessagePrompt-string",
        "name": "systemMessagePrompt",
        "label": "systemMessagePrompt",
        "type": "string",
        "optional": true,
        "description": "System Message"
      },
      {
        "id": "{nodeId}-input-humanMessagePrompt-string",
        "name": "humanMessagePrompt",
        "label": "humanMessagePrompt",
        "type": "string",
        "optional": true,
        "description": "This prompt will be added at the end of the messages as human message"
      },
      {
        "id": "{nodeId}-input-promptValues-json",
        "name": "promptValues",
        "label": "promptValues",
        "type": "json",
        "optional": true,
        "description": "Format Prompt Values"
      },
      {
        "id": "{nodeId}-input-messageHistory-tabs",
        "name": "messageHistory",
        "label": "messageHistory",
        "type": "tabs",
        "optional": true,
        "default": "messageHistoryCode",
        "description": "Add messages after System Message. This is useful when you want to provide few shot examples"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-chatPromptTemplate-ChatPromptTemplate|BaseChatPromptTemplate|BasePromptTemplate|Runnable",
        "name": "chatPromptTemplate",
        "label": "Chat Prompt Template",
        "type": "ChatPromptTemplate | BaseChatPromptTemplate | BasePromptTemplate | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Schema to represent a chat prompt",
    "baseClasses": [
      "ChatPromptTemplate",
      "BaseChatPromptTemplate",
      "BasePromptTemplate",
      "Runnable"
    ]
  },
  {
    "node_type": "fewShotPromptTemplate",
    "name": "fewShotPromptTemplate",
    "label": "Few Shot Prompt Template",
    "category": "Prompts",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-examplePrompt-PromptTemplate",
        "name": "examplePrompt",
        "label": "examplePrompt",
        "type": "PromptTemplate",
        "optional": true,
        "description": "Example Prompt"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-examples-string",
        "name": "examples",
        "label": "examples",
        "type": "string",
        "optional": true,
        "description": "Examples"
      },
      {
        "id": "{nodeId}-input-prefix-string",
        "name": "prefix",
        "label": "prefix",
        "type": "string",
        "optional": true,
        "description": "Prefix"
      },
      {
        "id": "{nodeId}-input-suffix-string",
        "name": "suffix",
        "label": "suffix",
        "type": "string",
        "optional": true,
        "description": "Suffix"
      },
      {
        "id": "{nodeId}-input-exampleSeparator-string",
        "name": "exampleSeparator",
        "label": "exampleSeparator",
        "type": "string",
        "optional": true,
        "description": "Example Separator"
      },
      {
        "id": "{nodeId}-input-templateFormat-options",
        "name": "templateFormat",
        "label": "templateFormat",
        "type": "options",
        "optional": true,
        "default": "f-string",
        "description": "Template Format"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-fewShotPromptTemplate-FewShotPromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable",
        "name": "fewShotPromptTemplate",
        "label": "Few Shot Prompt Template",
        "type": "FewShotPromptTemplate | BaseStringPromptTemplate | BasePromptTemplate | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Prompt template you can build with examples",
    "baseClasses": [
      "FewShotPromptTemplate",
      "BaseStringPromptTemplate",
      "BasePromptTemplate",
      "Runnable"
    ]
  },
  {
    "node_type": "promptTemplate",
    "name": "promptTemplate",
    "label": "Prompt Template",
    "category": "Prompts",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-template-string",
        "name": "template",
        "label": "template",
        "type": "string",
        "optional": true,
        "description": "Template"
      },
      {
        "id": "{nodeId}-input-promptValues-json",
        "name": "promptValues",
        "label": "promptValues",
        "type": "json",
        "optional": true,
        "description": "Format Prompt Values"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable",
        "name": "promptTemplate",
        "label": "Prompt Template",
        "type": "PromptTemplate | BaseStringPromptTemplate | BasePromptTemplate | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Schema to represent a basic prompt for an LLM",
    "baseClasses": [
      "PromptTemplate",
      "BaseStringPromptTemplate",
      "BasePromptTemplate",
      "Runnable"
    ]
  },
  {
    "node_type": "MySQLRecordManager",
    "name": "MySQLRecordManager",
    "label": "MySQL Record Manager",
    "category": "Record Manager",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-host-string",
        "name": "host",
        "label": "host",
        "type": "string",
        "optional": true,
        "description": "Host"
      },
      {
        "id": "{nodeId}-input-database-string",
        "name": "database",
        "label": "database",
        "type": "string",
        "optional": true,
        "description": "Database"
      },
      {
        "id": "{nodeId}-input-port-number",
        "name": "port",
        "label": "port",
        "type": "number",
        "optional": true,
        "description": "Port"
      },
      {
        "id": "{nodeId}-input-additionalConfig-json",
        "name": "additionalConfig",
        "label": "additionalConfig",
        "type": "json",
        "optional": true,
        "description": "Additional Connection Configuration"
      },
      {
        "id": "{nodeId}-input-tableName-string",
        "name": "tableName",
        "label": "tableName",
        "type": "string",
        "optional": true,
        "description": "Table Name"
      },
      {
        "id": "{nodeId}-input-namespace-string",
        "name": "namespace",
        "label": "namespace",
        "type": "string",
        "optional": true,
        "description": "Namespace"
      },
      {
        "id": "{nodeId}-input-cleanup-options",
        "name": "cleanup",
        "label": "cleanup",
        "type": "options",
        "optional": true,
        "default": "none",
        "description": "Read more on the difference between different cleanup methods <a target=\"_blank\" href=\"https://js.la"
      },
      {
        "id": "{nodeId}-input-sourceIdKey-string",
        "name": "sourceIdKey",
        "label": "sourceIdKey",
        "type": "string",
        "optional": true,
        "default": "source",
        "description": "Key used to get the true source of document, to be compared against the record. Document metadata mu"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-MySQLRecordManager-MySQL RecordManager|RecordManager",
        "name": "MySQLRecordManager",
        "label": "MySQL Record Manager",
        "type": "MySQL RecordManager | RecordManager"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Use MySQL to keep track of document writes into the vector databases",
    "baseClasses": [
      "MySQL RecordManager",
      "RecordManager"
    ],
    "credential_required": [
      "MySQLApi"
    ]
  },
  {
    "node_type": "SQLiteRecordManager",
    "name": "SQLiteRecordManager",
    "label": "SQLite Record Manager",
    "category": "Record Manager",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-additionalConfig-json",
        "name": "additionalConfig",
        "label": "additionalConfig",
        "type": "json",
        "optional": true,
        "description": "Additional Connection Configuration"
      },
      {
        "id": "{nodeId}-input-tableName-string",
        "name": "tableName",
        "label": "tableName",
        "type": "string",
        "optional": true,
        "description": "Table Name"
      },
      {
        "id": "{nodeId}-input-namespace-string",
        "name": "namespace",
        "label": "namespace",
        "type": "string",
        "optional": true,
        "description": "Namespace"
      },
      {
        "id": "{nodeId}-input-cleanup-options",
        "name": "cleanup",
        "label": "cleanup",
        "type": "options",
        "optional": true,
        "default": "none",
        "description": "Read more on the difference between different cleanup methods <a target=\"_blank\" href=\"https://js.la"
      },
      {
        "id": "{nodeId}-input-sourceIdKey-string",
        "name": "sourceIdKey",
        "label": "sourceIdKey",
        "type": "string",
        "optional": true,
        "default": "source",
        "description": "Key used to get the true source of document, to be compared against the record. Document metadata mu"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-SQLiteRecordManager-SQLite RecordManager|RecordManager",
        "name": "SQLiteRecordManager",
        "label": "SQLite Record Manager",
        "type": "SQLite RecordManager | RecordManager"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1.1",
    "description": "Use SQLite to keep track of document writes into the vector databases",
    "baseClasses": [
      "SQLite RecordManager",
      "RecordManager"
    ]
  },
  {
    "node_type": "postgresRecordManager",
    "name": "postgresRecordManager",
    "label": "Postgres Record Manager",
    "category": "Record Manager",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-host-string",
        "name": "host",
        "label": "host",
        "type": "string",
        "optional": false,
        "description": "Host"
      },
      {
        "id": "{nodeId}-input-database-string",
        "name": "database",
        "label": "database",
        "type": "string",
        "optional": false,
        "description": "Database"
      },
      {
        "id": "{nodeId}-input-port-number",
        "name": "port",
        "label": "port",
        "type": "number",
        "optional": true,
        "description": "Port"
      },
      {
        "id": "{nodeId}-input-ssl-boolean",
        "name": "ssl",
        "label": "ssl",
        "type": "boolean",
        "optional": true,
        "description": "Use SSL to connect to Postgres"
      },
      {
        "id": "{nodeId}-input-additionalConfig-json",
        "name": "additionalConfig",
        "label": "additionalConfig",
        "type": "json",
        "optional": true,
        "description": "Additional Connection Configuration"
      },
      {
        "id": "{nodeId}-input-tableName-string",
        "name": "tableName",
        "label": "tableName",
        "type": "string",
        "optional": true,
        "description": "Table Name"
      },
      {
        "id": "{nodeId}-input-namespace-string",
        "name": "namespace",
        "label": "namespace",
        "type": "string",
        "optional": true,
        "description": "Namespace"
      },
      {
        "id": "{nodeId}-input-cleanup-options",
        "name": "cleanup",
        "label": "cleanup",
        "type": "options",
        "optional": true,
        "default": "none",
        "description": "Read more on the difference between different cleanup methods <a target=\"_blank\" href=\"https://js.la"
      },
      {
        "id": "{nodeId}-input-sourceIdKey-string",
        "name": "sourceIdKey",
        "label": "sourceIdKey",
        "type": "string",
        "optional": true,
        "default": "source",
        "description": "Key used to get the true source of document, to be compared against the record. Document metadata mu"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-postgresRecordManager-Postgres RecordManager|RecordManager",
        "name": "postgresRecordManager",
        "label": "Postgres Record Manager",
        "type": "Postgres RecordManager | RecordManager"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Use Postgres to keep track of document writes into the vector databases",
    "baseClasses": [
      "Postgres RecordManager",
      "RecordManager"
    ],
    "credential_required": [
      "PostgresApi"
    ]
  },
  {
    "node_type": "compactrefineLlamaIndex",
    "name": "compactrefineLlamaIndex",
    "label": "Compact and Refine",
    "category": "Response Synthesizer",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-refinePrompt-string",
        "name": "refinePrompt",
        "label": "refinePrompt",
        "type": "string",
        "optional": true,
        "description": "We have provided an existing answer: {existingAnswer} We have the opportunity to refine the existing answer (only if needed) with some more context below."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-compactrefineLlamaIndex-CompactRefine|ResponseSynthesizer",
        "name": "compactrefineLlamaIndex",
        "label": "Compact and Refine",
        "type": "CompactRefine | ResponseSynthesizer"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "CompactRefine is a slight variation of Refine that first compacts the text chunks into the smallest possible number of chunks.",
    "baseClasses": [
      "CompactRefine",
      "ResponseSynthesizer"
    ]
  },
  {
    "node_type": "refineLlamaIndex",
    "name": "refineLlamaIndex",
    "label": "Refine",
    "category": "Response Synthesizer",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-refinePrompt-string",
        "name": "refinePrompt",
        "label": "refinePrompt",
        "type": "string",
        "optional": true,
        "description": "We have provided an existing answer: {existingAnswer} We have the opportunity to refine the existing answer (only if needed) with some more context below."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-refineLlamaIndex-Refine|ResponseSynthesizer",
        "name": "refineLlamaIndex",
        "label": "Refine",
        "type": "Refine | ResponseSynthesizer"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Create and refine an answer by sequentially going through each retrieved text chunk. This makes a separate LLM call per Node. Good for more detailed answers.",
    "baseClasses": [
      "Refine",
      "ResponseSynthesizer"
    ]
  },
  {
    "node_type": "simpleResponseBuilderLlamaIndex",
    "name": "simpleResponseBuilderLlamaIndex",
    "label": "Simple Response Builder",
    "category": "Response Synthesizer",
    "inputAnchors": [],
    "inputParams": [],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-simpleResponseBuilderLlamaIndex-SimpleResponseBuilder|ResponseSynthesizer",
        "name": "simpleResponseBuilderLlamaIndex",
        "label": "Simple Response Builder",
        "type": "SimpleResponseBuilder | ResponseSynthesizer"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Apply a query to a collection of text chunks, gathering the responses in an array, and return a combined string of all responses. Useful for individual queries on each text chunk.",
    "baseClasses": [
      "SimpleResponseBuilder",
      "ResponseSynthesizer"
    ]
  },
  {
    "node_type": "treeSummarizeLlamaIndex",
    "name": "treeSummarizeLlamaIndex",
    "label": "TreeSummarize",
    "category": "Response Synthesizer",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-prompt-string",
        "name": "prompt",
        "label": "prompt",
        "type": "string",
        "optional": true
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-treeSummarizeLlamaIndex-TreeSummarize|ResponseSynthesizer",
        "name": "treeSummarizeLlamaIndex",
        "label": "TreeSummarize",
        "type": "TreeSummarize | ResponseSynthesizer"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Given a set of text chunks and the query, recursively construct a tree and return the root node as the response. Good for summarization purposes.",
    "baseClasses": [
      "TreeSummarize",
      "ResponseSynthesizer"
    ]
  },
  {
    "node_type": "AzureRerankRetriever",
    "name": "AzureRerankRetriever",
    "label": "Azure Rerank Retriever",
    "category": "Retrievers",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-baseRetriever-VectorStoreRetriever",
        "name": "baseRetriever",
        "label": "baseRetriever",
        "type": "VectorStoreRetriever",
        "optional": true,
        "description": "Vector Store Retriever"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-model-options",
        "name": "model",
        "label": "model",
        "type": "options",
        "optional": true,
        "default": "Cohere-rerank-v4.0-fast",
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-query-string",
        "name": "query",
        "label": "query",
        "type": "string",
        "optional": true,
        "description": "Query to retrieve documents from retriever. If not specified, user question will be used"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Number of top results to fetch. Default to the TopK of the Base Retriever"
      },
      {
        "id": "{nodeId}-input-maxChunksPerDoc-number",
        "name": "maxChunksPerDoc",
        "label": "maxChunksPerDoc",
        "type": "number",
        "optional": true,
        "description": "The maximum number of chunks to produce internally from a document. Default to 10"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-AzureRerankRetriever-Azure Rerank Retriever|BaseRetriever",
        "name": "AzureRerankRetriever",
        "label": "Azure Rerank Retriever",
        "type": "Azure Rerank Retriever | BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Azure Rerank indexes the documents from most to least semantically relevant to the query.",
    "baseClasses": [
      "Azure Rerank Retriever",
      "BaseRetriever"
    ],
    "credential_required": [
      "azureFoundryApi"
    ]
  },
  {
    "node_type": "HydeRetriever",
    "name": "HydeRetriever",
    "label": "HyDE Retriever",
    "category": "Retrievers",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-model-BaseLanguageModel",
        "name": "model",
        "label": "model",
        "type": "BaseLanguageModel",
        "optional": true,
        "description": "Language Model"
      },
      {
        "id": "{nodeId}-input-vectorStore-VectorStore",
        "name": "vectorStore",
        "label": "vectorStore",
        "type": "VectorStore",
        "optional": true,
        "description": "Vector Store"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-query-string",
        "name": "query",
        "label": "query",
        "type": "string",
        "optional": true,
        "description": "Query to retrieve documents from retriever. If not specified, user question will be used"
      },
      {
        "id": "{nodeId}-input-promptKey-options",
        "name": "promptKey",
        "label": "promptKey",
        "type": "options",
        "optional": true,
        "default": "websearch",
        "description": "Select a pre-defined prompt"
      },
      {
        "id": "{nodeId}-input-customPrompt-string",
        "name": "customPrompt",
        "label": "customPrompt",
        "type": "string",
        "optional": true,
        "description": "If custom prompt is used, this will override Defined Prompt"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "default": "4",
        "description": "Number of top results to fetch. Default to 4"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-HydeRetriever-HydeRetriever|BaseRetriever",
        "name": "HydeRetriever",
        "label": "HyDE Retriever",
        "type": "HydeRetriever | BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "3",
    "description": "Use HyDE retriever to retrieve from a vector store",
    "baseClasses": [
      "HydeRetriever",
      "BaseRetriever"
    ]
  },
  {
    "node_type": "JinaRerankRetriever",
    "name": "JinaRerankRetriever",
    "label": "Jina AI Rerank Retriever",
    "category": "Retrievers",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-baseRetriever-VectorStoreRetriever",
        "name": "baseRetriever",
        "label": "baseRetriever",
        "type": "VectorStoreRetriever",
        "optional": true,
        "description": "Vector Store Retriever"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-model-options",
        "name": "model",
        "label": "model",
        "type": "options",
        "optional": true,
        "default": "jina-reranker-v2-base-multilingual",
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-query-string",
        "name": "query",
        "label": "query",
        "type": "string",
        "optional": true,
        "description": "Query to retrieve documents from retriever. If not specified, user question will be used"
      },
      {
        "id": "{nodeId}-input-topN-number",
        "name": "topN",
        "label": "topN",
        "type": "number",
        "optional": true,
        "default": "4",
        "description": "Number of top results to fetch. Default to 4"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-JinaRerankRetriever-JinaRerankRetriever|BaseRetriever",
        "name": "JinaRerankRetriever",
        "label": "Jina AI Rerank Retriever",
        "type": "JinaRerankRetriever | BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Jina AI Rerank indexes the documents from most to least semantically relevant to the query.",
    "baseClasses": [
      "JinaRerankRetriever",
      "BaseRetriever"
    ],
    "credential_required": [
      "jinaAIApi"
    ]
  },
  {
    "node_type": "RRFRetriever",
    "name": "RRFRetriever",
    "label": "Reciprocal Rank Fusion Retriever",
    "category": "Retrievers",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-baseRetriever-VectorStoreRetriever",
        "name": "baseRetriever",
        "label": "baseRetriever",
        "type": "VectorStoreRetriever",
        "optional": true,
        "description": "Vector Store Retriever"
      },
      {
        "id": "{nodeId}-input-model-BaseLanguageModel",
        "name": "model",
        "label": "model",
        "type": "BaseLanguageModel",
        "optional": true,
        "description": "Language Model"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-query-string",
        "name": "query",
        "label": "query",
        "type": "string",
        "optional": true,
        "description": "Query to retrieve documents from retriever. If not specified, user question will be used"
      },
      {
        "id": "{nodeId}-input-queryCount-number",
        "name": "queryCount",
        "label": "queryCount",
        "type": "number",
        "optional": true,
        "default": "4",
        "description": "Number of synthetic queries to generate. Default to 4"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Number of top results to fetch. Default to the TopK of the Base Retriever"
      },
      {
        "id": "{nodeId}-input-c-number",
        "name": "c",
        "label": "c",
        "type": "number",
        "optional": true,
        "default": "60",
        "description": "A constant added to the rank, controlling the balance between the importance of high-ranked items an"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-RRFRetriever-RRFRetriever|BaseRetriever",
        "name": "RRFRetriever",
        "label": "Reciprocal Rank Fusion Retriever",
        "type": "RRFRetriever | BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Reciprocal Rank Fusion to re-rank search results by multiple query generation.",
    "baseClasses": [
      "RRFRetriever",
      "BaseRetriever"
    ]
  },
  {
    "node_type": "awsBedrockKBRetriever",
    "name": "awsBedrockKBRetriever",
    "label": "AWS Bedrock Knowledge Base Retriever",
    "category": "Retrievers",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-region-asyncOptions",
        "name": "region",
        "label": "region",
        "type": "asyncOptions",
        "optional": true,
        "default": "us-east-1",
        "description": "Region"
      },
      {
        "id": "{nodeId}-input-knoledgeBaseID-string",
        "name": "knoledgeBaseID",
        "label": "knoledgeBaseID",
        "type": "string",
        "optional": true,
        "description": "Knowledge Base ID"
      },
      {
        "id": "{nodeId}-input-query-string",
        "name": "query",
        "label": "query",
        "type": "string",
        "optional": true,
        "description": "Query to retrieve documents from retriever. If not specified, user question will be used"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "default": "5",
        "description": "Number of chunks to retrieve"
      },
      {
        "id": "{nodeId}-input-searchType-options",
        "name": "searchType",
        "label": "searchType",
        "type": "options",
        "optional": true,
        "description": "Knowledge Base search type. Possible values are HYBRID and SEMANTIC. If not specified, default will"
      },
      {
        "id": "{nodeId}-input-filter-string",
        "name": "filter",
        "label": "filter",
        "type": "string",
        "optional": true,
        "description": "Knowledge Base retrieval filter. Read documentation for filter syntax"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-awsBedrockKBRetriever-AWSBedrockKBRetriever|BaseRetriever",
        "name": "awsBedrockKBRetriever",
        "label": "AWS Bedrock Knowledge Base Retriever",
        "type": "AWSBedrockKBRetriever | BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Connect to AWS Bedrock Knowledge Base API and retrieve relevant chunks",
    "baseClasses": [
      "AWSBedrockKBRetriever",
      "BaseRetriever"
    ],
    "credential_required": [
      "awsApi"
    ]
  },
  {
    "node_type": "cohereRerankRetriever",
    "name": "cohereRerankRetriever",
    "label": "Cohere Rerank Retriever",
    "category": "Retrievers",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-baseRetriever-VectorStoreRetriever",
        "name": "baseRetriever",
        "label": "baseRetriever",
        "type": "VectorStoreRetriever",
        "optional": true,
        "description": "Vector Store Retriever"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-model-options",
        "name": "model",
        "label": "model",
        "type": "options",
        "optional": true,
        "default": "rerank-v3.5",
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-query-string",
        "name": "query",
        "label": "query",
        "type": "string",
        "optional": true,
        "description": "Query to retrieve documents from retriever. If not specified, user question will be used"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Number of top results to fetch. Default to the TopK of the Base Retriever"
      },
      {
        "id": "{nodeId}-input-maxChunksPerDoc-number",
        "name": "maxChunksPerDoc",
        "label": "maxChunksPerDoc",
        "type": "number",
        "optional": true,
        "description": "The maximum number of chunks to produce internally from a document. Default to 10"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-cohereRerankRetriever-Cohere Rerank Retriever|BaseRetriever",
        "name": "cohereRerankRetriever",
        "label": "Cohere Rerank Retriever",
        "type": "Cohere Rerank Retriever | BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Cohere Rerank indexes the documents from most to least semantically relevant to the query.",
    "baseClasses": [
      "Cohere Rerank Retriever",
      "BaseRetriever"
    ],
    "credential_required": [
      "cohereApi"
    ]
  },
  {
    "node_type": "customRetriever",
    "name": "customRetriever",
    "label": "Custom Retriever",
    "category": "Retrievers",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-vectorStore-VectorStore",
        "name": "vectorStore",
        "label": "vectorStore",
        "type": "VectorStore",
        "optional": true,
        "description": "Vector Store"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-query-string",
        "name": "query",
        "label": "query",
        "type": "string",
        "optional": true,
        "description": "Query to retrieve documents from retriever. If not specified, user question will be used"
      },
      {
        "id": "{nodeId}-input-resultFormat-string",
        "name": "resultFormat",
        "label": "resultFormat",
        "type": "string",
        "optional": true,
        "description": "Source: {{metadata.source}} | Format to return the results in. Use {{context}} to insert the pageContent of the document and {{met |"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Number of top results to fetch. Default to vector store topK"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-customRetriever-CustomRetriever|BaseRetriever",
        "name": "customRetriever",
        "label": "Custom Retriever",
        "type": "CustomRetriever | BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Return results based on predefined format",
    "baseClasses": [
      "CustomRetriever",
      "BaseRetriever"
    ]
  },
  {
    "node_type": "embeddingsFilterRetriever",
    "name": "embeddingsFilterRetriever",
    "label": "Embeddings Filter Retriever",
    "category": "Retrievers",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-baseRetriever-VectorStoreRetriever",
        "name": "baseRetriever",
        "label": "baseRetriever",
        "type": "VectorStoreRetriever",
        "optional": true,
        "description": "Vector Store Retriever"
      },
      {
        "id": "{nodeId}-input-embeddings-Embeddings",
        "name": "embeddings",
        "label": "embeddings",
        "type": "Embeddings",
        "optional": true,
        "description": "Embeddings"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-query-string",
        "name": "query",
        "label": "query",
        "type": "string",
        "optional": true,
        "description": "Query to retrieve documents from retriever. If not specified, user question will be used"
      },
      {
        "id": "{nodeId}-input-similarityThreshold-number",
        "name": "similarityThreshold",
        "label": "similarityThreshold",
        "type": "number",
        "optional": true,
        "default": "0.8",
        "description": "Threshold for determining when two documents are similar enough to be considered redundant. Must be"
      },
      {
        "id": "{nodeId}-input-k-number",
        "name": "k",
        "label": "k",
        "type": "number",
        "optional": true,
        "default": "20",
        "description": "The number of relevant documents to return. Can be explicitly set to undefined, in which case simila"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-embeddingsFilterRetriever-EmbeddingsFilterRetriever|BaseRetriever",
        "name": "embeddingsFilterRetriever",
        "label": "Embeddings Filter Retriever",
        "type": "EmbeddingsFilterRetriever | BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "A document compressor that uses embeddings to drop documents unrelated to the query",
    "baseClasses": [
      "EmbeddingsFilterRetriever",
      "BaseRetriever"
    ]
  },
  {
    "node_type": "extractMetadataRetriever",
    "name": "extractMetadataRetriever",
    "label": "Extract Metadata Retriever",
    "category": "Retrievers",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-vectorStore-VectorStore",
        "name": "vectorStore",
        "label": "vectorStore",
        "type": "VectorStore",
        "optional": true,
        "description": "Vector Store"
      },
      {
        "id": "{nodeId}-input-model-BaseChatModel",
        "name": "model",
        "label": "model",
        "type": "BaseChatModel",
        "optional": true,
        "description": "Chat Model"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-query-string",
        "name": "query",
        "label": "query",
        "type": "string",
        "optional": true,
        "description": "Query to retrieve documents from retriever. If not specified, user question will be used"
      },
      {
        "id": "{nodeId}-input-dynamicMetadataFilterRetrieverPrompt-string",
        "name": "dynamicMetadataFilterRetrieverPrompt",
        "label": "dynamicMetadataFilterRetrieverPrompt",
        "type": "string",
        "optional": true,
        "default": "Extract keywords from the query: {{query}}",
        "description": "Prompt to extract metadata from query"
      },
      {
        "id": "{nodeId}-input-dynamicMetadataFilterRetrieverStructuredOutput-datagrid",
        "name": "dynamicMetadataFilterRetrieverStructuredOutput",
        "label": "dynamicMetadataFilterRetrieverStructuredOutput",
        "type": "datagrid",
        "optional": true,
        "description": "Instruct the model to give output in a JSON structured schema. This output will be used as the metad"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Number of top results to fetch. Default to vector store topK"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-extractMetadataRetriever-ExtractMetadataRetriever|BaseRetriever",
        "name": "extractMetadataRetriever",
        "label": "Extract Metadata Retriever",
        "type": "ExtractMetadataRetriever | BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Extract keywords/metadata from the query and use it to filter documents",
    "baseClasses": [
      "ExtractMetadataRetriever",
      "BaseRetriever"
    ]
  },
  {
    "node_type": "llmFilterRetriever",
    "name": "llmFilterRetriever",
    "label": "LLM Filter Retriever",
    "category": "Retrievers",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-baseRetriever-VectorStoreRetriever",
        "name": "baseRetriever",
        "label": "baseRetriever",
        "type": "VectorStoreRetriever",
        "optional": true,
        "description": "Vector Store Retriever"
      },
      {
        "id": "{nodeId}-input-model-BaseLanguageModel",
        "name": "model",
        "label": "model",
        "type": "BaseLanguageModel",
        "optional": true,
        "description": "Language Model"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-query-string",
        "name": "query",
        "label": "query",
        "type": "string",
        "optional": true,
        "description": "Query to retrieve documents from retriever. If not specified, user question will be used"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-llmFilterRetriever-LLMFilterRetriever|BaseRetriever",
        "name": "llmFilterRetriever",
        "label": "LLM Filter Retriever",
        "type": "LLMFilterRetriever | BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Iterate over the initially returned documents and extract, from each, only the content that is relevant to the query",
    "baseClasses": [
      "LLMFilterRetriever",
      "BaseRetriever"
    ]
  },
  {
    "node_type": "multiQueryRetriever",
    "name": "multiQueryRetriever",
    "label": "Multi Query Retriever",
    "category": "Retrievers",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-vectorStore-VectorStore",
        "name": "vectorStore",
        "label": "vectorStore",
        "type": "VectorStore",
        "optional": true,
        "description": "Vector Store"
      },
      {
        "id": "{nodeId}-input-model-BaseLanguageModel",
        "name": "model",
        "label": "model",
        "type": "BaseLanguageModel",
        "optional": true,
        "description": "Language Model"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-modelPrompt-string",
        "name": "modelPrompt",
        "label": "modelPrompt",
        "type": "string",
        "optional": true,
        "description": "to generate 3 different versions of the given user question to retrieve relevant documents from a vector database. By generating multiple perspectives on the user question, your goal is to help the us"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-multiQueryRetriever-MultiQueryRetriever|BaseRetriever",
        "name": "multiQueryRetriever",
        "label": "Multi Query Retriever",
        "type": "MultiQueryRetriever | BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Generate multiple queries from different perspectives for a given user input query",
    "baseClasses": [
      "MultiQueryRetriever",
      "BaseRetriever"
    ]
  },
  {
    "node_type": "promptRetriever",
    "name": "promptRetriever",
    "label": "Prompt Retriever",
    "category": "Retrievers",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-name-string",
        "name": "name",
        "label": "name",
        "type": "string",
        "optional": true,
        "description": "Prompt Name"
      },
      {
        "id": "{nodeId}-input-description-string",
        "name": "description",
        "label": "description",
        "type": "string",
        "optional": true,
        "description": "Description of what the prompt does and when it should be used"
      },
      {
        "id": "{nodeId}-input-systemMessage-string",
        "name": "systemMessage",
        "label": "systemMessage",
        "type": "string",
        "optional": true,
        "description": "Prompt System Message"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-promptRetriever-PromptRetriever",
        "name": "promptRetriever",
        "label": "Prompt Retriever",
        "type": "PromptRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Store prompt template with name & description to be later queried by MultiPromptChain",
    "baseClasses": [
      "PromptRetriever"
    ]
  },
  {
    "node_type": "similarityThresholdRetriever",
    "name": "similarityThresholdRetriever",
    "label": "Similarity Score Threshold Retriever",
    "category": "Retrievers",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-vectorStore-VectorStore",
        "name": "vectorStore",
        "label": "vectorStore",
        "type": "VectorStore",
        "optional": true,
        "description": "Vector Store"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-query-string",
        "name": "query",
        "label": "query",
        "type": "string",
        "optional": true,
        "description": "Query to retrieve documents from retriever. If not specified, user question will be used"
      },
      {
        "id": "{nodeId}-input-minSimilarityScore-number",
        "name": "minSimilarityScore",
        "label": "minSimilarityScore",
        "type": "number",
        "optional": true,
        "default": "80",
        "description": "Finds results with at least this similarity score"
      },
      {
        "id": "{nodeId}-input-maxK-number",
        "name": "maxK",
        "label": "maxK",
        "type": "number",
        "optional": true,
        "default": "20",
        "description": "The maximum number of results to fetch"
      },
      {
        "id": "{nodeId}-input-kIncrement-number",
        "name": "kIncrement",
        "label": "kIncrement",
        "type": "number",
        "optional": true,
        "default": "2",
        "description": "How much to increase K by each time. It'll fetch N results, then N + kIncrement, then N + kIncrement"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-similarityThresholdRetriever-SimilarityThresholdRetriever|BaseRetriever",
        "name": "similarityThresholdRetriever",
        "label": "Similarity Score Threshold Retriever",
        "type": "SimilarityThresholdRetriever | BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Return results based on the minimum similarity percentage",
    "baseClasses": [
      "SimilarityThresholdRetriever",
      "BaseRetriever"
    ]
  },
  {
    "node_type": "vectorStoreRetriever",
    "name": "vectorStoreRetriever",
    "label": "Vector Store Retriever",
    "category": "Retrievers",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-vectorStore-VectorStore",
        "name": "vectorStore",
        "label": "vectorStore",
        "type": "VectorStore",
        "optional": true,
        "description": "Vector Store"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-name-string",
        "name": "name",
        "label": "name",
        "type": "string",
        "optional": true,
        "description": "Retriever Name"
      },
      {
        "id": "{nodeId}-input-description-string",
        "name": "description",
        "label": "description",
        "type": "string",
        "optional": true,
        "description": "Description of when to use the vector store retriever"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-vectorStoreRetriever-VectorStoreRetriever",
        "name": "vectorStoreRetriever",
        "label": "Vector Store Retriever",
        "type": "VectorStoreRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Store vector store as retriever to be later queried by MultiRetrievalQAChain",
    "baseClasses": [
      "VectorStoreRetriever"
    ]
  },
  {
    "node_type": "voyageAIRerankRetriever",
    "name": "voyageAIRerankRetriever",
    "label": "Voyage AI Rerank Retriever",
    "category": "Retrievers",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-baseRetriever-VectorStoreRetriever",
        "name": "baseRetriever",
        "label": "baseRetriever",
        "type": "VectorStoreRetriever",
        "optional": true,
        "description": "Vector Store Retriever"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-model-options",
        "name": "model",
        "label": "model",
        "type": "options",
        "optional": true,
        "default": "rerank-lite-1",
        "description": "Model Name"
      },
      {
        "id": "{nodeId}-input-query-string",
        "name": "query",
        "label": "query",
        "type": "string",
        "optional": true,
        "description": "Query to retrieve documents from retriever. If not specified, user question will be used"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Number of top results to fetch. Default to the TopK of the Base Retriever"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-voyageAIRerankRetriever-VoyageAIRerankRetriever|BaseRetriever",
        "name": "voyageAIRerankRetriever",
        "label": "Voyage AI Rerank Retriever",
        "type": "VoyageAIRerankRetriever | BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Voyage AI Rerank indexes the documents from most to least semantically relevant to the query.",
    "baseClasses": [
      "VoyageAIRerankRetriever",
      "BaseRetriever"
    ],
    "credential_required": [
      "voyageAIApi"
    ]
  },
  {
    "node_type": "seqAgent",
    "name": "seqAgent",
    "label": "Agent",
    "category": "Sequential Agents",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-tools-Tool",
        "name": "tools",
        "label": "tools",
        "type": "Tool",
        "optional": true,
        "description": "Tools"
      },
      {
        "id": "{nodeId}-input-sequentialNode-Start",
        "name": "sequentialNode",
        "label": "sequentialNode",
        "type": "Start",
        "optional": true,
        "default": "Agent",
        "description": "Condition"
      },
      {
        "id": "{nodeId}-input-model-BaseChatModel",
        "name": "model",
        "label": "model",
        "type": "BaseChatModel",
        "optional": true,
        "description": "Overwrite model to be used for this agent"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-agentName-string",
        "name": "agentName",
        "label": "agentName",
        "type": "string",
        "optional": true,
        "description": "Agent Name"
      },
      {
        "id": "{nodeId}-input-systemMessagePrompt-string",
        "name": "systemMessagePrompt",
        "label": "systemMessagePrompt",
        "type": "string",
        "optional": true,
        "default": "You are a research assistant who can search for up-to-date info using search engine.",
        "description": "System Prompt"
      },
      {
        "id": "{nodeId}-input-interrupt-boolean",
        "name": "interrupt",
        "label": "interrupt",
        "type": "boolean",
        "optional": true,
        "description": "If enabled, the agent will prompt th |"
      },
      {
        "id": "{nodeId}-input-promptValues-json",
        "name": "promptValues",
        "label": "promptValues",
        "type": "json",
        "optional": true,
        "description": "Assign values to the prompt variables. You can also use $flow.state. to get the state"
      },
      {
        "id": "{nodeId}-input-messageHistory-code",
        "name": "messageHistory",
        "label": "messageHistory",
        "type": "code",
        "optional": true,
        "description": "Prepend a list of messages between System Prompt and Human Prompt. This is useful when you want to p"
      },
      {
        "id": "{nodeId}-input-conversationHistorySelection-options",
        "name": "conversationHistorySelection",
        "label": "conversationHistorySelection",
        "type": "options",
        "optional": true,
        "default": "all_messages",
        "description": "Select which messages from the conversation history to include in the prompt. The selected messages"
      },
      {
        "id": "{nodeId}-input-humanMessagePrompt-string",
        "name": "humanMessagePrompt",
        "label": "humanMessagePrompt",
        "type": "string",
        "optional": true,
        "description": "This prompt will be added at the end of the messages as human message"
      },
      {
        "id": "{nodeId}-input-approvalPrompt-string",
        "name": "approvalPrompt",
        "label": "approvalPrompt",
        "type": "string",
        "optional": true,
        "default": "You are about to execute tool: {tools}. Ask if user want to proceed",
        "description": "Prompt for approval. Only applicable if \"Require Approval\" is enabled"
      },
      {
        "id": "{nodeId}-input-approveButtonText-string",
        "name": "approveButtonText",
        "label": "approveButtonText",
        "type": "string",
        "optional": true,
        "default": "Yes",
        "description": "Text for approve button. Only applicable if \"Require Approval\" is enabled"
      },
      {
        "id": "{nodeId}-input-rejectButtonText-string",
        "name": "rejectButtonText",
        "label": "rejectButtonText",
        "type": "string",
        "optional": true,
        "default": "No",
        "description": "Text for reject button. Only applicable if \"Require Approval\" is enabled"
      },
      {
        "id": "{nodeId}-input-updateStateMemory-tabs",
        "name": "updateStateMemory",
        "label": "updateStateMemory",
        "type": "tabs",
        "optional": true,
        "default": "updateStateMemoryUI",
        "description": "Update State"
      },
      {
        "id": "{nodeId}-input-maxIterations-number",
        "name": "maxIterations",
        "label": "maxIterations",
        "type": "number",
        "optional": true,
        "description": "Max Iterations"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-seqAgent-Agent",
        "name": "seqAgent",
        "label": "Agent",
        "type": "Agent"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "4.1",
    "description": "Agent that can execute tools",
    "baseClasses": [
      "Agent"
    ]
  },
  {
    "node_type": "seqCondition",
    "name": "seqCondition",
    "label": "Condition",
    "category": "Sequential Agents",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-sequentialNode-Start",
        "name": "sequentialNode",
        "label": "sequentialNode",
        "type": "Start",
        "optional": true,
        "default": "Agent",
        "description": "LLMNode"
      },
      {
        "id": "{nodeId}-input-condition-conditionFunction",
        "name": "condition",
        "label": "condition",
        "type": "conditionFunction",
        "optional": true,
        "description": "Condition"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-conditionName-string",
        "name": "conditionName",
        "label": "conditionName",
        "type": "string",
        "optional": true,
        "description": "Condition Name"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-seqCondition-Condition",
        "name": "seqCondition",
        "label": "Condition",
        "type": "Condition"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2.1",
    "description": "Conditional function to determine which route to take next",
    "baseClasses": [
      "Condition"
    ]
  },
  {
    "node_type": "seqConditionAgent",
    "name": "seqConditionAgent",
    "label": "Condition Agent",
    "category": "Sequential Agents",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-sequentialNode-Start",
        "name": "sequentialNode",
        "label": "sequentialNode",
        "type": "Start",
        "optional": true,
        "default": "Agent",
        "description": "LLMNode"
      },
      {
        "id": "{nodeId}-input-model-BaseChatModel",
        "name": "model",
        "label": "model",
        "type": "BaseChatModel",
        "optional": true,
        "description": "Overwrite model to be used for this agent"
      },
      {
        "id": "{nodeId}-input-condition-conditionFunction",
        "name": "condition",
        "label": "condition",
        "type": "conditionFunction",
        "optional": true,
        "description": "Condition"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-conditionAgentName-string",
        "name": "conditionAgentName",
        "label": "conditionAgentName",
        "type": "string",
        "optional": true,
        "description": "Name"
      },
      {
        "id": "{nodeId}-input-systemMessagePrompt-string",
        "name": "systemMessagePrompt",
        "label": "systemMessagePrompt",
        "type": "string",
        "optional": true,
        "description": "Your job is to detect whether a customer support representative is routing a user to the technical support team, or just responding conversationally. | System Prompt |"
      },
      {
        "id": "{nodeId}-input-conversationHistorySelection-options",
        "name": "conversationHistorySelection",
        "label": "conversationHistorySelection",
        "type": "options",
        "optional": true,
        "default": "all_messages",
        "description": "Select which messages from the conversation history to include in the prompt. The selected messages"
      },
      {
        "id": "{nodeId}-input-humanMessagePrompt-string",
        "name": "humanMessagePrompt",
        "label": "humanMessagePrompt",
        "type": "string",
        "optional": true,
        "description": "Extract whether the representative is routing the user to the technical support team, or just responding conversationally."
      },
      {
        "id": "{nodeId}-input-promptValues-json",
        "name": "promptValues",
        "label": "promptValues",
        "type": "json",
        "optional": true,
        "description": "Assign values to the prompt variables. You can also use $flow.state. to get the state"
      },
      {
        "id": "{nodeId}-input-conditionAgentStructuredOutput-datagrid",
        "name": "conditionAgentStructuredOutput",
        "label": "conditionAgentStructuredOutput",
        "type": "datagrid",
        "optional": true,
        "description": "Instruct the LLM to give output in a JSON structured schema"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-seqConditionAgent-ConditionAgent",
        "name": "seqConditionAgent",
        "label": "Condition Agent",
        "type": "ConditionAgent"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "3.1",
    "description": "Uses an agent to determine which route to take next",
    "baseClasses": [
      "ConditionAgent"
    ]
  },
  {
    "node_type": "seqCustomFunction",
    "name": "seqCustomFunction",
    "label": "Custom JS Function",
    "category": "Sequential Agents",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-sequentialNode-Start",
        "name": "sequentialNode",
        "label": "sequentialNode",
        "type": "Start",
        "optional": true,
        "default": "Agent",
        "description": "Condition"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-functionInputVariables-json",
        "name": "functionInputVariables",
        "label": "functionInputVariables",
        "type": "json",
        "optional": true,
        "description": "Input variables can be used in the function with prefix $. For example: $var"
      },
      {
        "id": "{nodeId}-input-functionName-string",
        "name": "functionName",
        "label": "functionName",
        "type": "string",
        "optional": true,
        "description": "Function Name"
      },
      {
        "id": "{nodeId}-input-javascriptFunction-code",
        "name": "javascriptFunction",
        "label": "javascriptFunction",
        "type": "code",
        "optional": true,
        "description": "Javascript Function"
      },
      {
        "id": "{nodeId}-input-returnValueAs-options",
        "name": "returnValueAs",
        "label": "returnValueAs",
        "type": "options",
        "optional": true,
        "default": "aiMessage",
        "description": "Return Value As"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-seqCustomFunction-CustomFunction",
        "name": "seqCustomFunction",
        "label": "Custom JS Function",
        "type": "CustomFunction"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Execute custom javascript function",
    "baseClasses": [
      "CustomFunction"
    ]
  },
  {
    "node_type": "seqEnd",
    "name": "seqEnd",
    "label": "End",
    "category": "Sequential Agents",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-sequentialNode-Agent",
        "name": "sequentialNode",
        "label": "sequentialNode",
        "type": "Agent",
        "optional": true,
        "default": "Condition",
        "description": "LLMNode"
      }
    ],
    "inputParams": [],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-seqEnd-End",
        "name": "seqEnd",
        "label": "End",
        "type": "End"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2.1",
    "description": "End conversation",
    "baseClasses": [
      "End"
    ]
  },
  {
    "node_type": "seqExecuteFlow",
    "name": "seqExecuteFlow",
    "label": "Execute Flow",
    "category": "Sequential Agents",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-sequentialNode-Start",
        "name": "sequentialNode",
        "label": "sequentialNode",
        "type": "Start",
        "optional": true,
        "default": "Agent",
        "description": "Condition"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-seqExecuteFlowName-string",
        "name": "seqExecuteFlowName",
        "label": "seqExecuteFlowName",
        "type": "string",
        "optional": true,
        "description": "Name"
      },
      {
        "id": "{nodeId}-input-selectedFlow-asyncOptions",
        "name": "selectedFlow",
        "label": "selectedFlow",
        "type": "asyncOptions",
        "optional": true,
        "description": "Select Flow"
      },
      {
        "id": "{nodeId}-input-seqExecuteFlowInput-options",
        "name": "seqExecuteFlowInput",
        "label": "seqExecuteFlowInput",
        "type": "options",
        "optional": true,
        "description": "Select one of the following or enter custom input"
      },
      {
        "id": "{nodeId}-input-returnValueAs-options",
        "name": "returnValueAs",
        "label": "returnValueAs",
        "type": "options",
        "optional": true,
        "default": "aiMessage",
        "description": "Return Value As"
      },
      {
        "id": "{nodeId}-input-overrideConfig-json",
        "name": "overrideConfig",
        "label": "overrideConfig",
        "type": "json",
        "optional": true,
        "description": "Override the config passed to the flow."
      },
      {
        "id": "{nodeId}-input-baseURL-string",
        "name": "baseURL",
        "label": "baseURL",
        "type": "string",
        "optional": true,
        "description": "Base URL to Flowise. By default, it is the URL of the incoming request. Useful when you need to exec"
      },
      {
        "id": "{nodeId}-input-startNewSession-boolean",
        "name": "startNewSession",
        "label": "startNewSession",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Whether to continue the session or start a new one with each interaction. Useful for flows with memo"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-seqExecuteFlow-ExecuteFlow",
        "name": "seqExecuteFlow",
        "label": "Execute Flow",
        "type": "ExecuteFlow"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Execute chatflow/agentflow and return final response",
    "baseClasses": [
      "ExecuteFlow"
    ],
    "credential_required": [
      "chatflowApi"
    ]
  },
  {
    "node_type": "seqLLMNode",
    "name": "seqLLMNode",
    "label": "LLM Node",
    "category": "Sequential Agents",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-sequentialNode-Start",
        "name": "sequentialNode",
        "label": "sequentialNode",
        "type": "Start",
        "optional": true,
        "default": "Agent",
        "description": "Condition"
      },
      {
        "id": "{nodeId}-input-model-BaseChatModel",
        "name": "model",
        "label": "model",
        "type": "BaseChatModel",
        "optional": true,
        "description": "Overwrite model to be used for this node"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-llmNodeName-string",
        "name": "llmNodeName",
        "label": "llmNodeName",
        "type": "string",
        "optional": true,
        "description": "Name"
      },
      {
        "id": "{nodeId}-input-systemMessagePrompt-string",
        "name": "systemMessagePrompt",
        "label": "systemMessagePrompt",
        "type": "string",
        "optional": true,
        "description": "System Prompt"
      },
      {
        "id": "{nodeId}-input-messageHistory-code",
        "name": "messageHistory",
        "label": "messageHistory",
        "type": "code",
        "optional": true,
        "description": "Prepend a list of messages between System Prompt and Human Prompt. This is useful when you want to p"
      },
      {
        "id": "{nodeId}-input-conversationHistorySelection-options",
        "name": "conversationHistorySelection",
        "label": "conversationHistorySelection",
        "type": "options",
        "optional": true,
        "default": "all_messages",
        "description": "Select which messages from the conversation history to include in the prompt. The selected messages"
      },
      {
        "id": "{nodeId}-input-humanMessagePrompt-string",
        "name": "humanMessagePrompt",
        "label": "humanMessagePrompt",
        "type": "string",
        "optional": true,
        "description": "This prompt will be added at the end of the messages as human message"
      },
      {
        "id": "{nodeId}-input-promptValues-json",
        "name": "promptValues",
        "label": "promptValues",
        "type": "json",
        "optional": true,
        "description": "Assign values to the prompt variables. You can also use $flow.state. to get the state"
      },
      {
        "id": "{nodeId}-input-llmStructuredOutput-datagrid",
        "name": "llmStructuredOutput",
        "label": "llmStructuredOutput",
        "type": "datagrid",
        "optional": true,
        "description": "Instruct the LLM to give output in a JSON structured schema"
      },
      {
        "id": "{nodeId}-input-updateStateMemory-tabs",
        "name": "updateStateMemory",
        "label": "updateStateMemory",
        "type": "tabs",
        "optional": true,
        "default": "updateStateMemoryUI",
        "description": "Update State"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-seqLLMNode-LLMNode",
        "name": "seqLLMNode",
        "label": "LLM Node",
        "type": "LLMNode"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "4.1",
    "description": "Run Chat Model and return the output",
    "baseClasses": [
      "LLMNode"
    ]
  },
  {
    "node_type": "seqLoop",
    "name": "seqLoop",
    "label": "Loop",
    "category": "Sequential Agents",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-sequentialNode-Agent",
        "name": "sequentialNode",
        "label": "sequentialNode",
        "type": "Agent",
        "optional": true,
        "default": "Condition",
        "description": "LLMNode"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-loopToName-string",
        "name": "loopToName",
        "label": "loopToName",
        "type": "string",
        "optional": true,
        "description": "Name of the agent/llm to loop back to"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-seqLoop-Loop",
        "name": "seqLoop",
        "label": "Loop",
        "type": "Loop"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2.1",
    "description": "Loop back to the specific sequential node",
    "baseClasses": [
      "Loop"
    ]
  },
  {
    "node_type": "seqStart",
    "name": "seqStart",
    "label": "Start",
    "category": "Sequential Agents",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-model-BaseChatModel",
        "name": "model",
        "label": "model",
        "type": "BaseChatModel",
        "optional": true,
        "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthr"
      },
      {
        "id": "{nodeId}-input-agentMemory-BaseCheckpointSaver",
        "name": "agentMemory",
        "label": "agentMemory",
        "type": "BaseCheckpointSaver",
        "optional": true,
        "description": "Save the state of the agent"
      },
      {
        "id": "{nodeId}-input-state-State",
        "name": "state",
        "label": "state",
        "type": "State",
        "optional": true,
        "description": "State is an object that is updated by nodes in the graph, passing from one node to another. By defau"
      },
      {
        "id": "{nodeId}-input-inputModeration-Moderation",
        "name": "inputModeration",
        "label": "inputModeration",
        "type": "Moderation",
        "optional": true,
        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model"
      }
    ],
    "inputParams": [],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-seqStart-Start",
        "name": "seqStart",
        "label": "Start",
        "type": "Start"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Starting point of the conversation",
    "baseClasses": [
      "Start"
    ]
  },
  {
    "node_type": "seqState",
    "name": "seqState",
    "label": "State",
    "category": "Sequential Agents",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-stateMemory-tabs",
        "name": "stateMemory",
        "label": "stateMemory",
        "type": "tabs",
        "optional": true,
        "default": "stateMemoryUI",
        "description": "Custom State"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-seqState-State",
        "name": "seqState",
        "label": "State",
        "type": "State"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "A centralized state object, updated by nodes in the graph, passing from one node to another",
    "baseClasses": [
      "State"
    ]
  },
  {
    "node_type": "seqToolNode",
    "name": "seqToolNode",
    "label": "Tool Node",
    "category": "Sequential Agents",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-tools-Tool",
        "name": "tools",
        "label": "tools",
        "type": "Tool",
        "optional": true,
        "description": "Tools"
      },
      {
        "id": "{nodeId}-input-llmNode-LLMNode",
        "name": "llmNode",
        "label": "llmNode",
        "type": "LLMNode",
        "optional": true,
        "description": "LLM Node"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-toolNodeName-string",
        "name": "toolNodeName",
        "label": "toolNodeName",
        "type": "string",
        "optional": true,
        "description": "Name"
      },
      {
        "id": "{nodeId}-input-interrupt-boolean",
        "name": "interrupt",
        "label": "interrupt",
        "type": "boolean",
        "optional": true,
        "description": "Require approval before executing tools"
      },
      {
        "id": "{nodeId}-input-approvalPrompt-string",
        "name": "approvalPrompt",
        "label": "approvalPrompt",
        "type": "string",
        "optional": true,
        "default": "You are about to execute tool: {tools}. Ask if user want to proceed",
        "description": "Prompt for approval. Only applicable if \"Require Approval\" is enabled"
      },
      {
        "id": "{nodeId}-input-approveButtonText-string",
        "name": "approveButtonText",
        "label": "approveButtonText",
        "type": "string",
        "optional": true,
        "default": "Yes",
        "description": "Text for approve button. Only applicable if \"Require Approval\" is enabled"
      },
      {
        "id": "{nodeId}-input-rejectButtonText-string",
        "name": "rejectButtonText",
        "label": "rejectButtonText",
        "type": "string",
        "optional": true,
        "default": "No",
        "description": "Text for reject button. Only applicable if \"Require Approval\" is enabled"
      },
      {
        "id": "{nodeId}-input-updateStateMemory-tabs",
        "name": "updateStateMemory",
        "label": "updateStateMemory",
        "type": "tabs",
        "optional": true,
        "default": "updateStateMemoryUI",
        "description": "Update State"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-seqToolNode-ToolNode",
        "name": "seqToolNode",
        "label": "Tool Node",
        "type": "ToolNode"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2.1",
    "description": "Execute tool and return tool's output",
    "baseClasses": [
      "ToolNode"
    ]
  },
  {
    "node_type": "characterTextSplitter",
    "name": "characterTextSplitter",
    "label": "Character Text Splitter",
    "category": "Text Splitters",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-chunkSize-number",
        "name": "chunkSize",
        "label": "chunkSize",
        "type": "number",
        "optional": true,
        "default": "1000",
        "description": "Number of characters in each chunk. Default is 1000."
      },
      {
        "id": "{nodeId}-input-chunkOverlap-number",
        "name": "chunkOverlap",
        "label": "chunkOverlap",
        "type": "number",
        "optional": true,
        "default": "200",
        "description": "Number of characters to overlap between chunks. Default is 200."
      },
      {
        "id": "{nodeId}-input-separator-string",
        "name": "separator",
        "label": "separator",
        "type": "string",
        "optional": true,
        "description": "Separator to determine when to split the text, will override the default separator"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-characterTextSplitter-CharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable",
        "name": "characterTextSplitter",
        "label": "Character Text Splitter",
        "type": "CharacterTextSplitter | TextSplitter | BaseDocumentTransformer | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "splits only on one type of character (defaults to \"\\n\\n\").",
    "baseClasses": [
      "CharacterTextSplitter",
      "TextSplitter",
      "BaseDocumentTransformer",
      "Runnable"
    ]
  },
  {
    "node_type": "codeTextSplitter",
    "name": "codeTextSplitter",
    "label": "Code Text Splitter",
    "category": "Text Splitters",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-language-options",
        "name": "language",
        "label": "language",
        "type": "options",
        "optional": true,
        "description": "Language"
      },
      {
        "id": "{nodeId}-input-chunkSize-number",
        "name": "chunkSize",
        "label": "chunkSize",
        "type": "number",
        "optional": true,
        "default": "1000",
        "description": "Number of characters in each chunk. Default is 1000."
      },
      {
        "id": "{nodeId}-input-chunkOverlap-number",
        "name": "chunkOverlap",
        "label": "chunkOverlap",
        "type": "number",
        "optional": true,
        "default": "200",
        "description": "Number of characters to overlap between chunks. Default is 200."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-codeTextSplitter-CodeTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable",
        "name": "codeTextSplitter",
        "label": "Code Text Splitter",
        "type": "CodeTextSplitter | TextSplitter | BaseDocumentTransformer | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Split documents based on language-specific syntax",
    "baseClasses": [
      "CodeTextSplitter",
      "TextSplitter",
      "BaseDocumentTransformer",
      "Runnable"
    ]
  },
  {
    "node_type": "htmlToMarkdownTextSplitter",
    "name": "htmlToMarkdownTextSplitter",
    "label": "HtmlToMarkdown Text Splitter",
    "category": "Text Splitters",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-chunkSize-number",
        "name": "chunkSize",
        "label": "chunkSize",
        "type": "number",
        "optional": true,
        "default": "1000",
        "description": "Number of characters in each chunk. Default is 1000."
      },
      {
        "id": "{nodeId}-input-chunkOverlap-number",
        "name": "chunkOverlap",
        "label": "chunkOverlap",
        "type": "number",
        "optional": true,
        "default": "200",
        "description": "Number of characters to overlap between chunks. Default is 200."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-htmlToMarkdownTextSplitter-HtmlToMarkdownTextSplitter|MarkdownTextSplitter|RecursiveCharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable",
        "name": "htmlToMarkdownTextSplitter",
        "label": "HtmlToMarkdown Text Splitter",
        "type": "HtmlToMarkdownTextSplitter | MarkdownTextSplitter | RecursiveCharacterTextSplitter | TextSplitter | BaseDocumentTransformer | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Converts Html to Markdown and then split your content into documents based on the Markdown headers",
    "baseClasses": [
      "HtmlToMarkdownTextSplitter",
      "MarkdownTextSplitter",
      "RecursiveCharacterTextSplitter",
      "TextSplitter",
      "BaseDocumentTransformer",
      "Runnable"
    ]
  },
  {
    "node_type": "markdownTextSplitter",
    "name": "markdownTextSplitter",
    "label": "Markdown Text Splitter",
    "category": "Text Splitters",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-chunkSize-number",
        "name": "chunkSize",
        "label": "chunkSize",
        "type": "number",
        "optional": true,
        "default": "1000",
        "description": "Number of characters in each chunk. Default is 1000."
      },
      {
        "id": "{nodeId}-input-chunkOverlap-number",
        "name": "chunkOverlap",
        "label": "chunkOverlap",
        "type": "number",
        "optional": true,
        "default": "200",
        "description": "Number of characters to overlap between chunks. Default is 200."
      },
      {
        "id": "{nodeId}-input-splitByHeaders-options",
        "name": "splitByHeaders",
        "label": "splitByHeaders",
        "type": "options",
        "optional": true,
        "default": "disabled",
        "description": "Split documents at specified header levels. Headers will be included with their content."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-markdownTextSplitter-MarkdownTextSplitter|RecursiveCharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable",
        "name": "markdownTextSplitter",
        "label": "Markdown Text Splitter",
        "type": "MarkdownTextSplitter | RecursiveCharacterTextSplitter | TextSplitter | BaseDocumentTransformer | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1.1",
    "description": "Split your content into documents based on the Markdown headers",
    "baseClasses": [
      "MarkdownTextSplitter",
      "RecursiveCharacterTextSplitter",
      "TextSplitter",
      "BaseDocumentTransformer",
      "Runnable"
    ]
  },
  {
    "node_type": "recursiveCharacterTextSplitter",
    "name": "recursiveCharacterTextSplitter",
    "label": "Recursive Character Text Splitter",
    "category": "Text Splitters",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-chunkSize-number",
        "name": "chunkSize",
        "label": "chunkSize",
        "type": "number",
        "optional": true,
        "default": "1000",
        "description": "Number of characters in each chunk. Default is 1000."
      },
      {
        "id": "{nodeId}-input-chunkOverlap-number",
        "name": "chunkOverlap",
        "label": "chunkOverlap",
        "type": "number",
        "optional": true,
        "default": "200",
        "description": "Number of characters to overlap between chunks. Default is 200."
      },
      {
        "id": "{nodeId}-input-separators-string",
        "name": "separators",
        "label": "separators",
        "type": "string",
        "optional": true,
        "description": "Array of custom separators to determine when to split the text, will override the default separators"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-recursiveCharacterTextSplitter-RecursiveCharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable",
        "name": "recursiveCharacterTextSplitter",
        "label": "Recursive Character Text Splitter",
        "type": "RecursiveCharacterTextSplitter | TextSplitter | BaseDocumentTransformer | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Split documents recursively by different characters - starting with \"\\n\\n\", then \"\\n\", then \" \"",
    "baseClasses": [
      "RecursiveCharacterTextSplitter",
      "TextSplitter",
      "BaseDocumentTransformer",
      "Runnable"
    ]
  },
  {
    "node_type": "tokenTextSplitter",
    "name": "tokenTextSplitter",
    "label": "Token Text Splitter",
    "category": "Text Splitters",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-encodingName-options",
        "name": "encodingName",
        "label": "encodingName",
        "type": "options",
        "optional": true,
        "default": "gpt2",
        "description": "Encoding Name"
      },
      {
        "id": "{nodeId}-input-chunkSize-number",
        "name": "chunkSize",
        "label": "chunkSize",
        "type": "number",
        "optional": true,
        "default": "1000",
        "description": "Number of characters in each chunk. Default is 1000."
      },
      {
        "id": "{nodeId}-input-chunkOverlap-number",
        "name": "chunkOverlap",
        "label": "chunkOverlap",
        "type": "number",
        "optional": true,
        "default": "200",
        "description": "Number of characters to overlap between chunks. Default is 200."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-tokenTextSplitter-TokenTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable",
        "name": "tokenTextSplitter",
        "label": "Token Text Splitter",
        "type": "TokenTextSplitter | TextSplitter | BaseDocumentTransformer | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Splits a raw text string by first converting the text into BPE tokens, then split these tokens into chunks and convert the tokens within a single chunk back into text.",
    "baseClasses": [
      "TokenTextSplitter",
      "TextSplitter",
      "BaseDocumentTransformer",
      "Runnable"
    ]
  },
  {
    "node_type": "ChatflowTool",
    "name": "ChatflowTool",
    "label": "Chatflow Tool",
    "category": "Tools",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-selectedChatflow-asyncOptions",
        "name": "selectedChatflow",
        "label": "selectedChatflow",
        "type": "asyncOptions",
        "optional": true,
        "description": "Select Chatflow"
      },
      {
        "id": "{nodeId}-input-name-string",
        "name": "name",
        "label": "name",
        "type": "string",
        "optional": true,
        "description": "Tool Name"
      },
      {
        "id": "{nodeId}-input-description-string",
        "name": "description",
        "label": "description",
        "type": "string",
        "optional": true,
        "description": "Description of what the tool does. This is for LLM to determine when to use this tool."
      },
      {
        "id": "{nodeId}-input-returnDirect-boolean",
        "name": "returnDirect",
        "label": "returnDirect",
        "type": "boolean",
        "optional": true,
        "description": "Return Direct"
      },
      {
        "id": "{nodeId}-input-overrideConfig-json",
        "name": "overrideConfig",
        "label": "overrideConfig",
        "type": "json",
        "optional": true,
        "description": "Override the config passed to the Chatflow."
      },
      {
        "id": "{nodeId}-input-baseURL-string",
        "name": "baseURL",
        "label": "baseURL",
        "type": "string",
        "optional": true,
        "description": "Base URL to Flowise. By default, it is the URL of the incoming request. Useful when you need to exec"
      },
      {
        "id": "{nodeId}-input-startNewSession-boolean",
        "name": "startNewSession",
        "label": "startNewSession",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Whether to continue the session with the Chatflow tool or start a new one with each interaction. Use"
      },
      {
        "id": "{nodeId}-input-useQuestionFromChat-boolean",
        "name": "useQuestionFromChat",
        "label": "useQuestionFromChat",
        "type": "boolean",
        "optional": true,
        "description": "Whether to use the question from the chat as input to the chatflow. If turned on, this will override"
      },
      {
        "id": "{nodeId}-input-customInput-string",
        "name": "customInput",
        "label": "customInput",
        "type": "string",
        "optional": true,
        "description": "Custom input to be passed to the chatflow. Leave empty to let LLM decides the input."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-ChatflowTool-ChatflowTool|Tool",
        "name": "ChatflowTool",
        "label": "Chatflow Tool",
        "type": "ChatflowTool | Tool"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "5.1",
    "description": "Use as a tool to execute another chatflow",
    "baseClasses": [
      "ChatflowTool",
      "Tool"
    ],
    "credential_required": [
      "chatflowApi"
    ]
  },
  {
    "node_type": "agentAsTool",
    "name": "agentAsTool",
    "label": "Agent as Tool",
    "category": "Tools",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-selectedAgentflow-asyncOptions",
        "name": "selectedAgentflow",
        "label": "selectedAgentflow",
        "type": "asyncOptions",
        "optional": true,
        "description": "Select Agent"
      },
      {
        "id": "{nodeId}-input-name-string",
        "name": "name",
        "label": "name",
        "type": "string",
        "optional": true,
        "description": "Tool Name"
      },
      {
        "id": "{nodeId}-input-description-string",
        "name": "description",
        "label": "description",
        "type": "string",
        "optional": true,
        "description": "Description of what the tool does. This is for LLM to determine when to use this tool."
      },
      {
        "id": "{nodeId}-input-returnDirect-boolean",
        "name": "returnDirect",
        "label": "returnDirect",
        "type": "boolean",
        "optional": true,
        "description": "Return Direct"
      },
      {
        "id": "{nodeId}-input-overrideConfig-json",
        "name": "overrideConfig",
        "label": "overrideConfig",
        "type": "json",
        "optional": true,
        "description": "Override the config passed to the Agentflow."
      },
      {
        "id": "{nodeId}-input-baseURL-string",
        "name": "baseURL",
        "label": "baseURL",
        "type": "string",
        "optional": true,
        "description": "Base URL to Flowise. By default, it is the URL of the incoming request. Useful when you need to exec"
      },
      {
        "id": "{nodeId}-input-startNewSession-boolean",
        "name": "startNewSession",
        "label": "startNewSession",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Whether to continue the session with the Agentflow tool or start a new one with each interaction. Us"
      },
      {
        "id": "{nodeId}-input-useQuestionFromChat-boolean",
        "name": "useQuestionFromChat",
        "label": "useQuestionFromChat",
        "type": "boolean",
        "optional": true,
        "description": "Whether to use the question from the chat as input to the agentflow. If turned on, this will overrid"
      },
      {
        "id": "{nodeId}-input-customInput-string",
        "name": "customInput",
        "label": "customInput",
        "type": "string",
        "optional": true,
        "description": "Custom input to be passed to the agentflow. Leave empty to let LLM decides the input."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-agentAsTool-AgentAsTool|Tool",
        "name": "agentAsTool",
        "label": "Agent as Tool",
        "type": "AgentAsTool | Tool"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Use as a tool to execute another agentflow",
    "baseClasses": [
      "AgentAsTool",
      "Tool"
    ],
    "credential_required": [
      "agentflowApi"
    ]
  },
  {
    "node_type": "arxiv",
    "name": "arxiv",
    "label": "Arxiv",
    "category": "Tools",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-arxivName-string",
        "name": "arxivName",
        "label": "arxivName",
        "type": "string",
        "optional": true,
        "default": "arxiv_search",
        "description": "Name of the tool"
      },
      {
        "id": "{nodeId}-input-arxivDescription-string",
        "name": "arxivDescription",
        "label": "arxivDescription",
        "type": "string",
        "optional": true,
        "default": "Use this tool to search for academic papers on Arxiv. You can search by keywords, topics, authors, or specific Arxiv IDs. The tool can return either paper summaries or download and extract full paper content.",
        "description": "Describe to LLM when it should use this tool"
      },
      {
        "id": "{nodeId}-input-topKResults-number",
        "name": "topKResults",
        "label": "topKResults",
        "type": "number",
        "optional": true,
        "default": "3",
        "description": "Number of top results to return from Arxiv search"
      },
      {
        "id": "{nodeId}-input-maxQueryLength-number",
        "name": "maxQueryLength",
        "label": "maxQueryLength",
        "type": "number",
        "optional": true,
        "default": "300",
        "description": "Maximum length of the search query"
      },
      {
        "id": "{nodeId}-input-docContentCharsMax-number",
        "name": "docContentCharsMax",
        "label": "docContentCharsMax",
        "type": "number",
        "optional": true,
        "default": "10000",
        "description": "Maximum length of the returned content. Set to 0 for unlimited"
      },
      {
        "id": "{nodeId}-input-loadFullContent-boolean",
        "name": "loadFullContent",
        "label": "loadFullContent",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Download PDFs and extract full paper content instead of just summaries. Warning: This is slower and"
      },
      {
        "id": "{nodeId}-input-continueOnFailure-boolean",
        "name": "continueOnFailure",
        "label": "continueOnFailure",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Continue processing other papers if one fails to download/parse (only applies when Load Full Content"
      },
      {
        "id": "{nodeId}-input-legacyBuild-boolean",
        "name": "legacyBuild",
        "label": "legacyBuild",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Use legacy PDF.js build for PDF parsing (only applies when Load Full Content is enabled)"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-arxiv-Arxiv|DynamicStructuredTool|StructuredTool|Runnable",
        "name": "arxiv",
        "label": "Arxiv",
        "type": "Arxiv | DynamicStructuredTool | StructuredTool | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Search and read content from academic papers on Arxiv",
    "baseClasses": [
      "Arxiv",
      "DynamicStructuredTool",
      "StructuredTool",
      "Runnable"
    ]
  },
  {
    "node_type": "awsDynamoDBKVStorage",
    "name": "awsDynamoDBKVStorage",
    "label": "AWS DynamoDB KV Storage",
    "category": "Tools",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-region-options",
        "name": "region",
        "label": "region",
        "type": "options",
        "optional": true,
        "default": "us-east-1",
        "description": "AWS Region where your DynamoDB tables are located"
      },
      {
        "id": "{nodeId}-input-tableName-asyncOptions",
        "name": "tableName",
        "label": "tableName",
        "type": "asyncOptions",
        "optional": true,
        "description": "Select a DynamoDB table with partition key \"pk\" and sort key \"sk\""
      },
      {
        "id": "{nodeId}-input-operation-options",
        "name": "operation",
        "label": "operation",
        "type": "options",
        "optional": true,
        "default": "store",
        "description": "Choose whether to store or retrieve data"
      },
      {
        "id": "{nodeId}-input-keyPrefix-string",
        "name": "keyPrefix",
        "label": "keyPrefix",
        "type": "string",
        "optional": true,
        "description": "Optional prefix to add to all keys (e.g., \"myapp\" would make keys like \"myapp#userdata\")"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-awsDynamoDBKVStorage-AWSDynamoDBKVStorage|StructuredTool|Runnable",
        "name": "awsDynamoDBKVStorage",
        "label": "AWS DynamoDB KV Storage",
        "type": "AWSDynamoDBKVStorage | StructuredTool | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Store and retrieve versioned text values in AWS DynamoDB",
    "baseClasses": [
      "AWSDynamoDBKVStorage",
      "StructuredTool",
      "Runnable"
    ],
    "credential_required": [
      "awsApi"
    ]
  },
  {
    "node_type": "awsSNS",
    "name": "awsSNS",
    "label": "AWS SNS",
    "category": "Tools",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-region-options",
        "name": "region",
        "label": "region",
        "type": "options",
        "optional": true,
        "default": "us-east-1",
        "description": "AWS Region where your SNS topics are located"
      },
      {
        "id": "{nodeId}-input-topicArn-asyncOptions",
        "name": "topicArn",
        "label": "topicArn",
        "type": "asyncOptions",
        "optional": true,
        "description": "Select the SNS topic to publish to"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-awsSNS-AWSSNS|Tool|StructuredTool|Runnable",
        "name": "awsSNS",
        "label": "AWS SNS",
        "type": "AWSSNS | Tool | StructuredTool | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Publish messages to AWS SNS topics",
    "baseClasses": [
      "AWSSNS",
      "Tool",
      "StructuredTool",
      "Runnable"
    ],
    "credential_required": [
      "awsApi"
    ]
  },
  {
    "node_type": "braveSearchAPI",
    "name": "braveSearchAPI",
    "label": "BraveSearch API",
    "category": "Tools",
    "inputAnchors": [],
    "inputParams": [],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-braveSearchAPI-BraveSearchAPI|Tool|StructuredTool|Runnable",
        "name": "braveSearchAPI",
        "label": "BraveSearch API",
        "type": "BraveSearchAPI | Tool | StructuredTool | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Wrapper around BraveSearch API - a real-time API to access Brave search results",
    "baseClasses": [
      "BraveSearchAPI",
      "Tool",
      "StructuredTool",
      "Runnable"
    ],
    "credential_required": [
      "braveSearchApi"
    ]
  },
  {
    "node_type": "calculator",
    "name": "calculator",
    "label": "Calculator",
    "category": "Tools",
    "inputAnchors": [],
    "inputParams": [],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-calculator-Calculator|Tool|StructuredTool|Runnable",
        "name": "calculator",
        "label": "Calculator",
        "type": "Calculator | Tool | StructuredTool | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Perform calculations on response",
    "baseClasses": [
      "Calculator",
      "Tool",
      "StructuredTool",
      "Runnable"
    ]
  },
  {
    "node_type": "chainTool",
    "name": "chainTool",
    "label": "Chain Tool",
    "category": "Tools",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-baseChain-BaseChain",
        "name": "baseChain",
        "label": "baseChain",
        "type": "BaseChain",
        "optional": true,
        "description": "Base Chain"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-name-string",
        "name": "name",
        "label": "name",
        "type": "string",
        "optional": true,
        "description": "Chain Name"
      },
      {
        "id": "{nodeId}-input-description-string",
        "name": "description",
        "label": "description",
        "type": "string",
        "optional": true,
        "description": "Chain Description"
      },
      {
        "id": "{nodeId}-input-returnDirect-boolean",
        "name": "returnDirect",
        "label": "returnDirect",
        "type": "boolean",
        "optional": true,
        "description": "Return Direct"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-chainTool-ChainTool|DynamicTool|Tool|StructuredTool|Runnable",
        "name": "chainTool",
        "label": "Chain Tool",
        "type": "ChainTool | DynamicTool | Tool | StructuredTool | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Use a chain as allowed tool for agent",
    "baseClasses": [
      "ChainTool",
      "DynamicTool",
      "Tool",
      "StructuredTool",
      "Runnable"
    ]
  },
  {
    "node_type": "codeInterpreterE2B",
    "name": "codeInterpreterE2B",
    "label": "Code Interpreter by E2B",
    "category": "Tools",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-toolName-string",
        "name": "toolName",
        "label": "toolName",
        "type": "string",
        "optional": true,
        "default": "code_interpreter",
        "description": "Specify the name of the tool"
      },
      {
        "id": "{nodeId}-input-toolDesc-string",
        "name": "toolDesc",
        "label": "toolDesc",
        "type": "string",
        "optional": true,
        "default": "Evaluates python code in a sandbox environment. The environment is long running and exists across multiple executions. You must send the whole script every time and print your outputs. Script should be pure python code that can be evaluated. It should be in python format NOT markdown. The code shoul",
        "description": "Specify the description of the tool"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-codeInterpreterE2B-CodeInterpreter|Tool|StructuredTool|Runnable",
        "name": "codeInterpreterE2B",
        "label": "Code Interpreter by E2B",
        "type": "CodeInterpreter | Tool | StructuredTool | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Execute code in a sandbox environment",
    "baseClasses": [
      "CodeInterpreter",
      "Tool",
      "StructuredTool",
      "Runnable"
    ],
    "credential_required": [
      "E2BApi"
    ]
  },
  {
    "node_type": "composio",
    "name": "composio",
    "label": "Composio",
    "category": "Tools",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-actions-asyncMultiOptions",
        "name": "actions",
        "label": "actions",
        "type": "asyncMultiOptions",
        "optional": true,
        "description": "Select the actions you want to use"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-appName-asyncOptions",
        "name": "appName",
        "label": "appName",
        "type": "asyncOptions",
        "optional": true,
        "description": "Select the app to connect with"
      },
      {
        "id": "{nodeId}-input-connectedAccountId-asyncOptions",
        "name": "connectedAccountId",
        "label": "connectedAccountId",
        "type": "asyncOptions",
        "optional": true,
        "description": "Select which connection to use"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-composio-Composio|Tool|StructuredTool|Runnable",
        "name": "composio",
        "label": "Composio",
        "type": "Composio | Tool | StructuredTool | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Toolset with over 250+ Apps for building AI-powered applications",
    "baseClasses": [
      "Composio",
      "Tool",
      "StructuredTool",
      "Runnable"
    ],
    "credential_required": [
      "composioApi"
    ]
  },
  {
    "node_type": "currentDateTime",
    "name": "currentDateTime",
    "label": "CurrentDateTime",
    "category": "Tools",
    "inputAnchors": [],
    "inputParams": [],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-currentDateTime-CurrentDateTime|Tool",
        "name": "currentDateTime",
        "label": "CurrentDateTime",
        "type": "CurrentDateTime | Tool"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Get todays day, date and time.",
    "baseClasses": [
      "CurrentDateTime",
      "Tool"
    ]
  },
  {
    "node_type": "customTool",
    "name": "customTool",
    "label": "Custom Tool",
    "category": "Tools",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-selectedTool-asyncOptions",
        "name": "selectedTool",
        "label": "selectedTool",
        "type": "asyncOptions",
        "optional": true,
        "description": "Select Tool"
      },
      {
        "id": "{nodeId}-input-returnDirect-boolean",
        "name": "returnDirect",
        "label": "returnDirect",
        "type": "boolean",
        "optional": true,
        "description": "Return the output of the tool directly to the user"
      },
      {
        "id": "{nodeId}-input-customToolName-string",
        "name": "customToolName",
        "label": "customToolName",
        "type": "string",
        "optional": true,
        "description": "Custom Tool Name"
      },
      {
        "id": "{nodeId}-input-customToolDesc-string",
        "name": "customToolDesc",
        "label": "customToolDesc",
        "type": "string",
        "optional": true,
        "description": "Custom Tool Description"
      },
      {
        "id": "{nodeId}-input-customToolSchema-string",
        "name": "customToolSchema",
        "label": "customToolSchema",
        "type": "string",
        "optional": true,
        "description": "Custom Tool Schema"
      },
      {
        "id": "{nodeId}-input-customToolFunc-string",
        "name": "customToolFunc",
        "label": "customToolFunc",
        "type": "string",
        "optional": true,
        "description": "Custom Tool Func"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-customTool-CustomTool|Tool|StructuredTool|Runnable",
        "name": "customTool",
        "label": "Custom Tool",
        "type": "CustomTool | Tool | StructuredTool | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "3",
    "description": "Use custom tool you've created in Flowise within chatflow",
    "baseClasses": [
      "CustomTool",
      "Tool",
      "StructuredTool",
      "Runnable"
    ]
  },
  {
    "node_type": "exaSearch",
    "name": "exaSearch",
    "label": "Exa Search",
    "category": "Tools",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-description-string",
        "name": "description",
        "label": "description",
        "type": "string",
        "optional": true,
        "default": "A wrapper around Exa Search. Input should be an Exa-optimized query. Output is a JSON array of the query results",
        "description": "Description of what the tool does. This is for LLM to determine when to use this tool."
      },
      {
        "id": "{nodeId}-input-numResults-number",
        "name": "numResults",
        "label": "numResults",
        "type": "number",
        "optional": true,
        "description": "Number of search results to return. Default 10. Max 10 for basic plans. Up to thousands for custom p"
      },
      {
        "id": "{nodeId}-input-type-options",
        "name": "type",
        "label": "type",
        "type": "options",
        "optional": true,
        "description": "Search Type"
      },
      {
        "id": "{nodeId}-input-useAutoprompt-boolean",
        "name": "useAutoprompt",
        "label": "useAutoprompt",
        "type": "boolean",
        "optional": true,
        "description": "If true, your query will be converted to a Exa query. Default false."
      },
      {
        "id": "{nodeId}-input-category-options",
        "name": "category",
        "label": "category",
        "type": "options",
        "optional": true,
        "description": "A data category to focus on, with higher comprehensivity and data cleanliness. Categories right now"
      },
      {
        "id": "{nodeId}-input-includeDomains-string",
        "name": "includeDomains",
        "label": "includeDomains",
        "type": "string",
        "optional": true,
        "description": "List of domains to include in the search, separated by comma. If specified, results will only come f"
      },
      {
        "id": "{nodeId}-input-excludeDomains-string",
        "name": "excludeDomains",
        "label": "excludeDomains",
        "type": "string",
        "optional": true,
        "description": "List of domains to exclude in the search, separated by comma. If specified, results will not include"
      },
      {
        "id": "{nodeId}-input-startCrawlDate-string",
        "name": "startCrawlDate",
        "label": "startCrawlDate",
        "type": "string",
        "optional": true,
        "description": "Crawl date refers to the date that Exa discovered a link. Results will include links that were crawl"
      },
      {
        "id": "{nodeId}-input-endCrawlDate-string",
        "name": "endCrawlDate",
        "label": "endCrawlDate",
        "type": "string",
        "optional": true,
        "description": "Crawl date refers to the date that Exa discovered a link. Results will include links that were crawl"
      },
      {
        "id": "{nodeId}-input-startPublishedDate-string",
        "name": "startPublishedDate",
        "label": "startPublishedDate",
        "type": "string",
        "optional": true,
        "description": "Only links with a published date after this will be returned. Must be specified in ISO 8601 format."
      },
      {
        "id": "{nodeId}-input-endPublishedDate-string",
        "name": "endPublishedDate",
        "label": "endPublishedDate",
        "type": "string",
        "optional": true,
        "description": "Only links with a published date before this will be returned. Must be specified in ISO 8601 format."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-exaSearch-ExaSearch|Tool|StructuredTool|Runnable",
        "name": "exaSearch",
        "label": "Exa Search",
        "type": "ExaSearch | Tool | StructuredTool | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1.1",
    "description": "Wrapper around Exa Search API - search engine fully designed for use by LLMs",
    "baseClasses": [
      "ExaSearch",
      "Tool",
      "StructuredTool",
      "Runnable"
    ],
    "credential_required": [
      "exaSearchApi"
    ]
  },
  {
    "node_type": "gmail",
    "name": "gmail",
    "label": "Gmail",
    "category": "Tools",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-gmailType-options",
        "name": "gmailType",
        "label": "gmailType",
        "type": "options",
        "optional": true,
        "description": "Type"
      },
      {
        "id": "{nodeId}-input-draftActions-multiOptions",
        "name": "draftActions",
        "label": "draftActions",
        "type": "multiOptions",
        "optional": true,
        "description": "Draft Actions"
      },
      {
        "id": "{nodeId}-input-messageActions-multiOptions",
        "name": "messageActions",
        "label": "messageActions",
        "type": "multiOptions",
        "optional": true,
        "description": "Message Actions"
      },
      {
        "id": "{nodeId}-input-labelActions-multiOptions",
        "name": "labelActions",
        "label": "labelActions",
        "type": "multiOptions",
        "optional": true,
        "description": "Label Actions"
      },
      {
        "id": "{nodeId}-input-threadActions-multiOptions",
        "name": "threadActions",
        "label": "threadActions",
        "type": "multiOptions",
        "optional": true,
        "description": "Thread Actions"
      },
      {
        "id": "{nodeId}-input-draftMaxResults-number",
        "name": "draftMaxResults",
        "label": "draftMaxResults",
        "type": "number",
        "optional": true,
        "default": "100",
        "description": "Maximum number of drafts to return"
      },
      {
        "id": "{nodeId}-input-draftTo-string",
        "name": "draftTo",
        "label": "draftTo",
        "type": "string",
        "optional": true,
        "description": "Recipient email address(es), comma-separated"
      },
      {
        "id": "{nodeId}-input-draftSubject-string",
        "name": "draftSubject",
        "label": "draftSubject",
        "type": "string",
        "optional": true,
        "description": "Email subject"
      },
      {
        "id": "{nodeId}-input-draftBody-string",
        "name": "draftBody",
        "label": "draftBody",
        "type": "string",
        "optional": true,
        "description": "Email body content"
      },
      {
        "id": "{nodeId}-input-draftCc-string",
        "name": "draftCc",
        "label": "draftCc",
        "type": "string",
        "optional": true,
        "description": "CC email address(es), comma-separated"
      },
      {
        "id": "{nodeId}-input-draftBcc-string",
        "name": "draftBcc",
        "label": "draftBcc",
        "type": "string",
        "optional": true,
        "description": "BCC email address(es), comma-separated"
      },
      {
        "id": "{nodeId}-input-draftId-string",
        "name": "draftId",
        "label": "draftId",
        "type": "string",
        "optional": true,
        "description": "ID of the draft"
      },
      {
        "id": "{nodeId}-input-draftUpdateTo-string",
        "name": "draftUpdateTo",
        "label": "draftUpdateTo",
        "type": "string",
        "optional": true,
        "description": "Recipient email address(es), comma-separated"
      },
      {
        "id": "{nodeId}-input-draftUpdateSubject-string",
        "name": "draftUpdateSubject",
        "label": "draftUpdateSubject",
        "type": "string",
        "optional": true,
        "description": "Email subject"
      },
      {
        "id": "{nodeId}-input-draftUpdateBody-string",
        "name": "draftUpdateBody",
        "label": "draftUpdateBody",
        "type": "string",
        "optional": true,
        "description": "Email body content"
      },
      {
        "id": "{nodeId}-input-messageMaxResults-number",
        "name": "messageMaxResults",
        "label": "messageMaxResults",
        "type": "number",
        "optional": true,
        "default": "100",
        "description": "Maximum number of messages to return"
      },
      {
        "id": "{nodeId}-input-messageQuery-string",
        "name": "messageQuery",
        "label": "messageQuery",
        "type": "string",
        "optional": true,
        "description": "Query string for filtering results (Gmail search syntax)"
      },
      {
        "id": "{nodeId}-input-messageTo-string",
        "name": "messageTo",
        "label": "messageTo",
        "type": "string",
        "optional": true,
        "description": "Recipient email address(es), comma-separated"
      },
      {
        "id": "{nodeId}-input-messageSubject-string",
        "name": "messageSubject",
        "label": "messageSubject",
        "type": "string",
        "optional": true,
        "description": "Email subject"
      },
      {
        "id": "{nodeId}-input-messageBody-string",
        "name": "messageBody",
        "label": "messageBody",
        "type": "string",
        "optional": true,
        "description": "Email body content"
      },
      {
        "id": "{nodeId}-input-messageCc-string",
        "name": "messageCc",
        "label": "messageCc",
        "type": "string",
        "optional": true,
        "description": "CC email address(es), comma-separated"
      },
      {
        "id": "{nodeId}-input-messageBcc-string",
        "name": "messageBcc",
        "label": "messageBcc",
        "type": "string",
        "optional": true,
        "description": "BCC email address(es), comma-separated"
      },
      {
        "id": "{nodeId}-input-messageId-string",
        "name": "messageId",
        "label": "messageId",
        "type": "string",
        "optional": true,
        "description": "ID of the message"
      },
      {
        "id": "{nodeId}-input-messageAddLabelIds-string",
        "name": "messageAddLabelIds",
        "label": "messageAddLabelIds",
        "type": "string",
        "optional": true,
        "description": "Comma-separated label IDs to add"
      },
      {
        "id": "{nodeId}-input-messageRemoveLabelIds-string",
        "name": "messageRemoveLabelIds",
        "label": "messageRemoveLabelIds",
        "type": "string",
        "optional": true,
        "description": "Comma-separated label IDs to remove"
      },
      {
        "id": "{nodeId}-input-labelName-string",
        "name": "labelName",
        "label": "labelName",
        "type": "string",
        "optional": true,
        "description": "Name of the label"
      },
      {
        "id": "{nodeId}-input-labelColor-string",
        "name": "labelColor",
        "label": "labelColor",
        "type": "string",
        "optional": true,
        "description": "Color of the label (hex color code)"
      },
      {
        "id": "{nodeId}-input-labelId-string",
        "name": "labelId",
        "label": "labelId",
        "type": "string",
        "optional": true,
        "description": "ID of the label"
      },
      {
        "id": "{nodeId}-input-threadMaxResults-number",
        "name": "threadMaxResults",
        "label": "threadMaxResults",
        "type": "number",
        "optional": true,
        "default": "100",
        "description": "Maximum number of threads to return"
      },
      {
        "id": "{nodeId}-input-threadQuery-string",
        "name": "threadQuery",
        "label": "threadQuery",
        "type": "string",
        "optional": true,
        "description": "Query string for filtering results (Gmail search syntax)"
      },
      {
        "id": "{nodeId}-input-threadId-string",
        "name": "threadId",
        "label": "threadId",
        "type": "string",
        "optional": true,
        "description": "ID of the thread"
      },
      {
        "id": "{nodeId}-input-threadAddLabelIds-string",
        "name": "threadAddLabelIds",
        "label": "threadAddLabelIds",
        "type": "string",
        "optional": true,
        "description": "Comma-separated label IDs to add"
      },
      {
        "id": "{nodeId}-input-threadRemoveLabelIds-string",
        "name": "threadRemoveLabelIds",
        "label": "threadRemoveLabelIds",
        "type": "string",
        "optional": true,
        "description": "Comma-separated label IDs to remove"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-gmail-Gmail|Tool",
        "name": "gmail",
        "label": "Gmail",
        "type": "Gmail | Tool"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Perform Gmail operations for drafts, messages, labels, and threads",
    "baseClasses": [
      "Gmail",
      "Tool"
    ],
    "credential_required": [
      "gmailOAuth2"
    ]
  },
  {
    "node_type": "googleCalendarTool",
    "name": "googleCalendarTool",
    "label": "Google Calendar",
    "category": "Tools",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-calendarType-options",
        "name": "calendarType",
        "label": "calendarType",
        "type": "options",
        "optional": true,
        "description": "Type of Google Calendar operation"
      },
      {
        "id": "{nodeId}-input-eventActions-multiOptions",
        "name": "eventActions",
        "label": "eventActions",
        "type": "multiOptions",
        "optional": true,
        "description": "Actions to perform"
      },
      {
        "id": "{nodeId}-input-calendarActions-multiOptions",
        "name": "calendarActions",
        "label": "calendarActions",
        "type": "multiOptions",
        "optional": true,
        "description": "Actions to perform"
      },
      {
        "id": "{nodeId}-input-freebusyActions-multiOptions",
        "name": "freebusyActions",
        "label": "freebusyActions",
        "type": "multiOptions",
        "optional": true,
        "description": "Actions to perform"
      },
      {
        "id": "{nodeId}-input-calendarId-string",
        "name": "calendarId",
        "label": "calendarId",
        "type": "string",
        "optional": true,
        "default": "primary",
        "description": "Calendar ID (use \"primary\" for primary calendar)"
      },
      {
        "id": "{nodeId}-input-eventId-string",
        "name": "eventId",
        "label": "eventId",
        "type": "string",
        "optional": true,
        "description": "Event ID for operations on specific events"
      },
      {
        "id": "{nodeId}-input-summary-string",
        "name": "summary",
        "label": "summary",
        "type": "string",
        "optional": true,
        "description": "Event title/summary"
      },
      {
        "id": "{nodeId}-input-description-string",
        "name": "description",
        "label": "description",
        "type": "string",
        "optional": true,
        "description": "Event description"
      },
      {
        "id": "{nodeId}-input-location-string",
        "name": "location",
        "label": "location",
        "type": "string",
        "optional": true,
        "description": "Event location"
      },
      {
        "id": "{nodeId}-input-startDateTime-string",
        "name": "startDateTime",
        "label": "startDateTime",
        "type": "string",
        "optional": true,
        "description": "Event start time (ISO 8601 format: 2023-12-25T10:00:00)"
      },
      {
        "id": "{nodeId}-input-endDateTime-string",
        "name": "endDateTime",
        "label": "endDateTime",
        "type": "string",
        "optional": true,
        "description": "Event end time (ISO 8601 format: 2023-12-25T11:00:00)"
      },
      {
        "id": "{nodeId}-input-timeZone-string",
        "name": "timeZone",
        "label": "timeZone",
        "type": "string",
        "optional": true,
        "description": "Time zone (e.g., America/New_York)"
      },
      {
        "id": "{nodeId}-input-allDay-boolean",
        "name": "allDay",
        "label": "allDay",
        "type": "boolean",
        "optional": true,
        "description": "Whether this is an all-day event"
      },
      {
        "id": "{nodeId}-input-startDate-string",
        "name": "startDate",
        "label": "startDate",
        "type": "string",
        "optional": true,
        "description": "Start date for all-day events (YYYY-MM-DD format)"
      },
      {
        "id": "{nodeId}-input-endDate-string",
        "name": "endDate",
        "label": "endDate",
        "type": "string",
        "optional": true,
        "description": "End date for all-day events (YYYY-MM-DD format)"
      },
      {
        "id": "{nodeId}-input-attendees-string",
        "name": "attendees",
        "label": "attendees",
        "type": "string",
        "optional": true,
        "description": "Comma-separated list of attendee emails"
      },
      {
        "id": "{nodeId}-input-sendUpdates-options",
        "name": "sendUpdates",
        "label": "sendUpdates",
        "type": "options",
        "optional": true,
        "description": "Send Updates to attendees"
      },
      {
        "id": "{nodeId}-input-recurrence-string",
        "name": "recurrence",
        "label": "recurrence",
        "type": "string",
        "optional": true,
        "description": "Recurrence rules (RRULE format)"
      },
      {
        "id": "{nodeId}-input-reminderMinutes-number",
        "name": "reminderMinutes",
        "label": "reminderMinutes",
        "type": "number",
        "optional": true,
        "description": "Minutes before event to send reminder"
      },
      {
        "id": "{nodeId}-input-visibility-options",
        "name": "visibility",
        "label": "visibility",
        "type": "options",
        "optional": true,
        "description": "Event visibility"
      },
      {
        "id": "{nodeId}-input-quickAddText-string",
        "name": "quickAddText",
        "label": "quickAddText",
        "type": "string",
        "optional": true,
        "description": "Natural language text for quick event creation (e.g., \"Lunch with John tomorrow at 12pm\")"
      },
      {
        "id": "{nodeId}-input-timeMin-string",
        "name": "timeMin",
        "label": "timeMin",
        "type": "string",
        "optional": true,
        "description": "Lower bound for event search (ISO 8601 format)"
      },
      {
        "id": "{nodeId}-input-timeMax-string",
        "name": "timeMax",
        "label": "timeMax",
        "type": "string",
        "optional": true,
        "description": "Upper bound for event search (ISO 8601 format)"
      },
      {
        "id": "{nodeId}-input-maxResults-number",
        "name": "maxResults",
        "label": "maxResults",
        "type": "number",
        "optional": true,
        "default": "250",
        "description": "Maximum number of events to return"
      },
      {
        "id": "{nodeId}-input-singleEvents-boolean",
        "name": "singleEvents",
        "label": "singleEvents",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "Whether to expand recurring events into instances"
      },
      {
        "id": "{nodeId}-input-orderBy-options",
        "name": "orderBy",
        "label": "orderBy",
        "type": "options",
        "optional": true,
        "description": "Order of events returned"
      },
      {
        "id": "{nodeId}-input-query-string",
        "name": "query",
        "label": "query",
        "type": "string",
        "optional": true,
        "description": "Free text search terms"
      },
      {
        "id": "{nodeId}-input-calendarIdForCalendar-string",
        "name": "calendarIdForCalendar",
        "label": "calendarIdForCalendar",
        "type": "string",
        "optional": true,
        "description": "Calendar ID for operations on specific calendars"
      },
      {
        "id": "{nodeId}-input-calendarSummary-string",
        "name": "calendarSummary",
        "label": "calendarSummary",
        "type": "string",
        "optional": true,
        "description": "Calendar title/name"
      },
      {
        "id": "{nodeId}-input-calendarDescription-string",
        "name": "calendarDescription",
        "label": "calendarDescription",
        "type": "string",
        "optional": true,
        "description": "Calendar description"
      },
      {
        "id": "{nodeId}-input-calendarLocation-string",
        "name": "calendarLocation",
        "label": "calendarLocation",
        "type": "string",
        "optional": true,
        "description": "Calendar location"
      },
      {
        "id": "{nodeId}-input-calendarTimeZone-string",
        "name": "calendarTimeZone",
        "label": "calendarTimeZone",
        "type": "string",
        "optional": true,
        "description": "Calendar time zone (e.g., America/New_York)"
      },
      {
        "id": "{nodeId}-input-showHidden-boolean",
        "name": "showHidden",
        "label": "showHidden",
        "type": "boolean",
        "optional": true,
        "description": "Whether to show hidden calendars"
      },
      {
        "id": "{nodeId}-input-minAccessRole-options",
        "name": "minAccessRole",
        "label": "minAccessRole",
        "type": "options",
        "optional": true,
        "description": "Minimum access role for calendar list"
      },
      {
        "id": "{nodeId}-input-freebusyTimeMin-string",
        "name": "freebusyTimeMin",
        "label": "freebusyTimeMin",
        "type": "string",
        "optional": true,
        "description": "Lower bound for freebusy query (ISO 8601 format)"
      },
      {
        "id": "{nodeId}-input-freebusyTimeMax-string",
        "name": "freebusyTimeMax",
        "label": "freebusyTimeMax",
        "type": "string",
        "optional": true,
        "description": "Upper bound for freebusy query (ISO 8601 format)"
      },
      {
        "id": "{nodeId}-input-calendarIds-string",
        "name": "calendarIds",
        "label": "calendarIds",
        "type": "string",
        "optional": true,
        "description": "Comma-separated list of calendar IDs to check for free/busy info"
      },
      {
        "id": "{nodeId}-input-groupExpansionMax-number",
        "name": "groupExpansionMax",
        "label": "groupExpansionMax",
        "type": "number",
        "optional": true,
        "description": "Maximum number of calendars for which FreeBusy information is to be provided"
      },
      {
        "id": "{nodeId}-input-calendarExpansionMax-number",
        "name": "calendarExpansionMax",
        "label": "calendarExpansionMax",
        "type": "number",
        "optional": true,
        "description": "Maximum number of events that can be expanded for each calendar"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-googleCalendarTool-Tool",
        "name": "googleCalendarTool",
        "label": "Google Calendar",
        "type": "Tool"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Perform Google Calendar operations such as managing events, calendars, and checking availability",
    "baseClasses": [
      "Tool"
    ],
    "credential_required": [
      "googleCalendarOAuth2"
    ]
  },
  {
    "node_type": "googleCustomSearch",
    "name": "googleCustomSearch",
    "label": "Google Custom Search",
    "category": "Tools",
    "inputAnchors": [],
    "inputParams": [],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-googleCustomSearch-GoogleCustomSearchAPI|Tool|StructuredTool|Runnable",
        "name": "googleCustomSearch",
        "label": "Google Custom Search",
        "type": "GoogleCustomSearchAPI | Tool | StructuredTool | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Wrapper around Google Custom Search API - a real-time API to access Google search results",
    "baseClasses": [
      "GoogleCustomSearchAPI",
      "Tool",
      "StructuredTool",
      "Runnable"
    ],
    "credential_required": [
      "googleCustomSearchApi"
    ]
  },
  {
    "node_type": "googleDocsTool",
    "name": "googleDocsTool",
    "label": "Google Docs",
    "category": "Tools",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-actions-multiOptions",
        "name": "actions",
        "label": "actions",
        "type": "multiOptions",
        "optional": true,
        "description": "Actions to perform"
      },
      {
        "id": "{nodeId}-input-documentId-string",
        "name": "documentId",
        "label": "documentId",
        "type": "string",
        "optional": true,
        "description": "Document ID for operations on specific documents"
      },
      {
        "id": "{nodeId}-input-title-string",
        "name": "title",
        "label": "title",
        "type": "string",
        "optional": true,
        "description": "Document title"
      },
      {
        "id": "{nodeId}-input-text-string",
        "name": "text",
        "label": "text",
        "type": "string",
        "optional": true,
        "description": "Text content to insert or append"
      },
      {
        "id": "{nodeId}-input-index-number",
        "name": "index",
        "label": "index",
        "type": "number",
        "optional": true,
        "default": "1",
        "description": "Index where to insert text or media (1-based, default: 1 for beginning)"
      },
      {
        "id": "{nodeId}-input-replaceText-string",
        "name": "replaceText",
        "label": "replaceText",
        "type": "string",
        "optional": true,
        "description": "Text to replace"
      },
      {
        "id": "{nodeId}-input-newText-string",
        "name": "newText",
        "label": "newText",
        "type": "string",
        "optional": true,
        "description": "New text to replace with"
      },
      {
        "id": "{nodeId}-input-matchCase-boolean",
        "name": "matchCase",
        "label": "matchCase",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Whether the search should be case-sensitive"
      },
      {
        "id": "{nodeId}-input-imageUrl-string",
        "name": "imageUrl",
        "label": "imageUrl",
        "type": "string",
        "optional": true,
        "description": "URL of the image to insert"
      },
      {
        "id": "{nodeId}-input-rows-number",
        "name": "rows",
        "label": "rows",
        "type": "number",
        "optional": true,
        "description": "Number of rows in the table"
      },
      {
        "id": "{nodeId}-input-columns-number",
        "name": "columns",
        "label": "columns",
        "type": "number",
        "optional": true,
        "description": "Number of columns in the table"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-googleDocsTool-Tool",
        "name": "googleDocsTool",
        "label": "Google Docs",
        "type": "Tool"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Perform Google Docs operations such as creating, reading, updating, and deleting documents, as well as text manipulation",
    "baseClasses": [
      "Tool"
    ],
    "credential_required": [
      "googleDocsOAuth2"
    ]
  },
  {
    "node_type": "googleDriveTool",
    "name": "googleDriveTool",
    "label": "Google Drive",
    "category": "Tools",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-driveType-options",
        "name": "driveType",
        "label": "driveType",
        "type": "options",
        "optional": true,
        "description": "Type of Google Drive operation"
      },
      {
        "id": "{nodeId}-input-fileActions-multiOptions",
        "name": "fileActions",
        "label": "fileActions",
        "type": "multiOptions",
        "optional": true,
        "description": "Actions to perform on files"
      },
      {
        "id": "{nodeId}-input-folderActions-multiOptions",
        "name": "folderActions",
        "label": "folderActions",
        "type": "multiOptions",
        "optional": true,
        "description": "Actions to perform on folders"
      },
      {
        "id": "{nodeId}-input-searchActions-multiOptions",
        "name": "searchActions",
        "label": "searchActions",
        "type": "multiOptions",
        "optional": true,
        "description": "Search operations"
      },
      {
        "id": "{nodeId}-input-shareActions-multiOptions",
        "name": "shareActions",
        "label": "shareActions",
        "type": "multiOptions",
        "optional": true,
        "description": "Sharing operations"
      },
      {
        "id": "{nodeId}-input-fileId-string",
        "name": "fileId",
        "label": "fileId",
        "type": "string",
        "optional": true,
        "description": "File ID for file operations"
      },
      {
        "id": "{nodeId}-input-fileId-string",
        "name": "fileId",
        "label": "fileId",
        "type": "string",
        "optional": true,
        "description": "File ID for sharing operations"
      },
      {
        "id": "{nodeId}-input-folderId-string",
        "name": "folderId",
        "label": "folderId",
        "type": "string",
        "optional": true,
        "description": "Folder ID for folder operations"
      },
      {
        "id": "{nodeId}-input-permissionId-string",
        "name": "permissionId",
        "label": "permissionId",
        "type": "string",
        "optional": true,
        "description": "Permission ID to remove"
      },
      {
        "id": "{nodeId}-input-fileName-string",
        "name": "fileName",
        "label": "fileName",
        "type": "string",
        "optional": true,
        "description": "Name of the file"
      },
      {
        "id": "{nodeId}-input-fileName-string",
        "name": "fileName",
        "label": "fileName",
        "type": "string",
        "optional": true,
        "description": "Name of the folder"
      },
      {
        "id": "{nodeId}-input-fileContent-string",
        "name": "fileContent",
        "label": "fileContent",
        "type": "string",
        "optional": true,
        "description": "Content of the file (for text files)"
      },
      {
        "id": "{nodeId}-input-mimeType-string",
        "name": "mimeType",
        "label": "mimeType",
        "type": "string",
        "optional": true,
        "description": "MIME type of the file (e.g., text/plain, application/pdf)"
      },
      {
        "id": "{nodeId}-input-parentFolderId-string",
        "name": "parentFolderId",
        "label": "parentFolderId",
        "type": "string",
        "optional": true,
        "description": "ID of the parent folder (comma-separated for multiple parents)"
      },
      {
        "id": "{nodeId}-input-parentFolderId-string",
        "name": "parentFolderId",
        "label": "parentFolderId",
        "type": "string",
        "optional": true,
        "description": "ID of the parent folder for the new folder"
      },
      {
        "id": "{nodeId}-input-description-string",
        "name": "description",
        "label": "description",
        "type": "string",
        "optional": true,
        "description": "File description"
      },
      {
        "id": "{nodeId}-input-description-string",
        "name": "description",
        "label": "description",
        "type": "string",
        "optional": true,
        "description": "Folder description"
      },
      {
        "id": "{nodeId}-input-searchQuery-string",
        "name": "searchQuery",
        "label": "searchQuery",
        "type": "string",
        "optional": true,
        "description": "Search query using Google Drive search syntax"
      },
      {
        "id": "{nodeId}-input-maxResults-number",
        "name": "maxResults",
        "label": "maxResults",
        "type": "number",
        "optional": true,
        "default": "10",
        "description": "Maximum number of results to return (1-1000)"
      },
      {
        "id": "{nodeId}-input-maxResults-number",
        "name": "maxResults",
        "label": "maxResults",
        "type": "number",
        "optional": true,
        "default": "10",
        "description": "Maximum number of results to return (1-1000)"
      },
      {
        "id": "{nodeId}-input-orderBy-options",
        "name": "orderBy",
        "label": "orderBy",
        "type": "options",
        "optional": true,
        "description": "Sort order for file results"
      },
      {
        "id": "{nodeId}-input-orderBy-options",
        "name": "orderBy",
        "label": "orderBy",
        "type": "options",
        "optional": true,
        "description": "Sort order for search results"
      },
      {
        "id": "{nodeId}-input-shareRole-options",
        "name": "shareRole",
        "label": "shareRole",
        "type": "options",
        "optional": true,
        "description": "Permission role for sharing"
      },
      {
        "id": "{nodeId}-input-shareType-options",
        "name": "shareType",
        "label": "shareType",
        "type": "options",
        "optional": true,
        "description": "Type of permission"
      },
      {
        "id": "{nodeId}-input-emailAddress-string",
        "name": "emailAddress",
        "label": "emailAddress",
        "type": "string",
        "optional": true,
        "description": "Email address for user/group sharing"
      },
      {
        "id": "{nodeId}-input-domainName-string",
        "name": "domainName",
        "label": "domainName",
        "type": "string",
        "optional": true,
        "description": "Domain name for domain sharing"
      },
      {
        "id": "{nodeId}-input-sendNotificationEmail-boolean",
        "name": "sendNotificationEmail",
        "label": "sendNotificationEmail",
        "type": "boolean",
        "optional": true,
        "default": "True",
        "description": "Whether to send notification emails when sharing"
      },
      {
        "id": "{nodeId}-input-emailMessage-string",
        "name": "emailMessage",
        "label": "emailMessage",
        "type": "string",
        "optional": true,
        "description": "Custom message to include in notification email"
      },
      {
        "id": "{nodeId}-input-includeItemsFromAllDrives-boolean",
        "name": "includeItemsFromAllDrives",
        "label": "includeItemsFromAllDrives",
        "type": "boolean",
        "optional": true,
        "description": "Include items from all drives (shared drives)"
      },
      {
        "id": "{nodeId}-input-includeItemsFromAllDrives-boolean",
        "name": "includeItemsFromAllDrives",
        "label": "includeItemsFromAllDrives",
        "type": "boolean",
        "optional": true,
        "description": "Include items from all drives (shared drives)"
      },
      {
        "id": "{nodeId}-input-supportsAllDrives-boolean",
        "name": "supportsAllDrives",
        "label": "supportsAllDrives",
        "type": "boolean",
        "optional": true,
        "description": "Whether the application supports both My Drives and shared drives"
      },
      {
        "id": "{nodeId}-input-supportsAllDrives-boolean",
        "name": "supportsAllDrives",
        "label": "supportsAllDrives",
        "type": "boolean",
        "optional": true,
        "description": "Whether the application supports both My Drives and shared drives"
      },
      {
        "id": "{nodeId}-input-supportsAllDrives-boolean",
        "name": "supportsAllDrives",
        "label": "supportsAllDrives",
        "type": "boolean",
        "optional": true,
        "description": "Whether the application supports both My Drives and shared drives"
      },
      {
        "id": "{nodeId}-input-supportsAllDrives-boolean",
        "name": "supportsAllDrives",
        "label": "supportsAllDrives",
        "type": "boolean",
        "optional": true,
        "description": "Whether the application supports both My Drives and shared drives"
      },
      {
        "id": "{nodeId}-input-fields-string",
        "name": "fields",
        "label": "fields",
        "type": "string",
        "optional": true,
        "description": "Specific fields to include in response (e.g., \"files(id,name,mimeType)\")"
      },
      {
        "id": "{nodeId}-input-acknowledgeAbuse-boolean",
        "name": "acknowledgeAbuse",
        "label": "acknowledgeAbuse",
        "type": "boolean",
        "optional": true,
        "description": "Acknowledge the risk of downloading known malware or abusive files"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-googleDriveTool-Tool",
        "name": "googleDriveTool",
        "label": "Google Drive",
        "type": "Tool"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Perform Google Drive operations such as managing files, folders, sharing, and searching",
    "baseClasses": [
      "Tool"
    ],
    "credential_required": [
      "googleDriveOAuth2"
    ]
  },
  {
    "node_type": "googleSheetsTool",
    "name": "googleSheetsTool",
    "label": "Google Sheets",
    "category": "Tools",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-sheetsType-options",
        "name": "sheetsType",
        "label": "sheetsType",
        "type": "options",
        "optional": true,
        "description": "Type of Google Sheets operation"
      },
      {
        "id": "{nodeId}-input-spreadsheetActions-multiOptions",
        "name": "spreadsheetActions",
        "label": "spreadsheetActions",
        "type": "multiOptions",
        "optional": true,
        "description": "Actions to perform on spreadsheets"
      },
      {
        "id": "{nodeId}-input-valuesActions-multiOptions",
        "name": "valuesActions",
        "label": "valuesActions",
        "type": "multiOptions",
        "optional": true,
        "description": "Actions to perform on sheet values"
      },
      {
        "id": "{nodeId}-input-spreadsheetId-string",
        "name": "spreadsheetId",
        "label": "spreadsheetId",
        "type": "string",
        "optional": true,
        "description": "The ID of the spreadsheet"
      },
      {
        "id": "{nodeId}-input-title-string",
        "name": "title",
        "label": "title",
        "type": "string",
        "optional": true,
        "description": "The title of the spreadsheet"
      },
      {
        "id": "{nodeId}-input-sheetCount-number",
        "name": "sheetCount",
        "label": "sheetCount",
        "type": "number",
        "optional": true,
        "default": "1",
        "description": "Number of sheets to create"
      },
      {
        "id": "{nodeId}-input-range-string",
        "name": "range",
        "label": "range",
        "type": "string",
        "optional": true,
        "description": "The range to read/write (e.g., A1:B2, Sheet1!A1:C10)"
      },
      {
        "id": "{nodeId}-input-ranges-string",
        "name": "ranges",
        "label": "ranges",
        "type": "string",
        "optional": true,
        "description": "Comma-separated list of ranges for batch operations"
      },
      {
        "id": "{nodeId}-input-values-string",
        "name": "values",
        "label": "values",
        "type": "string",
        "optional": true,
        "description": "JSON array of values to write (e.g., [[\"A1\", \"B1\"], [\"A2\", \"B2\"]])"
      },
      {
        "id": "{nodeId}-input-valueInputOption-options",
        "name": "valueInputOption",
        "label": "valueInputOption",
        "type": "options",
        "optional": true,
        "default": "USER_ENTERED",
        "description": "How input data should be interpreted"
      },
      {
        "id": "{nodeId}-input-valueRenderOption-options",
        "name": "valueRenderOption",
        "label": "valueRenderOption",
        "type": "options",
        "optional": true,
        "default": "FORMATTED_VALUE",
        "description": "How values should be represented in the output"
      },
      {
        "id": "{nodeId}-input-dateTimeRenderOption-options",
        "name": "dateTimeRenderOption",
        "label": "dateTimeRenderOption",
        "type": "options",
        "optional": true,
        "default": "FORMATTED_STRING",
        "description": "How dates, times, and durations should be represented"
      },
      {
        "id": "{nodeId}-input-insertDataOption-options",
        "name": "insertDataOption",
        "label": "insertDataOption",
        "type": "options",
        "optional": true,
        "default": "OVERWRITE",
        "description": "How data should be inserted"
      },
      {
        "id": "{nodeId}-input-includeGridData-boolean",
        "name": "includeGridData",
        "label": "includeGridData",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "True if grid data should be returned"
      },
      {
        "id": "{nodeId}-input-majorDimension-options",
        "name": "majorDimension",
        "label": "majorDimension",
        "type": "options",
        "optional": true,
        "default": "ROWS",
        "description": "The major dimension that results should use"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-googleSheetsTool-Tool",
        "name": "googleSheetsTool",
        "label": "Google Sheets",
        "type": "Tool"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Perform Google Sheets operations such as managing spreadsheets, reading and writing values",
    "baseClasses": [
      "Tool"
    ],
    "credential_required": [
      "googleSheetsOAuth2"
    ]
  },
  {
    "node_type": "jiraTool",
    "name": "jiraTool",
    "label": "Jira",
    "category": "Tools",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-jiraHost-string",
        "name": "jiraHost",
        "label": "jiraHost",
        "type": "string",
        "optional": true,
        "description": "Host"
      },
      {
        "id": "{nodeId}-input-jiraType-options",
        "name": "jiraType",
        "label": "jiraType",
        "type": "options",
        "optional": true,
        "description": "Type"
      },
      {
        "id": "{nodeId}-input-issueActions-multiOptions",
        "name": "issueActions",
        "label": "issueActions",
        "type": "multiOptions",
        "optional": true,
        "description": "Issue Actions"
      },
      {
        "id": "{nodeId}-input-commentActions-multiOptions",
        "name": "commentActions",
        "label": "commentActions",
        "type": "multiOptions",
        "optional": true,
        "description": "Comment Actions"
      },
      {
        "id": "{nodeId}-input-userActions-multiOptions",
        "name": "userActions",
        "label": "userActions",
        "type": "multiOptions",
        "optional": true,
        "description": "User Actions"
      },
      {
        "id": "{nodeId}-input-projectKey-string",
        "name": "projectKey",
        "label": "projectKey",
        "type": "string",
        "optional": true,
        "description": "Project key for the issue"
      },
      {
        "id": "{nodeId}-input-issueType-string",
        "name": "issueType",
        "label": "issueType",
        "type": "string",
        "optional": true,
        "description": "Type of issue to create"
      },
      {
        "id": "{nodeId}-input-issueSummary-string",
        "name": "issueSummary",
        "label": "issueSummary",
        "type": "string",
        "optional": true,
        "description": "Issue summary/title"
      },
      {
        "id": "{nodeId}-input-issueDescription-string",
        "name": "issueDescription",
        "label": "issueDescription",
        "type": "string",
        "optional": true,
        "description": "Issue description"
      },
      {
        "id": "{nodeId}-input-issuePriority-string",
        "name": "issuePriority",
        "label": "issuePriority",
        "type": "string",
        "optional": true,
        "description": "Issue priority"
      },
      {
        "id": "{nodeId}-input-issueKey-string",
        "name": "issueKey",
        "label": "issueKey",
        "type": "string",
        "optional": true,
        "description": "Issue key (e.g., PROJ-123)"
      },
      {
        "id": "{nodeId}-input-assigneeAccountId-string",
        "name": "assigneeAccountId",
        "label": "assigneeAccountId",
        "type": "string",
        "optional": true,
        "description": "Account ID of the user to assign"
      },
      {
        "id": "{nodeId}-input-transitionId-string",
        "name": "transitionId",
        "label": "transitionId",
        "type": "string",
        "optional": true,
        "description": "ID of the transition to execute"
      },
      {
        "id": "{nodeId}-input-jqlQuery-string",
        "name": "jqlQuery",
        "label": "jqlQuery",
        "type": "string",
        "optional": true,
        "description": "JQL query for filtering issues"
      },
      {
        "id": "{nodeId}-input-issueMaxResults-number",
        "name": "issueMaxResults",
        "label": "issueMaxResults",
        "type": "number",
        "optional": true,
        "default": "50",
        "description": "Maximum number of issues to return"
      },
      {
        "id": "{nodeId}-input-commentIssueKey-string",
        "name": "commentIssueKey",
        "label": "commentIssueKey",
        "type": "string",
        "optional": true,
        "description": "Issue key for comment operations"
      },
      {
        "id": "{nodeId}-input-commentText-string",
        "name": "commentText",
        "label": "commentText",
        "type": "string",
        "optional": true,
        "description": "Comment content"
      },
      {
        "id": "{nodeId}-input-commentId-string",
        "name": "commentId",
        "label": "commentId",
        "type": "string",
        "optional": true,
        "description": "ID of the comment"
      },
      {
        "id": "{nodeId}-input-userQuery-string",
        "name": "userQuery",
        "label": "userQuery",
        "type": "string",
        "optional": true,
        "description": "Query string for user search"
      },
      {
        "id": "{nodeId}-input-userAccountId-string",
        "name": "userAccountId",
        "label": "userAccountId",
        "type": "string",
        "optional": true,
        "description": "User account ID"
      },
      {
        "id": "{nodeId}-input-userEmail-string",
        "name": "userEmail",
        "label": "userEmail",
        "type": "string",
        "optional": true,
        "description": "User email address"
      },
      {
        "id": "{nodeId}-input-userDisplayName-string",
        "name": "userDisplayName",
        "label": "userDisplayName",
        "type": "string",
        "optional": true,
        "description": "User display name"
      },
      {
        "id": "{nodeId}-input-userMaxResults-number",
        "name": "userMaxResults",
        "label": "userMaxResults",
        "type": "number",
        "optional": true,
        "default": "50",
        "description": "Maximum number of users to return"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-jiraTool-Jira|Tool",
        "name": "jiraTool",
        "label": "Jira",
        "type": "Jira | Tool"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Perform Jira operations for issues, comments, and users",
    "baseClasses": [
      "Jira",
      "Tool"
    ],
    "credential_required": [
      "jiraApi"
    ]
  },
  {
    "node_type": "jsonPathExtractor",
    "name": "jsonPathExtractor",
    "label": "JSON Path Extractor",
    "category": "Tools",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-path-string",
        "name": "path",
        "label": "path",
        "type": "string",
        "optional": true,
        "description": "Path to extract. Examples: data, user.name, items[0].id"
      },
      {
        "id": "{nodeId}-input-returnNullOnError-boolean",
        "name": "returnNullOnError",
        "label": "returnNullOnError",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Return null instead of throwing error when extraction fails"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-jsonPathExtractor-JSONPathExtractor|StructuredTool|Runnable",
        "name": "jsonPathExtractor",
        "label": "JSON Path Extractor",
        "type": "JSONPathExtractor | StructuredTool | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Extract values from JSON using path expressions",
    "baseClasses": [
      "JSONPathExtractor",
      "StructuredTool",
      "Runnable"
    ]
  },
  {
    "node_type": "microsoftOutlook",
    "name": "microsoftOutlook",
    "label": "Microsoft Outlook",
    "category": "Tools",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-outlookType-options",
        "name": "outlookType",
        "label": "outlookType",
        "type": "options",
        "optional": true,
        "description": "Type"
      },
      {
        "id": "{nodeId}-input-calendarActions-multiOptions",
        "name": "calendarActions",
        "label": "calendarActions",
        "type": "multiOptions",
        "optional": true,
        "description": "Calendar Actions"
      },
      {
        "id": "{nodeId}-input-messageActions-multiOptions",
        "name": "messageActions",
        "label": "messageActions",
        "type": "multiOptions",
        "optional": true,
        "description": "Message Actions"
      },
      {
        "id": "{nodeId}-input-maxResultsListCalendars-number",
        "name": "maxResultsListCalendars",
        "label": "maxResultsListCalendars",
        "type": "number",
        "optional": true,
        "default": "50",
        "description": "Maximum number of calendars to return"
      },
      {
        "id": "{nodeId}-input-calendarIdGetCalendar-string",
        "name": "calendarIdGetCalendar",
        "label": "calendarIdGetCalendar",
        "type": "string",
        "optional": true,
        "description": "ID of the calendar to retrieve"
      },
      {
        "id": "{nodeId}-input-calendarNameCreateCalendar-string",
        "name": "calendarNameCreateCalendar",
        "label": "calendarNameCreateCalendar",
        "type": "string",
        "optional": true,
        "description": "Name of the calendar"
      },
      {
        "id": "{nodeId}-input-calendarIdUpdateCalendar-string",
        "name": "calendarIdUpdateCalendar",
        "label": "calendarIdUpdateCalendar",
        "type": "string",
        "optional": true,
        "description": "ID of the calendar to update"
      },
      {
        "id": "{nodeId}-input-calendarNameUpdateCalendar-string",
        "name": "calendarNameUpdateCalendar",
        "label": "calendarNameUpdateCalendar",
        "type": "string",
        "optional": true,
        "description": "New name of the calendar"
      },
      {
        "id": "{nodeId}-input-calendarIdDeleteCalendar-string",
        "name": "calendarIdDeleteCalendar",
        "label": "calendarIdDeleteCalendar",
        "type": "string",
        "optional": true,
        "description": "ID of the calendar to delete"
      },
      {
        "id": "{nodeId}-input-calendarIdListEvents-string",
        "name": "calendarIdListEvents",
        "label": "calendarIdListEvents",
        "type": "string",
        "optional": true,
        "description": "ID of the calendar (leave empty for primary calendar)"
      },
      {
        "id": "{nodeId}-input-maxResultsListEvents-number",
        "name": "maxResultsListEvents",
        "label": "maxResultsListEvents",
        "type": "number",
        "optional": true,
        "default": "50",
        "description": "Maximum number of events to return"
      },
      {
        "id": "{nodeId}-input-startDateTimeListEvents-string",
        "name": "startDateTimeListEvents",
        "label": "startDateTimeListEvents",
        "type": "string",
        "optional": true,
        "description": "Start date time filter in ISO format"
      },
      {
        "id": "{nodeId}-input-endDateTimeListEvents-string",
        "name": "endDateTimeListEvents",
        "label": "endDateTimeListEvents",
        "type": "string",
        "optional": true,
        "description": "End date time filter in ISO format"
      },
      {
        "id": "{nodeId}-input-eventIdGetEvent-string",
        "name": "eventIdGetEvent",
        "label": "eventIdGetEvent",
        "type": "string",
        "optional": true,
        "description": "ID of the event to retrieve"
      },
      {
        "id": "{nodeId}-input-subjectCreateEvent-string",
        "name": "subjectCreateEvent",
        "label": "subjectCreateEvent",
        "type": "string",
        "optional": true,
        "description": "Subject/title of the event"
      },
      {
        "id": "{nodeId}-input-bodyCreateEvent-string",
        "name": "bodyCreateEvent",
        "label": "bodyCreateEvent",
        "type": "string",
        "optional": true,
        "description": "Body/description of the event"
      },
      {
        "id": "{nodeId}-input-startDateTimeCreateEvent-string",
        "name": "startDateTimeCreateEvent",
        "label": "startDateTimeCreateEvent",
        "type": "string",
        "optional": true,
        "description": "Start date and time in ISO format"
      },
      {
        "id": "{nodeId}-input-endDateTimeCreateEvent-string",
        "name": "endDateTimeCreateEvent",
        "label": "endDateTimeCreateEvent",
        "type": "string",
        "optional": true,
        "description": "End date and time in ISO format"
      },
      {
        "id": "{nodeId}-input-timeZoneCreateEvent-string",
        "name": "timeZoneCreateEvent",
        "label": "timeZoneCreateEvent",
        "type": "string",
        "optional": true,
        "default": "UTC",
        "description": "Time zone for the event"
      },
      {
        "id": "{nodeId}-input-locationCreateEvent-string",
        "name": "locationCreateEvent",
        "label": "locationCreateEvent",
        "type": "string",
        "optional": true,
        "description": "Location of the event"
      },
      {
        "id": "{nodeId}-input-attendeesCreateEvent-string",
        "name": "attendeesCreateEvent",
        "label": "attendeesCreateEvent",
        "type": "string",
        "optional": true,
        "description": "Comma-separated list of attendee email addresses"
      },
      {
        "id": "{nodeId}-input-eventIdUpdateEvent-string",
        "name": "eventIdUpdateEvent",
        "label": "eventIdUpdateEvent",
        "type": "string",
        "optional": true,
        "description": "ID of the event to update"
      },
      {
        "id": "{nodeId}-input-subjectUpdateEvent-string",
        "name": "subjectUpdateEvent",
        "label": "subjectUpdateEvent",
        "type": "string",
        "optional": true,
        "description": "New subject/title of the event"
      },
      {
        "id": "{nodeId}-input-eventIdDeleteEvent-string",
        "name": "eventIdDeleteEvent",
        "label": "eventIdDeleteEvent",
        "type": "string",
        "optional": true,
        "description": "ID of the event to delete"
      },
      {
        "id": "{nodeId}-input-maxResultsListMessages-number",
        "name": "maxResultsListMessages",
        "label": "maxResultsListMessages",
        "type": "number",
        "optional": true,
        "default": "50",
        "description": "Maximum number of messages to return"
      },
      {
        "id": "{nodeId}-input-filterListMessages-string",
        "name": "filterListMessages",
        "label": "filterListMessages",
        "type": "string",
        "optional": true,
        "description": "Filter query (e.g., \"isRead eq false\")"
      },
      {
        "id": "{nodeId}-input-messageIdGetMessage-string",
        "name": "messageIdGetMessage",
        "label": "messageIdGetMessage",
        "type": "string",
        "optional": true,
        "description": "ID of the message to retrieve"
      },
      {
        "id": "{nodeId}-input-toCreateDraftMessage-string",
        "name": "toCreateDraftMessage",
        "label": "toCreateDraftMessage",
        "type": "string",
        "optional": true,
        "description": "Recipient email address(es), comma-separated"
      },
      {
        "id": "{nodeId}-input-subjectCreateDraftMessage-string",
        "name": "subjectCreateDraftMessage",
        "label": "subjectCreateDraftMessage",
        "type": "string",
        "optional": true,
        "description": "Subject of the message"
      },
      {
        "id": "{nodeId}-input-bodyCreateDraftMessage-string",
        "name": "bodyCreateDraftMessage",
        "label": "bodyCreateDraftMessage",
        "type": "string",
        "optional": true,
        "description": "Body content of the message"
      },
      {
        "id": "{nodeId}-input-ccCreateDraftMessage-string",
        "name": "ccCreateDraftMessage",
        "label": "ccCreateDraftMessage",
        "type": "string",
        "optional": true,
        "description": "CC email address(es), comma-separated"
      },
      {
        "id": "{nodeId}-input-bccCreateDraftMessage-string",
        "name": "bccCreateDraftMessage",
        "label": "bccCreateDraftMessage",
        "type": "string",
        "optional": true,
        "description": "BCC email address(es), comma-separated"
      },
      {
        "id": "{nodeId}-input-toSendMessage-string",
        "name": "toSendMessage",
        "label": "toSendMessage",
        "type": "string",
        "optional": true,
        "description": "Recipient email address(es), comma-separated"
      },
      {
        "id": "{nodeId}-input-subjectSendMessage-string",
        "name": "subjectSendMessage",
        "label": "subjectSendMessage",
        "type": "string",
        "optional": true,
        "description": "Subject of the message"
      },
      {
        "id": "{nodeId}-input-bodySendMessage-string",
        "name": "bodySendMessage",
        "label": "bodySendMessage",
        "type": "string",
        "optional": true,
        "description": "Body content of the message"
      },
      {
        "id": "{nodeId}-input-messageIdUpdateMessage-string",
        "name": "messageIdUpdateMessage",
        "label": "messageIdUpdateMessage",
        "type": "string",
        "optional": true,
        "description": "ID of the message to update"
      },
      {
        "id": "{nodeId}-input-isReadUpdateMessage-boolean",
        "name": "isReadUpdateMessage",
        "label": "isReadUpdateMessage",
        "type": "boolean",
        "optional": true,
        "description": "Mark message as read/unread"
      },
      {
        "id": "{nodeId}-input-messageIdDeleteMessage-string",
        "name": "messageIdDeleteMessage",
        "label": "messageIdDeleteMessage",
        "type": "string",
        "optional": true,
        "description": "ID of the message to delete"
      },
      {
        "id": "{nodeId}-input-messageIdCopyMessage-string",
        "name": "messageIdCopyMessage",
        "label": "messageIdCopyMessage",
        "type": "string",
        "optional": true,
        "description": "ID of the message to copy"
      },
      {
        "id": "{nodeId}-input-destinationFolderIdCopyMessage-string",
        "name": "destinationFolderIdCopyMessage",
        "label": "destinationFolderIdCopyMessage",
        "type": "string",
        "optional": true,
        "description": "ID of the destination folder"
      },
      {
        "id": "{nodeId}-input-messageIdMoveMessage-string",
        "name": "messageIdMoveMessage",
        "label": "messageIdMoveMessage",
        "type": "string",
        "optional": true,
        "description": "ID of the message to move"
      },
      {
        "id": "{nodeId}-input-destinationFolderIdMoveMessage-string",
        "name": "destinationFolderIdMoveMessage",
        "label": "destinationFolderIdMoveMessage",
        "type": "string",
        "optional": true,
        "description": "ID of the destination folder"
      },
      {
        "id": "{nodeId}-input-messageIdReplyMessage-string",
        "name": "messageIdReplyMessage",
        "label": "messageIdReplyMessage",
        "type": "string",
        "optional": true,
        "description": "ID of the message to reply to"
      },
      {
        "id": "{nodeId}-input-replyBodyReplyMessage-string",
        "name": "replyBodyReplyMessage",
        "label": "replyBodyReplyMessage",
        "type": "string",
        "optional": true,
        "description": "Reply message body"
      },
      {
        "id": "{nodeId}-input-messageIdForwardMessage-string",
        "name": "messageIdForwardMessage",
        "label": "messageIdForwardMessage",
        "type": "string",
        "optional": true,
        "description": "ID of the message to forward"
      },
      {
        "id": "{nodeId}-input-forwardToForwardMessage-string",
        "name": "forwardToForwardMessage",
        "label": "forwardToForwardMessage",
        "type": "string",
        "optional": true,
        "description": "Email address(es) to forward to, comma-separated"
      },
      {
        "id": "{nodeId}-input-forwardCommentForwardMessage-string",
        "name": "forwardCommentForwardMessage",
        "label": "forwardCommentForwardMessage",
        "type": "string",
        "optional": true,
        "description": "Additional comment to include with forward"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-microsoftOutlook-MicrosoftOutlook|Tool",
        "name": "microsoftOutlook",
        "label": "Microsoft Outlook",
        "type": "MicrosoftOutlook | Tool"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Perform Microsoft Outlook operations for calendars, events, and messages",
    "baseClasses": [
      "MicrosoftOutlook",
      "Tool"
    ],
    "credential_required": [
      "microsoftOutlookOAuth2"
    ]
  },
  {
    "node_type": "microsoftTeams",
    "name": "microsoftTeams",
    "label": "Microsoft Teams",
    "category": "Tools",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-teamsType-options",
        "name": "teamsType",
        "label": "teamsType",
        "type": "options",
        "optional": true,
        "description": "Type"
      },
      {
        "id": "{nodeId}-input-channelActions-multiOptions",
        "name": "channelActions",
        "label": "channelActions",
        "type": "multiOptions",
        "optional": true,
        "description": "Channel Actions"
      },
      {
        "id": "{nodeId}-input-chatActions-multiOptions",
        "name": "chatActions",
        "label": "chatActions",
        "type": "multiOptions",
        "optional": true,
        "description": "Chat Actions"
      },
      {
        "id": "{nodeId}-input-chatMessageActions-multiOptions",
        "name": "chatMessageActions",
        "label": "chatMessageActions",
        "type": "multiOptions",
        "optional": true,
        "description": "Chat Message Actions"
      },
      {
        "id": "{nodeId}-input-teamIdListChannels-string",
        "name": "teamIdListChannels",
        "label": "teamIdListChannels",
        "type": "string",
        "optional": true,
        "description": "ID of the team to list channels from"
      },
      {
        "id": "{nodeId}-input-maxResultsListChannels-number",
        "name": "maxResultsListChannels",
        "label": "maxResultsListChannels",
        "type": "number",
        "optional": true,
        "default": "50",
        "description": "Maximum number of channels to return"
      },
      {
        "id": "{nodeId}-input-teamIdGetChannel-string",
        "name": "teamIdGetChannel",
        "label": "teamIdGetChannel",
        "type": "string",
        "optional": true,
        "description": "ID of the team that contains the channel"
      },
      {
        "id": "{nodeId}-input-channelIdGetChannel-string",
        "name": "channelIdGetChannel",
        "label": "channelIdGetChannel",
        "type": "string",
        "optional": true,
        "description": "ID of the channel to retrieve"
      },
      {
        "id": "{nodeId}-input-teamIdCreateChannel-string",
        "name": "teamIdCreateChannel",
        "label": "teamIdCreateChannel",
        "type": "string",
        "optional": true,
        "description": "ID of the team to create the channel in"
      },
      {
        "id": "{nodeId}-input-displayNameCreateChannel-string",
        "name": "displayNameCreateChannel",
        "label": "displayNameCreateChannel",
        "type": "string",
        "optional": true,
        "description": "Display name of the channel"
      },
      {
        "id": "{nodeId}-input-descriptionCreateChannel-string",
        "name": "descriptionCreateChannel",
        "label": "descriptionCreateChannel",
        "type": "string",
        "optional": true,
        "description": "Description of the channel"
      },
      {
        "id": "{nodeId}-input-membershipTypeCreateChannel-options",
        "name": "membershipTypeCreateChannel",
        "label": "membershipTypeCreateChannel",
        "type": "options",
        "optional": true,
        "default": "standard",
        "description": "Type of channel membership"
      },
      {
        "id": "{nodeId}-input-teamIdUpdateChannel-string",
        "name": "teamIdUpdateChannel",
        "label": "teamIdUpdateChannel",
        "type": "string",
        "optional": true,
        "description": "ID of the team that contains the channel"
      },
      {
        "id": "{nodeId}-input-channelIdUpdateChannel-string",
        "name": "channelIdUpdateChannel",
        "label": "channelIdUpdateChannel",
        "type": "string",
        "optional": true,
        "description": "ID of the channel to update"
      },
      {
        "id": "{nodeId}-input-displayNameUpdateChannel-string",
        "name": "displayNameUpdateChannel",
        "label": "displayNameUpdateChannel",
        "type": "string",
        "optional": true,
        "description": "New display name of the channel"
      },
      {
        "id": "{nodeId}-input-teamIdDeleteChannel-string",
        "name": "teamIdDeleteChannel",
        "label": "teamIdDeleteChannel",
        "type": "string",
        "optional": true,
        "description": "ID of the team that contains the channel"
      },
      {
        "id": "{nodeId}-input-channelIdDeleteChannel-string",
        "name": "channelIdDeleteChannel",
        "label": "channelIdDeleteChannel",
        "type": "string",
        "optional": true,
        "description": "ID of the channel to delete or archive"
      },
      {
        "id": "{nodeId}-input-teamIdChannelMembers-string",
        "name": "teamIdChannelMembers",
        "label": "teamIdChannelMembers",
        "type": "string",
        "optional": true,
        "description": "ID of the team that contains the channel"
      },
      {
        "id": "{nodeId}-input-channelIdChannelMembers-string",
        "name": "channelIdChannelMembers",
        "label": "channelIdChannelMembers",
        "type": "string",
        "optional": true,
        "description": "ID of the channel"
      },
      {
        "id": "{nodeId}-input-userIdChannelMember-string",
        "name": "userIdChannelMember",
        "label": "userIdChannelMember",
        "type": "string",
        "optional": true,
        "description": "ID of the user to add or remove"
      },
      {
        "id": "{nodeId}-input-maxResultsListChats-number",
        "name": "maxResultsListChats",
        "label": "maxResultsListChats",
        "type": "number",
        "optional": true,
        "default": "50",
        "description": "Maximum number of chats to return"
      },
      {
        "id": "{nodeId}-input-chatIdGetChat-string",
        "name": "chatIdGetChat",
        "label": "chatIdGetChat",
        "type": "string",
        "optional": true,
        "description": "ID of the chat to retrieve"
      },
      {
        "id": "{nodeId}-input-chatTypeCreateChat-options",
        "name": "chatTypeCreateChat",
        "label": "chatTypeCreateChat",
        "type": "options",
        "optional": true,
        "default": "group",
        "description": "Type of chat to create"
      },
      {
        "id": "{nodeId}-input-topicCreateChat-string",
        "name": "topicCreateChat",
        "label": "topicCreateChat",
        "type": "string",
        "optional": true,
        "description": "Topic/subject of the chat (for group chats)"
      },
      {
        "id": "{nodeId}-input-membersCreateChat-string",
        "name": "membersCreateChat",
        "label": "membersCreateChat",
        "type": "string",
        "optional": true,
        "description": "Comma-separated list of user IDs to add to the chat"
      },
      {
        "id": "{nodeId}-input-chatIdUpdateChat-string",
        "name": "chatIdUpdateChat",
        "label": "chatIdUpdateChat",
        "type": "string",
        "optional": true,
        "description": "ID of the chat to update"
      },
      {
        "id": "{nodeId}-input-topicUpdateChat-string",
        "name": "topicUpdateChat",
        "label": "topicUpdateChat",
        "type": "string",
        "optional": true,
        "description": "New topic/subject of the chat"
      },
      {
        "id": "{nodeId}-input-chatIdDeleteChat-string",
        "name": "chatIdDeleteChat",
        "label": "chatIdDeleteChat",
        "type": "string",
        "optional": true,
        "description": "ID of the chat to delete"
      },
      {
        "id": "{nodeId}-input-chatIdChatMembers-string",
        "name": "chatIdChatMembers",
        "label": "chatIdChatMembers",
        "type": "string",
        "optional": true,
        "description": "ID of the chat"
      },
      {
        "id": "{nodeId}-input-userIdChatMember-string",
        "name": "userIdChatMember",
        "label": "userIdChatMember",
        "type": "string",
        "optional": true,
        "description": "ID of the user to add or remove"
      },
      {
        "id": "{nodeId}-input-chatIdPinMessage-string",
        "name": "chatIdPinMessage",
        "label": "chatIdPinMessage",
        "type": "string",
        "optional": true,
        "description": "ID of the chat"
      },
      {
        "id": "{nodeId}-input-messageIdPinMessage-string",
        "name": "messageIdPinMessage",
        "label": "messageIdPinMessage",
        "type": "string",
        "optional": true,
        "description": "ID of the message to pin or unpin"
      },
      {
        "id": "{nodeId}-input-chatChannelIdListMessages-string",
        "name": "chatChannelIdListMessages",
        "label": "chatChannelIdListMessages",
        "type": "string",
        "optional": true,
        "description": "ID of the chat or channel to list messages from"
      },
      {
        "id": "{nodeId}-input-teamIdListMessages-string",
        "name": "teamIdListMessages",
        "label": "teamIdListMessages",
        "type": "string",
        "optional": true,
        "description": "ID of the team (required for channel messages)"
      },
      {
        "id": "{nodeId}-input-maxResultsListMessages-number",
        "name": "maxResultsListMessages",
        "label": "maxResultsListMessages",
        "type": "number",
        "optional": true,
        "default": "50",
        "description": "Maximum number of messages to return"
      },
      {
        "id": "{nodeId}-input-chatChannelIdGetMessage-string",
        "name": "chatChannelIdGetMessage",
        "label": "chatChannelIdGetMessage",
        "type": "string",
        "optional": true,
        "description": "ID of the chat or channel"
      },
      {
        "id": "{nodeId}-input-teamIdGetMessage-string",
        "name": "teamIdGetMessage",
        "label": "teamIdGetMessage",
        "type": "string",
        "optional": true,
        "description": "ID of the team (required for channel messages)"
      },
      {
        "id": "{nodeId}-input-messageIdGetMessage-string",
        "name": "messageIdGetMessage",
        "label": "messageIdGetMessage",
        "type": "string",
        "optional": true,
        "description": "ID of the message to retrieve"
      },
      {
        "id": "{nodeId}-input-chatChannelIdSendMessage-string",
        "name": "chatChannelIdSendMessage",
        "label": "chatChannelIdSendMessage",
        "type": "string",
        "optional": true,
        "description": "ID of the chat or channel to send message to"
      },
      {
        "id": "{nodeId}-input-teamIdSendMessage-string",
        "name": "teamIdSendMessage",
        "label": "teamIdSendMessage",
        "type": "string",
        "optional": true,
        "description": "ID of the team (required for channel messages)"
      },
      {
        "id": "{nodeId}-input-messageBodySendMessage-string",
        "name": "messageBodySendMessage",
        "label": "messageBodySendMessage",
        "type": "string",
        "optional": true,
        "description": "Content of the message"
      },
      {
        "id": "{nodeId}-input-contentTypeSendMessage-options",
        "name": "contentTypeSendMessage",
        "label": "contentTypeSendMessage",
        "type": "options",
        "optional": true,
        "default": "text",
        "description": "Content type of the message"
      },
      {
        "id": "{nodeId}-input-chatChannelIdUpdateMessage-string",
        "name": "chatChannelIdUpdateMessage",
        "label": "chatChannelIdUpdateMessage",
        "type": "string",
        "optional": true,
        "description": "ID of the chat or channel"
      },
      {
        "id": "{nodeId}-input-teamIdUpdateMessage-string",
        "name": "teamIdUpdateMessage",
        "label": "teamIdUpdateMessage",
        "type": "string",
        "optional": true,
        "description": "ID of the team (required for channel messages)"
      },
      {
        "id": "{nodeId}-input-messageIdUpdateMessage-string",
        "name": "messageIdUpdateMessage",
        "label": "messageIdUpdateMessage",
        "type": "string",
        "optional": true,
        "description": "ID of the message to update"
      },
      {
        "id": "{nodeId}-input-chatChannelIdDeleteMessage-string",
        "name": "chatChannelIdDeleteMessage",
        "label": "chatChannelIdDeleteMessage",
        "type": "string",
        "optional": true,
        "description": "ID of the chat or channel"
      },
      {
        "id": "{nodeId}-input-teamIdDeleteMessage-string",
        "name": "teamIdDeleteMessage",
        "label": "teamIdDeleteMessage",
        "type": "string",
        "optional": true,
        "description": "ID of the team (required for channel messages)"
      },
      {
        "id": "{nodeId}-input-messageIdDeleteMessage-string",
        "name": "messageIdDeleteMessage",
        "label": "messageIdDeleteMessage",
        "type": "string",
        "optional": true,
        "description": "ID of the message to delete"
      },
      {
        "id": "{nodeId}-input-chatChannelIdReplyMessage-string",
        "name": "chatChannelIdReplyMessage",
        "label": "chatChannelIdReplyMessage",
        "type": "string",
        "optional": true,
        "description": "ID of the chat or channel"
      },
      {
        "id": "{nodeId}-input-teamIdReplyMessage-string",
        "name": "teamIdReplyMessage",
        "label": "teamIdReplyMessage",
        "type": "string",
        "optional": true,
        "description": "ID of the team (required for channel messages)"
      },
      {
        "id": "{nodeId}-input-messageIdReplyMessage-string",
        "name": "messageIdReplyMessage",
        "label": "messageIdReplyMessage",
        "type": "string",
        "optional": true,
        "description": "ID of the message to reply to"
      },
      {
        "id": "{nodeId}-input-replyBodyReplyMessage-string",
        "name": "replyBodyReplyMessage",
        "label": "replyBodyReplyMessage",
        "type": "string",
        "optional": true,
        "description": "Content of the reply"
      },
      {
        "id": "{nodeId}-input-chatChannelIdReaction-string",
        "name": "chatChannelIdReaction",
        "label": "chatChannelIdReaction",
        "type": "string",
        "optional": true,
        "description": "ID of the chat or channel"
      },
      {
        "id": "{nodeId}-input-teamIdReaction-string",
        "name": "teamIdReaction",
        "label": "teamIdReaction",
        "type": "string",
        "optional": true,
        "description": "ID of the team (required for channel messages)"
      },
      {
        "id": "{nodeId}-input-messageIdReaction-string",
        "name": "messageIdReaction",
        "label": "messageIdReaction",
        "type": "string",
        "optional": true,
        "description": "ID of the message to react to"
      },
      {
        "id": "{nodeId}-input-reactionTypeSetReaction-options",
        "name": "reactionTypeSetReaction",
        "label": "reactionTypeSetReaction",
        "type": "options",
        "optional": true,
        "default": "like",
        "description": "Type of reaction to set"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-microsoftTeams-MicrosoftTeams|Tool",
        "name": "microsoftTeams",
        "label": "Microsoft Teams",
        "type": "MicrosoftTeams | Tool"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Perform Microsoft Teams operations for channels, chats, and chat messages",
    "baseClasses": [
      "MicrosoftTeams",
      "Tool"
    ],
    "credential_required": [
      "microsoftTeamsOAuth2"
    ]
  },
  {
    "node_type": "openAPIToolkit",
    "name": "openAPIToolkit",
    "label": "OpenAPI Toolkit",
    "category": "Tools",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-selectedEndpoints-asyncMultiOptions",
        "name": "selectedEndpoints",
        "label": "selectedEndpoints",
        "type": "asyncMultiOptions",
        "optional": true,
        "description": "Select which endpoints to expose as tools"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-inputType-options",
        "name": "inputType",
        "label": "inputType",
        "type": "options",
        "optional": true,
        "default": "file",
        "description": "Choose how to provide the OpenAPI specification"
      },
      {
        "id": "{nodeId}-input-openApiFile-file",
        "name": "openApiFile",
        "label": "openApiFile",
        "type": "file",
        "optional": true,
        "description": "Upload your OpenAPI specification file (YAML or JSON)"
      },
      {
        "id": "{nodeId}-input-openApiLink-string",
        "name": "openApiLink",
        "label": "openApiLink",
        "type": "string",
        "optional": true,
        "description": "Provide a link to your OpenAPI specification (YAML or JSON)"
      },
      {
        "id": "{nodeId}-input-selectedServer-asyncOptions",
        "name": "selectedServer",
        "label": "selectedServer",
        "type": "asyncOptions",
        "optional": true,
        "description": "Select which server to use for API calls"
      },
      {
        "id": "{nodeId}-input-returnDirect-boolean",
        "name": "returnDirect",
        "label": "returnDirect",
        "type": "boolean",
        "optional": true,
        "description": "Return the output of the tool directly to the user"
      },
      {
        "id": "{nodeId}-input-removeNulls-boolean",
        "name": "removeNulls",
        "label": "removeNulls",
        "type": "boolean",
        "optional": true,
        "description": "Remove all keys with null values from the parsed arguments"
      },
      {
        "id": "{nodeId}-input-headers-json",
        "name": "headers",
        "label": "headers",
        "type": "json",
        "optional": true,
        "description": "Request headers to be sent with the API request. For example, {\"Authorization\": \"Bearer token\"}"
      },
      {
        "id": "{nodeId}-input-customCode-code",
        "name": "customCode",
        "label": "customCode",
        "type": "code",
        "optional": true,
        "description": "const url = $url; const options = $options;"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-openAPIToolkit-OpenAPIToolkit|Tool",
        "name": "openAPIToolkit",
        "label": "OpenAPI Toolkit",
        "type": "OpenAPIToolkit | Tool"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2.1",
    "description": "Load OpenAPI specification, and converts each API endpoint to a tool",
    "baseClasses": [
      "OpenAPIToolkit",
      "Tool"
    ]
  },
  {
    "node_type": "queryEngineToolLlamaIndex",
    "name": "queryEngineToolLlamaIndex",
    "label": "QueryEngine Tool",
    "category": "Tools",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-baseQueryEngine-BaseQueryEngine",
        "name": "baseQueryEngine",
        "label": "baseQueryEngine",
        "type": "BaseQueryEngine",
        "optional": true,
        "description": "Base QueryEngine"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-toolName-string",
        "name": "toolName",
        "label": "toolName",
        "type": "string",
        "optional": true,
        "description": "Tool name must be small capital letter with underscore. Ex: my_tool"
      },
      {
        "id": "{nodeId}-input-toolDesc-string",
        "name": "toolDesc",
        "label": "toolDesc",
        "type": "string",
        "optional": true,
        "description": "Tool Description"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-queryEngineToolLlamaIndex-QueryEngineTool|Tool_LlamaIndex",
        "name": "queryEngineToolLlamaIndex",
        "label": "QueryEngine Tool",
        "type": "QueryEngineTool | Tool_LlamaIndex"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Tool used to invoke query engine",
    "baseClasses": [
      "QueryEngineTool",
      "Tool_LlamaIndex"
    ]
  },
  {
    "node_type": "requestsDelete",
    "name": "requestsDelete",
    "label": "Requests Delete",
    "category": "Tools",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-requestsDeleteUrl-string",
        "name": "requestsDeleteUrl",
        "label": "requestsDeleteUrl",
        "type": "string",
        "optional": true,
        "description": "URL"
      },
      {
        "id": "{nodeId}-input-requestsDeleteName-string",
        "name": "requestsDeleteName",
        "label": "requestsDeleteName",
        "type": "string",
        "optional": true,
        "default": "requests_delete",
        "description": "Name of the tool"
      },
      {
        "id": "{nodeId}-input-requestsDeleteDescription-string",
        "name": "requestsDeleteDescription",
        "label": "requestsDeleteDescription",
        "type": "string",
        "optional": true,
        "default": "Use this when you need to execute a DELETE request to remove data from a website.",
        "description": "Describe to LLM when it should use this tool"
      },
      {
        "id": "{nodeId}-input-requestsDeleteHeaders-string",
        "name": "requestsDeleteHeaders",
        "label": "requestsDeleteHeaders",
        "type": "string",
        "optional": true,
        "description": "Headers"
      },
      {
        "id": "{nodeId}-input-requestsDeleteQueryParamsSchema-code",
        "name": "requestsDeleteQueryParamsSchema",
        "label": "requestsDeleteQueryParamsSchema",
        "type": "code",
        "optional": true,
        "description": "Description of the available query params to enable LLM to figure out which query params to use"
      },
      {
        "id": "{nodeId}-input-requestsDeleteMaxOutputLength-number",
        "name": "requestsDeleteMaxOutputLength",
        "label": "requestsDeleteMaxOutputLength",
        "type": "number",
        "optional": true,
        "default": "2000",
        "description": "Max length of the output. Remove this if you want to return the entire response"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-requestsDelete-RequestsDelete|DynamicStructuredTool|StructuredTool|Runnable|Tool",
        "name": "requestsDelete",
        "label": "Requests Delete",
        "type": "RequestsDelete | DynamicStructuredTool | StructuredTool | Runnable | Tool"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Execute HTTP DELETE requests",
    "baseClasses": [
      "RequestsDelete",
      "DynamicStructuredTool",
      "StructuredTool",
      "Runnable",
      "Tool"
    ]
  },
  {
    "node_type": "requestsGet",
    "name": "requestsGet",
    "label": "Requests Get",
    "category": "Tools",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-requestsGetUrl-string",
        "name": "requestsGetUrl",
        "label": "requestsGetUrl",
        "type": "string",
        "optional": true,
        "description": "URL"
      },
      {
        "id": "{nodeId}-input-requestsGetName-string",
        "name": "requestsGetName",
        "label": "requestsGetName",
        "type": "string",
        "optional": true,
        "default": "requests_get",
        "description": "Name of the tool"
      },
      {
        "id": "{nodeId}-input-requestsGetDescription-string",
        "name": "requestsGetDescription",
        "label": "requestsGetDescription",
        "type": "string",
        "optional": true,
        "default": "Use this when you need to execute a GET request to get data from a website.",
        "description": "Describe to LLM when it should use this tool"
      },
      {
        "id": "{nodeId}-input-requestsGetHeaders-string",
        "name": "requestsGetHeaders",
        "label": "requestsGetHeaders",
        "type": "string",
        "optional": true,
        "description": "Headers"
      },
      {
        "id": "{nodeId}-input-requestsGetQueryParamsSchema-code",
        "name": "requestsGetQueryParamsSchema",
        "label": "requestsGetQueryParamsSchema",
        "type": "code",
        "optional": true,
        "description": "Description of the available query params to enable LLM to figure out which query params to use"
      },
      {
        "id": "{nodeId}-input-requestsGetMaxOutputLength-number",
        "name": "requestsGetMaxOutputLength",
        "label": "requestsGetMaxOutputLength",
        "type": "number",
        "optional": true,
        "default": "2000",
        "description": "Max length of the output. Remove this if you want to return the entire response"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-requestsGet-RequestsGet|DynamicStructuredTool|StructuredTool|Runnable|Tool",
        "name": "requestsGet",
        "label": "Requests Get",
        "type": "RequestsGet | DynamicStructuredTool | StructuredTool | Runnable | Tool"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Execute HTTP GET requests",
    "baseClasses": [
      "RequestsGet",
      "DynamicStructuredTool",
      "StructuredTool",
      "Runnable",
      "Tool"
    ]
  },
  {
    "node_type": "requestsPost",
    "name": "requestsPost",
    "label": "Requests Post",
    "category": "Tools",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-requestsPostUrl-string",
        "name": "requestsPostUrl",
        "label": "requestsPostUrl",
        "type": "string",
        "optional": true,
        "description": "URL"
      },
      {
        "id": "{nodeId}-input-requestsPostName-string",
        "name": "requestsPostName",
        "label": "requestsPostName",
        "type": "string",
        "optional": true,
        "default": "requests_post",
        "description": "Name of the tool"
      },
      {
        "id": "{nodeId}-input-requestsPostDescription-string",
        "name": "requestsPostDescription",
        "label": "requestsPostDescription",
        "type": "string",
        "optional": true,
        "default": "Use this when you want to execute a POST request to create or update a resource.",
        "description": "Describe to LLM when it should use this tool"
      },
      {
        "id": "{nodeId}-input-requestsPostHeaders-string",
        "name": "requestsPostHeaders",
        "label": "requestsPostHeaders",
        "type": "string",
        "optional": true,
        "description": "Headers"
      },
      {
        "id": "{nodeId}-input-requestPostBody-string",
        "name": "requestPostBody",
        "label": "requestPostBody",
        "type": "string",
        "optional": true,
        "description": "JSON body for the POST request. This will override the body generated by the LLM"
      },
      {
        "id": "{nodeId}-input-requestsPostBodySchema-code",
        "name": "requestsPostBodySchema",
        "label": "requestsPostBodySchema",
        "type": "code",
        "optional": true,
        "description": "Description of the available body params to enable LLM to figure out which body params to use"
      },
      {
        "id": "{nodeId}-input-requestsPostMaxOutputLength-number",
        "name": "requestsPostMaxOutputLength",
        "label": "requestsPostMaxOutputLength",
        "type": "number",
        "optional": true,
        "default": "2000",
        "description": "Max length of the output. Remove this if you want to return the entire response"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-requestsPost-RequestsPost|DynamicStructuredTool|StructuredTool|Runnable|Tool",
        "name": "requestsPost",
        "label": "Requests Post",
        "type": "RequestsPost | DynamicStructuredTool | StructuredTool | Runnable | Tool"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Execute HTTP POST requests",
    "baseClasses": [
      "RequestsPost",
      "DynamicStructuredTool",
      "StructuredTool",
      "Runnable",
      "Tool"
    ]
  },
  {
    "node_type": "requestsPut",
    "name": "requestsPut",
    "label": "Requests Put",
    "category": "Tools",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-requestsPutUrl-string",
        "name": "requestsPutUrl",
        "label": "requestsPutUrl",
        "type": "string",
        "optional": true,
        "description": "URL"
      },
      {
        "id": "{nodeId}-input-requestsPutName-string",
        "name": "requestsPutName",
        "label": "requestsPutName",
        "type": "string",
        "optional": true,
        "default": "requests_put",
        "description": "Name of the tool"
      },
      {
        "id": "{nodeId}-input-requestsPutDescription-string",
        "name": "requestsPutDescription",
        "label": "requestsPutDescription",
        "type": "string",
        "optional": true,
        "default": "Use this when you want to execute a PUT request to update or replace a resource.",
        "description": "Describe to LLM when it should use this tool"
      },
      {
        "id": "{nodeId}-input-requestsPutHeaders-string",
        "name": "requestsPutHeaders",
        "label": "requestsPutHeaders",
        "type": "string",
        "optional": true,
        "description": "Headers"
      },
      {
        "id": "{nodeId}-input-requestPutBody-string",
        "name": "requestPutBody",
        "label": "requestPutBody",
        "type": "string",
        "optional": true,
        "description": "JSON body for the PUT request. This will override the body generated by the LLM"
      },
      {
        "id": "{nodeId}-input-requestsPutBodySchema-code",
        "name": "requestsPutBodySchema",
        "label": "requestsPutBodySchema",
        "type": "code",
        "optional": true,
        "description": "Description of the available body params to enable LLM to figure out which body params to use"
      },
      {
        "id": "{nodeId}-input-requestsPutMaxOutputLength-number",
        "name": "requestsPutMaxOutputLength",
        "label": "requestsPutMaxOutputLength",
        "type": "number",
        "optional": true,
        "default": "2000",
        "description": "Max length of the output. Remove this if you want to return the entire response"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-requestsPut-RequestsPut|DynamicStructuredTool|StructuredTool|Runnable|Tool",
        "name": "requestsPut",
        "label": "Requests Put",
        "type": "RequestsPut | DynamicStructuredTool | StructuredTool | Runnable | Tool"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Execute HTTP PUT requests",
    "baseClasses": [
      "RequestsPut",
      "DynamicStructuredTool",
      "StructuredTool",
      "Runnable",
      "Tool"
    ]
  },
  {
    "node_type": "retrieverTool",
    "name": "retrieverTool",
    "label": "Retriever Tool",
    "category": "Tools",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-retriever-BaseRetriever",
        "name": "retriever",
        "label": "retriever",
        "type": "BaseRetriever",
        "optional": true,
        "description": "Retriever"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-name-string",
        "name": "name",
        "label": "name",
        "type": "string",
        "optional": true,
        "description": "Retriever Name"
      },
      {
        "id": "{nodeId}-input-description-string",
        "name": "description",
        "label": "description",
        "type": "string",
        "optional": true,
        "description": "When should agent uses to retrieve documents"
      },
      {
        "id": "{nodeId}-input-returnSourceDocuments-boolean",
        "name": "returnSourceDocuments",
        "label": "returnSourceDocuments",
        "type": "boolean",
        "optional": true,
        "description": "Return Source Documents"
      },
      {
        "id": "{nodeId}-input-retrieverToolMetadataFilter-json",
        "name": "retrieverToolMetadataFilter",
        "label": "retrieverToolMetadataFilter",
        "type": "json",
        "optional": true,
        "description": "Add additional metadata filter on top of the existing filter from vector store"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable",
        "name": "retrieverTool",
        "label": "Retriever Tool",
        "type": "RetrieverTool | DynamicTool | Tool | StructuredTool | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "3",
    "description": "Use a retriever as allowed tool for agent",
    "baseClasses": [
      "RetrieverTool",
      "DynamicTool",
      "Tool",
      "StructuredTool",
      "Runnable"
    ]
  },
  {
    "node_type": "searXNG",
    "name": "searXNG",
    "label": "SearXNG",
    "category": "Tools",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-apiBase-string",
        "name": "apiBase",
        "label": "apiBase",
        "type": "string",
        "optional": true,
        "default": "http://localhost:8080",
        "description": "Base URL"
      },
      {
        "id": "{nodeId}-input-toolName-string",
        "name": "toolName",
        "label": "toolName",
        "type": "string",
        "optional": true,
        "default": "searxng-search",
        "description": "Tool Name"
      },
      {
        "id": "{nodeId}-input-toolDescription-string",
        "name": "toolDescription",
        "label": "toolDescription",
        "type": "string",
        "optional": true,
        "default": "A meta search engine. Useful for when you need to answer questions about current events. Input should be a search query. Output is a JSON array of the query results",
        "description": "Tool Description"
      },
      {
        "id": "{nodeId}-input-headers-json",
        "name": "headers",
        "label": "headers",
        "type": "json",
        "optional": true,
        "description": "Custom headers for the request"
      },
      {
        "id": "{nodeId}-input-format-options",
        "name": "format",
        "label": "format",
        "type": "options",
        "optional": true,
        "default": "json",
        "description": "Format of the response. You need to enable search formats in settings.yml. Refer to <a target=\"_blan"
      },
      {
        "id": "{nodeId}-input-categories-string",
        "name": "categories",
        "label": "categories",
        "type": "string",
        "optional": true,
        "description": "Comma separated list, specifies the active search categories. (see <a target=\"_blank\" href=\"https://"
      },
      {
        "id": "{nodeId}-input-engines-string",
        "name": "engines",
        "label": "engines",
        "type": "string",
        "optional": true,
        "description": "Comma separated list, specifies the active search engines. (see <a target=\"_blank\" href=\"https://doc"
      },
      {
        "id": "{nodeId}-input-language-string",
        "name": "language",
        "label": "language",
        "type": "string",
        "optional": true,
        "description": "Code of the language."
      },
      {
        "id": "{nodeId}-input-pageno-number",
        "name": "pageno",
        "label": "pageno",
        "type": "number",
        "optional": true,
        "description": "Search page number."
      },
      {
        "id": "{nodeId}-input-time_range-string",
        "name": "time_range",
        "label": "time_range",
        "type": "string",
        "optional": true,
        "description": "Time range of search for engines which support it. See if an engine supports time range search in th"
      },
      {
        "id": "{nodeId}-input-safesearch-number",
        "name": "safesearch",
        "label": "safesearch",
        "type": "number",
        "optional": true,
        "description": "Filter search results of engines which support safe search. See if an engine supports safe search in"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-searXNG-SearXNG|Tool|StructuredTool|Runnable",
        "name": "searXNG",
        "label": "SearXNG",
        "type": "SearXNG | Tool | StructuredTool | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "3",
    "description": "Wrapper around SearXNG - a free internet metasearch engine",
    "baseClasses": [
      "SearXNG",
      "Tool",
      "StructuredTool",
      "Runnable"
    ]
  },
  {
    "node_type": "searchAPI",
    "name": "searchAPI",
    "label": "SearchApi",
    "category": "Tools",
    "inputAnchors": [],
    "inputParams": [],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-searchAPI-SearchAPI|Tool|StructuredTool|Runnable",
        "name": "searchAPI",
        "label": "SearchApi",
        "type": "SearchAPI | Tool | StructuredTool | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Real-time API for accessing Google Search data",
    "baseClasses": [
      "SearchAPI",
      "Tool",
      "StructuredTool",
      "Runnable"
    ],
    "credential_required": [
      "searchApi"
    ]
  },
  {
    "node_type": "serpAPI",
    "name": "serpAPI",
    "label": "Serp API",
    "category": "Tools",
    "inputAnchors": [],
    "inputParams": [],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-serpAPI-SerpAPI|Tool|StructuredTool|Runnable",
        "name": "serpAPI",
        "label": "Serp API",
        "type": "SerpAPI | Tool | StructuredTool | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Wrapper around SerpAPI - a real-time API to access Google search results",
    "baseClasses": [
      "SerpAPI",
      "Tool",
      "StructuredTool",
      "Runnable"
    ],
    "credential_required": [
      "serpApi"
    ]
  },
  {
    "node_type": "serper",
    "name": "serper",
    "label": "Serper",
    "category": "Tools",
    "inputAnchors": [],
    "inputParams": [],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-serper-Serper|Tool|StructuredTool|Runnable",
        "name": "serper",
        "label": "Serper",
        "type": "Serper | Tool | StructuredTool | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Wrapper around Serper.dev - Google Search API",
    "baseClasses": [
      "Serper",
      "Tool",
      "StructuredTool",
      "Runnable"
    ],
    "credential_required": [
      "serperApi"
    ]
  },
  {
    "node_type": "stripeAgentTool",
    "name": "stripeAgentTool",
    "label": "StripeAgentTool",
    "category": "Tools",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-paymentLinks-multiOptions",
        "name": "paymentLinks",
        "label": "paymentLinks",
        "type": "multiOptions",
        "optional": true,
        "description": "Payment Links"
      },
      {
        "id": "{nodeId}-input-products-multiOptions",
        "name": "products",
        "label": "products",
        "type": "multiOptions",
        "optional": true,
        "description": "Products"
      },
      {
        "id": "{nodeId}-input-prices-multiOptions",
        "name": "prices",
        "label": "prices",
        "type": "multiOptions",
        "optional": true,
        "description": "Prices"
      },
      {
        "id": "{nodeId}-input-balance-multiOptions",
        "name": "balance",
        "label": "balance",
        "type": "multiOptions",
        "optional": true,
        "description": "Balance"
      },
      {
        "id": "{nodeId}-input-invoiceItems-multiOptions",
        "name": "invoiceItems",
        "label": "invoiceItems",
        "type": "multiOptions",
        "optional": true,
        "description": "Invoice Items"
      },
      {
        "id": "{nodeId}-input-invoices-multiOptions",
        "name": "invoices",
        "label": "invoices",
        "type": "multiOptions",
        "optional": true,
        "description": "Invoices"
      },
      {
        "id": "{nodeId}-input-customers-multiOptions",
        "name": "customers",
        "label": "customers",
        "type": "multiOptions",
        "optional": true,
        "description": "Customers"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-stripeAgentTool-stripeAgentTool|Tool",
        "name": "stripeAgentTool",
        "label": "StripeAgentTool",
        "type": "stripeAgentTool | Tool"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Use Stripe Agent function calling for financial transactions",
    "baseClasses": [
      "stripeAgentTool",
      "Tool"
    ],
    "credential_required": [
      "stripeApi"
    ]
  },
  {
    "node_type": "tavilyAPI",
    "name": "tavilyAPI",
    "label": "Tavily API",
    "category": "Tools",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-topic-options",
        "name": "topic",
        "label": "topic",
        "type": "options",
        "optional": true,
        "default": "general",
        "description": "The category of the search. News for real-time updates, general for broader searches"
      },
      {
        "id": "{nodeId}-input-searchDepth-options",
        "name": "searchDepth",
        "label": "searchDepth",
        "type": "options",
        "optional": true,
        "default": "basic",
        "description": "The depth of the search. Advanced costs 2 API Credits, basic costs 1"
      },
      {
        "id": "{nodeId}-input-chunksPerSource-number",
        "name": "chunksPerSource",
        "label": "chunksPerSource",
        "type": "number",
        "optional": true,
        "default": "3",
        "description": "Number of content chunks per source (1-3). Only for advanced search"
      },
      {
        "id": "{nodeId}-input-maxResults-number",
        "name": "maxResults",
        "label": "maxResults",
        "type": "number",
        "optional": true,
        "default": "5",
        "description": "Maximum number of search results (0-20)"
      },
      {
        "id": "{nodeId}-input-timeRange-options",
        "name": "timeRange",
        "label": "timeRange",
        "type": "options",
        "optional": true,
        "description": "Time range to filter results"
      },
      {
        "id": "{nodeId}-input-days-number",
        "name": "days",
        "label": "days",
        "type": "number",
        "optional": true,
        "default": "7",
        "description": "Number of days back from current date (only for news topic)"
      },
      {
        "id": "{nodeId}-input-includeAnswer-boolean",
        "name": "includeAnswer",
        "label": "includeAnswer",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Include an LLM-generated answer to the query"
      },
      {
        "id": "{nodeId}-input-includeRawContent-boolean",
        "name": "includeRawContent",
        "label": "includeRawContent",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Include cleaned and parsed HTML content of each result"
      },
      {
        "id": "{nodeId}-input-includeImages-boolean",
        "name": "includeImages",
        "label": "includeImages",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Include image search results"
      },
      {
        "id": "{nodeId}-input-includeImageDescriptions-boolean",
        "name": "includeImageDescriptions",
        "label": "includeImageDescriptions",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Include descriptive text for each image"
      },
      {
        "id": "{nodeId}-input-includeDomains-string",
        "name": "includeDomains",
        "label": "includeDomains",
        "type": "string",
        "optional": true,
        "description": "Comma-separated list of domains to include in results"
      },
      {
        "id": "{nodeId}-input-excludeDomains-string",
        "name": "excludeDomains",
        "label": "excludeDomains",
        "type": "string",
        "optional": true,
        "description": "Comma-separated list of domains to exclude from results"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-tavilyAPI-TavilyAPI|Tool|StructuredTool|Runnable",
        "name": "tavilyAPI",
        "label": "Tavily API",
        "type": "TavilyAPI | Tool | StructuredTool | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1.2",
    "description": "Wrapper around TavilyAPI - A specialized search engine designed for LLMs and AI agents",
    "baseClasses": [
      "TavilyAPI",
      "Tool",
      "StructuredTool",
      "Runnable"
    ],
    "credential_required": [
      "tavilyApi"
    ]
  },
  {
    "node_type": "webBrowser",
    "name": "webBrowser",
    "label": "Web Browser",
    "category": "Tools",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-model-BaseLanguageModel",
        "name": "model",
        "label": "model",
        "type": "BaseLanguageModel",
        "optional": true,
        "description": "Language Model"
      },
      {
        "id": "{nodeId}-input-embeddings-Embeddings",
        "name": "embeddings",
        "label": "embeddings",
        "type": "Embeddings",
        "optional": true,
        "description": "Embeddings"
      }
    ],
    "inputParams": [],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-webBrowser-WebBrowser|Tool|StructuredTool|Runnable",
        "name": "webBrowser",
        "label": "Web Browser",
        "type": "WebBrowser | Tool | StructuredTool | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Gives agent the ability to visit a website and extract information",
    "baseClasses": [
      "WebBrowser",
      "Tool",
      "StructuredTool",
      "Runnable"
    ]
  },
  {
    "node_type": "webScraperTool",
    "name": "webScraperTool",
    "label": "Web Scraper Tool",
    "category": "Tools",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-scrapeMode-options",
        "name": "scrapeMode",
        "label": "scrapeMode",
        "type": "options",
        "optional": true,
        "default": "recursive",
        "description": "Select discovery method: 'Recursive' follows links found on pages (uses Max Depth). 'Sitemap' tries"
      },
      {
        "id": "{nodeId}-input-maxDepth-number",
        "name": "maxDepth",
        "label": "maxDepth",
        "type": "number",
        "optional": true,
        "default": "1",
        "description": "Maximum levels of links to follow (e.g., 1 = only the initial URL, 2 = initial URL + links found on"
      },
      {
        "id": "{nodeId}-input-maxPages-number",
        "name": "maxPages",
        "label": "maxPages",
        "type": "number",
        "optional": true,
        "default": "10",
        "description": "Maximum total number of pages to scrape, regardless of mode or depth. Stops when this limit is reach"
      },
      {
        "id": "{nodeId}-input-timeoutS-number",
        "name": "timeoutS",
        "label": "timeoutS",
        "type": "number",
        "optional": true,
        "default": "60",
        "description": "Maximum time in seconds to wait for each page request to complete. Accepts decimals (e.g., 0.5). Def"
      },
      {
        "id": "{nodeId}-input-description-string",
        "name": "description",
        "label": "description",
        "type": "string",
        "optional": true,
        "description": "Custom description of what the tool does. This is for LLM to determine when to use this tool. Overri"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-webScraperTool-Tool|Tool|StructuredTool|Runnable",
        "name": "webScraperTool",
        "label": "Web Scraper Tool",
        "type": "Tool | Tool | StructuredTool | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1.1",
    "description": "Scrapes web pages recursively by following links OR by fetching URLs from the default sitemap.",
    "baseClasses": [
      "Tool",
      "Tool",
      "StructuredTool",
      "Runnable"
    ]
  },
  {
    "node_type": "wolframAlpha",
    "name": "wolframAlpha",
    "label": "WolframAlpha",
    "category": "Tools",
    "inputAnchors": [],
    "inputParams": [],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-wolframAlpha-WolframAlpha|Tool|StructuredTool|Runnable",
        "name": "wolframAlpha",
        "label": "WolframAlpha",
        "type": "WolframAlpha | Tool | StructuredTool | Runnable"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Wrapper around WolframAlpha - a powerful computational knowledge engine",
    "baseClasses": [
      "WolframAlpha",
      "Tool",
      "StructuredTool",
      "Runnable"
    ],
    "credential_required": [
      "wolframAlphaAppId"
    ]
  },
  {
    "node_type": "braveSearchMCP",
    "name": "braveSearchMCP",
    "label": "Brave Search MCP",
    "category": "Tools (MCP)",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-mcpActions-asyncMultiOptions",
        "name": "mcpActions",
        "label": "mcpActions",
        "type": "asyncMultiOptions",
        "optional": true,
        "description": "Available Actions"
      }
    ],
    "inputParams": [],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-braveSearchMCP-Tool",
        "name": "braveSearchMCP",
        "label": "Brave Search MCP",
        "type": "Tool"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "MCP server that integrates the Brave Search API - a real-time API to access web search capabilities",
    "baseClasses": [
      "Tool"
    ],
    "credential_required": [
      "braveSearchApi"
    ]
  },
  {
    "node_type": "customMCP",
    "name": "customMCP",
    "label": "Custom MCP",
    "category": "Tools (MCP)",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-mcpActions-asyncMultiOptions",
        "name": "mcpActions",
        "label": "mcpActions",
        "type": "asyncMultiOptions",
        "optional": true,
        "description": "Available Actions"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-mcpServerConfig-code",
        "name": "mcpServerConfig",
        "label": "mcpServerConfig",
        "type": "code",
        "optional": true,
        "description": "MCP Server Config"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-customMCP-Tool",
        "name": "customMCP",
        "label": "Custom MCP",
        "type": "Tool"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1.1",
    "description": "Custom MCP Config",
    "baseClasses": [
      "Tool"
    ]
  },
  {
    "node_type": "githubMCP",
    "name": "githubMCP",
    "label": "Github MCP",
    "category": "Tools (MCP)",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-mcpActions-asyncMultiOptions",
        "name": "mcpActions",
        "label": "mcpActions",
        "type": "asyncMultiOptions",
        "optional": true,
        "description": "Available Actions"
      }
    ],
    "inputParams": [],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-githubMCP-Tool",
        "name": "githubMCP",
        "label": "Github MCP",
        "type": "Tool"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "MCP Server for the GitHub API",
    "baseClasses": [
      "Tool"
    ],
    "credential_required": [
      "githubApi"
    ]
  },
  {
    "node_type": "postgreSQLMCP",
    "name": "postgreSQLMCP",
    "label": "PostgreSQL MCP",
    "category": "Tools (MCP)",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-mcpActions-asyncMultiOptions",
        "name": "mcpActions",
        "label": "mcpActions",
        "type": "asyncMultiOptions",
        "optional": true,
        "description": "Available Actions"
      }
    ],
    "inputParams": [],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-postgreSQLMCP-Tool",
        "name": "postgreSQLMCP",
        "label": "PostgreSQL MCP",
        "type": "Tool"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "MCP server that provides read-only access to PostgreSQL databases",
    "baseClasses": [
      "Tool"
    ],
    "credential_required": [
      "PostgresUrl"
    ]
  },
  {
    "node_type": "sequentialThinkingMCP",
    "name": "sequentialThinkingMCP",
    "label": "Sequential Thinking MCP",
    "category": "Tools (MCP)",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-mcpActions-asyncMultiOptions",
        "name": "mcpActions",
        "label": "mcpActions",
        "type": "asyncMultiOptions",
        "optional": true,
        "description": "Available Actions"
      }
    ],
    "inputParams": [],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-sequentialThinkingMCP-Tool",
        "name": "sequentialThinkingMCP",
        "label": "Sequential Thinking MCP",
        "type": "Tool"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "MCP server that provides a tool for dynamic and reflective problem-solving through a structured thinking process",
    "baseClasses": [
      "Tool"
    ]
  },
  {
    "node_type": "slackMCP",
    "name": "slackMCP",
    "label": "Slack MCP",
    "category": "Tools (MCP)",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-mcpActions-asyncMultiOptions",
        "name": "mcpActions",
        "label": "mcpActions",
        "type": "asyncMultiOptions",
        "optional": true,
        "description": "Available Actions"
      }
    ],
    "inputParams": [],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-slackMCP-Tool",
        "name": "slackMCP",
        "label": "Slack MCP",
        "type": "Tool"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "MCP Server for the Slack API",
    "baseClasses": [
      "Tool"
    ],
    "credential_required": [
      "slackApi"
    ]
  },
  {
    "node_type": "supergatewayMCP",
    "name": "supergatewayMCP",
    "label": "Supergateway MCP",
    "category": "Tools (MCP)",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-mcpActions-asyncMultiOptions",
        "name": "mcpActions",
        "label": "mcpActions",
        "type": "asyncMultiOptions",
        "optional": true,
        "description": "Available Actions"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-arguments-string",
        "name": "arguments",
        "label": "arguments",
        "type": "string",
        "optional": true,
        "description": "Arguments to pass to the supergateway server. Refer to the <a href=\"https://github.com/supercorp-ai/"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-supergatewayMCP-Tool",
        "name": "supergatewayMCP",
        "label": "Supergateway MCP",
        "type": "Tool"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Runs MCP stdio-based servers over SSE (Server-Sent Events) or WebSockets (WS)",
    "baseClasses": [
      "Tool"
    ]
  },
  {
    "node_type": "teradataMCP",
    "name": "teradataMCP",
    "label": "Teradata MCP",
    "category": "Tools (MCP)",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-mcpActions-asyncMultiOptions",
        "name": "mcpActions",
        "label": "mcpActions",
        "type": "asyncMultiOptions",
        "optional": true,
        "description": "Available Actions"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-mcpUrl-string",
        "name": "mcpUrl",
        "label": "mcpUrl",
        "type": "string",
        "optional": false,
        "description": "URL of your Teradata MCP server"
      },
      {
        "id": "{nodeId}-input-bearerToken-string",
        "name": "bearerToken",
        "label": "bearerToken",
        "type": "string",
        "optional": true,
        "description": "Optional to override Default set credentials"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-teradataMCP-Tool",
        "name": "teradataMCP",
        "label": "Teradata MCP",
        "type": "Tool"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "MCP Server for Teradata (remote HTTP streamable)",
    "baseClasses": [
      "Tool"
    ],
    "credential_required": [
      "teradataTD2Auth",
      "teradataBearerToken"
    ]
  },
  {
    "node_type": "customFunction",
    "name": "customFunction",
    "label": "Custom JS Function",
    "category": "Utilities",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-tools-Tool",
        "name": "tools",
        "label": "tools",
        "type": "Tool",
        "optional": true,
        "description": "Tools can be used in the function with $tools.{tool_name}.invoke(args)"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-functionInputVariables-json",
        "name": "functionInputVariables",
        "label": "functionInputVariables",
        "type": "json",
        "optional": true,
        "description": "Input variables can be used in the function with prefix $. For example: $var"
      },
      {
        "id": "{nodeId}-input-functionName-string",
        "name": "functionName",
        "label": "functionName",
        "type": "string",
        "optional": true,
        "description": "Function Name"
      },
      {
        "id": "{nodeId}-input-javascriptFunction-code",
        "name": "javascriptFunction",
        "label": "javascriptFunction",
        "type": "code",
        "optional": true,
        "description": "Javascript Function"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-customFunction-CustomFunction|Utilities",
        "name": "customFunction",
        "label": "Custom JS Function",
        "type": "CustomFunction | Utilities"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "3",
    "description": "Execute custom javascript function",
    "baseClasses": [
      "CustomFunction",
      "Utilities"
    ]
  },
  {
    "node_type": "getVariable",
    "name": "getVariable",
    "label": "Get Variable",
    "category": "Utilities",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-variableName-string",
        "name": "variableName",
        "label": "variableName",
        "type": "string",
        "optional": true,
        "description": "Variable Name"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-getVariable-GetVariable|Utilities",
        "name": "getVariable",
        "label": "Get Variable",
        "type": "GetVariable | Utilities"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Get variable that was saved using Set Variable node",
    "baseClasses": [
      "GetVariable",
      "Utilities"
    ]
  },
  {
    "node_type": "ifElseFunction",
    "name": "ifElseFunction",
    "label": "IfElse Function",
    "category": "Utilities",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-functionInputVariables-json",
        "name": "functionInputVariables",
        "label": "functionInputVariables",
        "type": "json",
        "optional": true,
        "description": "Input variables can be used in the function with prefix $. For example: $var"
      },
      {
        "id": "{nodeId}-input-functionName-string",
        "name": "functionName",
        "label": "functionName",
        "type": "string",
        "optional": true,
        "description": "IfElse Name"
      },
      {
        "id": "{nodeId}-input-ifFunction-code",
        "name": "ifFunction",
        "label": "ifFunction",
        "type": "code",
        "optional": true,
        "description": "return true; } | Function must return a value |"
      },
      {
        "id": "{nodeId}-input-elseFunction-code",
        "name": "elseFunction",
        "label": "elseFunction",
        "type": "code",
        "optional": true,
        "default": "return false;",
        "description": "Function must return a value"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-ifElseFunction-IfElseFunction|Utilities",
        "name": "ifElseFunction",
        "label": "IfElse Function",
        "type": "IfElseFunction | Utilities"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Split flows based on If Else javascript functions",
    "baseClasses": [
      "IfElseFunction",
      "Utilities"
    ]
  },
  {
    "node_type": "setVariable",
    "name": "setVariable",
    "label": "Set Variable",
    "category": "Utilities",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-input-string",
        "name": "input",
        "label": "input",
        "type": "string",
        "optional": true,
        "default": "number",
        "description": "boolean"
      },
      {
        "id": "{nodeId}-input-variableName-string",
        "name": "variableName",
        "label": "variableName",
        "type": "string",
        "optional": true,
        "description": "Variable Name"
      },
      {
        "id": "{nodeId}-input-showOutput-boolean",
        "name": "showOutput",
        "label": "showOutput",
        "type": "boolean",
        "optional": true,
        "description": "Show the output result in the Prediction API response"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-setVariable-SetVariable|Utilities",
        "name": "setVariable",
        "label": "Set Variable",
        "type": "SetVariable | Utilities"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2.1",
    "description": "Set variable which can be retrieved at a later stage. Variable is only available during runtime.",
    "baseClasses": [
      "SetVariable",
      "Utilities"
    ]
  },
  {
    "node_type": "stickyNote",
    "name": "stickyNote",
    "label": "Sticky Note",
    "category": "Utilities",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-note-string",
        "name": "note",
        "label": "note",
        "type": "string",
        "optional": true
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-stickyNote-StickyNote",
        "name": "stickyNote",
        "label": "Sticky Note",
        "type": "StickyNote"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Add a sticky note",
    "baseClasses": [
      "StickyNote"
    ]
  },
  {
    "node_type": "Astra",
    "name": "Astra",
    "label": "Astra",
    "category": "Vector Stores",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-document-Document",
        "name": "document",
        "label": "document",
        "type": "Document",
        "optional": true,
        "description": "Document"
      },
      {
        "id": "{nodeId}-input-embeddings-Embeddings",
        "name": "embeddings",
        "label": "embeddings",
        "type": "Embeddings",
        "optional": true,
        "description": "Embeddings"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-astraNamespace-string",
        "name": "astraNamespace",
        "label": "astraNamespace",
        "type": "string",
        "optional": true,
        "description": "Namespace"
      },
      {
        "id": "{nodeId}-input-astraCollection-string",
        "name": "astraCollection",
        "label": "astraCollection",
        "type": "string",
        "optional": true,
        "description": "Collection"
      },
      {
        "id": "{nodeId}-input-vectorDimension-number",
        "name": "vectorDimension",
        "label": "vectorDimension",
        "type": "number",
        "optional": true,
        "description": "Dimension used for storing vector embedding"
      },
      {
        "id": "{nodeId}-input-similarityMetric-string",
        "name": "similarityMetric",
        "label": "similarityMetric",
        "type": "string",
        "optional": true,
        "description": "cosine"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Number of top results to fetch. Default to 4"
      },
      {
        "id": "{nodeId}-input-searchType-options",
        "name": "searchType",
        "label": "searchType",
        "type": "options",
        "optional": true,
        "default": "similarity",
        "description": "Search Type"
      },
      {
        "id": "{nodeId}-input-fetchK-number",
        "name": "fetchK",
        "label": "fetchK",
        "type": "number",
        "optional": true,
        "description": "Number of initial documents to fetch for MMR reranking. Default to 20. Used only when the search typ"
      },
      {
        "id": "{nodeId}-input-lambda-number",
        "name": "lambda",
        "label": "lambda",
        "type": "number",
        "optional": true,
        "description": "Number between 0 and 1 that determines the degree of diversity among the results, where 0 correspond"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-Astra-Astra|VectorStoreRetriever|BaseRetriever",
        "name": "Astra",
        "label": "Astra",
        "type": "Astra | VectorStoreRetriever | BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Upsert embedded data and perform similarity or mmr search upon query using DataStax Astra DB, a serverless vector database thats perfect for managing mission-critical AI workloads",
    "baseClasses": [
      "Astra",
      "VectorStoreRetriever",
      "BaseRetriever"
    ],
    "credential_required": [
      "AstraDBApi"
    ]
  },
  {
    "node_type": "chroma",
    "name": "chroma",
    "label": "Chroma",
    "category": "Vector Stores",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-document-Document",
        "name": "document",
        "label": "document",
        "type": "Document",
        "optional": true,
        "description": "Document"
      },
      {
        "id": "{nodeId}-input-embeddings-Embeddings",
        "name": "embeddings",
        "label": "embeddings",
        "type": "Embeddings",
        "optional": true,
        "description": "Embeddings"
      },
      {
        "id": "{nodeId}-input-recordManager-RecordManager",
        "name": "recordManager",
        "label": "recordManager",
        "type": "RecordManager",
        "optional": true,
        "description": "Keep track of the record to prevent duplication"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-collectionName-string",
        "name": "collectionName",
        "label": "collectionName",
        "type": "string",
        "optional": true,
        "description": "Collection Name"
      },
      {
        "id": "{nodeId}-input-chromaURL-string",
        "name": "chromaURL",
        "label": "chromaURL",
        "type": "string",
        "optional": true,
        "description": "Chroma URL"
      },
      {
        "id": "{nodeId}-input-chromaMetadataFilter-json",
        "name": "chromaMetadataFilter",
        "label": "chromaMetadataFilter",
        "type": "json",
        "optional": true,
        "description": "Chroma Metadata Filter"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Number of top results to fetch. Default to 4"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-chroma-Chroma|VectorStoreRetriever|BaseRetriever",
        "name": "chroma",
        "label": "Chroma",
        "type": "Chroma | VectorStoreRetriever | BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Upsert embedded data and perform similarity search upon query using Chroma, an open-source embedding database",
    "baseClasses": [
      "Chroma",
      "VectorStoreRetriever",
      "BaseRetriever"
    ],
    "credential_required": [
      "chromaApi"
    ]
  },
  {
    "node_type": "couchbase",
    "name": "couchbase",
    "label": "Couchbase",
    "category": "Vector Stores",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-document-Document",
        "name": "document",
        "label": "document",
        "type": "Document",
        "optional": true,
        "description": "Document"
      },
      {
        "id": "{nodeId}-input-embeddings-Embeddings",
        "name": "embeddings",
        "label": "embeddings",
        "type": "Embeddings",
        "optional": true,
        "description": "Embeddings"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-bucketName-string",
        "name": "bucketName",
        "label": "bucketName",
        "type": "string",
        "optional": true,
        "description": "Bucket Name"
      },
      {
        "id": "{nodeId}-input-scopeName-string",
        "name": "scopeName",
        "label": "scopeName",
        "type": "string",
        "optional": true,
        "description": "Scope Name"
      },
      {
        "id": "{nodeId}-input-collectionName-string",
        "name": "collectionName",
        "label": "collectionName",
        "type": "string",
        "optional": true,
        "description": "Collection Name"
      },
      {
        "id": "{nodeId}-input-indexName-string",
        "name": "indexName",
        "label": "indexName",
        "type": "string",
        "optional": true,
        "description": "Index Name"
      },
      {
        "id": "{nodeId}-input-textKey-string",
        "name": "textKey",
        "label": "textKey",
        "type": "string",
        "optional": true,
        "default": "text",
        "description": "Name of the field (column) that contains the actual content"
      },
      {
        "id": "{nodeId}-input-embeddingKey-string",
        "name": "embeddingKey",
        "label": "embeddingKey",
        "type": "string",
        "optional": true,
        "default": "embedding",
        "description": "Name of the field (column) that contains the Embedding"
      },
      {
        "id": "{nodeId}-input-couchbaseMetadataFilter-json",
        "name": "couchbaseMetadataFilter",
        "label": "couchbaseMetadataFilter",
        "type": "json",
        "optional": true,
        "description": "Couchbase Metadata Filter"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Number of top results to fetch. Default to 4"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-couchbase-Couchbase|VectorStoreRetriever|BaseRetriever",
        "name": "couchbase",
        "label": "Couchbase",
        "type": "Couchbase | VectorStoreRetriever | BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Upsert embedded data and load existing index using Couchbase, a award-winning distributed NoSQL database",
    "baseClasses": [
      "Couchbase",
      "VectorStoreRetriever",
      "BaseRetriever"
    ],
    "credential_required": [
      "couchbaseApi"
    ]
  },
  {
    "node_type": "documentStoreVS",
    "name": "documentStoreVS",
    "label": "Document Store (Vector)",
    "category": "Vector Stores",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-selectedStore-asyncOptions",
        "name": "selectedStore",
        "label": "selectedStore",
        "type": "asyncOptions",
        "optional": true,
        "description": "Select Store"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-documentStoreVS-DocumentStoreVS",
        "name": "documentStoreVS",
        "label": "Document Store (Vector)",
        "type": "DocumentStoreVS"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Search and retrieve documents from Document Store",
    "baseClasses": [
      "DocumentStoreVS"
    ]
  },
  {
    "node_type": "elasticsearch",
    "name": "elasticsearch",
    "label": "Elasticsearch",
    "category": "Vector Stores",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-document-Document",
        "name": "document",
        "label": "document",
        "type": "Document",
        "optional": true,
        "description": "Document"
      },
      {
        "id": "{nodeId}-input-embeddings-Embeddings",
        "name": "embeddings",
        "label": "embeddings",
        "type": "Embeddings",
        "optional": true,
        "description": "Embeddings"
      },
      {
        "id": "{nodeId}-input-recordManager-RecordManager",
        "name": "recordManager",
        "label": "recordManager",
        "type": "RecordManager",
        "optional": true,
        "description": "Keep track of the record to prevent duplication"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-indexName-string",
        "name": "indexName",
        "label": "indexName",
        "type": "string",
        "optional": true,
        "description": "Index Name"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Number of top results to fetch. Default to 4"
      },
      {
        "id": "{nodeId}-input-similarity-options",
        "name": "similarity",
        "label": "similarity",
        "type": "options",
        "optional": true,
        "default": "l2_norm",
        "description": "Similarity measure used in Elasticsearch."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-elasticsearch-Elasticsearch|VectorStoreRetriever|BaseRetriever",
        "name": "elasticsearch",
        "label": "Elasticsearch",
        "type": "Elasticsearch | VectorStoreRetriever | BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Upsert embedded data and perform similarity search upon query using Elasticsearch, a distributed search and analytics engine",
    "baseClasses": [
      "Elasticsearch",
      "VectorStoreRetriever",
      "BaseRetriever"
    ],
    "credential_required": [
      "elasticsearchApi",
      "elasticSearchUserPassword"
    ]
  },
  {
    "node_type": "faiss",
    "name": "faiss",
    "label": "Faiss",
    "category": "Vector Stores",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-document-Document",
        "name": "document",
        "label": "document",
        "type": "Document",
        "optional": true,
        "description": "Document"
      },
      {
        "id": "{nodeId}-input-embeddings-Embeddings",
        "name": "embeddings",
        "label": "embeddings",
        "type": "Embeddings",
        "optional": true,
        "description": "Embeddings"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-basePath-string",
        "name": "basePath",
        "label": "basePath",
        "type": "string",
        "optional": true,
        "description": "Path to load faiss.index file"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Number of top results to fetch. Default to 4"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-faiss-Faiss|VectorStoreRetriever|BaseRetriever",
        "name": "faiss",
        "label": "Faiss",
        "type": "Faiss | VectorStoreRetriever | BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Upsert embedded data and perform similarity search upon query using Faiss library from Meta",
    "baseClasses": [
      "Faiss",
      "VectorStoreRetriever",
      "BaseRetriever"
    ]
  },
  {
    "node_type": "kendra",
    "name": "kendra",
    "label": "AWS Kendra",
    "category": "Vector Stores",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-document-Document",
        "name": "document",
        "label": "document",
        "type": "Document",
        "optional": true,
        "description": "Document"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-region-asyncOptions",
        "name": "region",
        "label": "region",
        "type": "asyncOptions",
        "optional": true,
        "default": "us-east-1",
        "description": "Region"
      },
      {
        "id": "{nodeId}-input-indexId-string",
        "name": "indexId",
        "label": "indexId",
        "type": "string",
        "optional": true,
        "description": "The ID of your AWS Kendra index"
      },
      {
        "id": "{nodeId}-input-fileUpload-boolean",
        "name": "fileUpload",
        "label": "fileUpload",
        "type": "boolean",
        "optional": true,
        "description": "Allow file upload on the chat"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Number of top results to fetch. Default to 10"
      },
      {
        "id": "{nodeId}-input-attributeFilter-json",
        "name": "attributeFilter",
        "label": "attributeFilter",
        "type": "json",
        "optional": true,
        "description": "Optional filter to apply when retrieving documents"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-kendra-Kendra|VectorStoreRetriever|BaseRetriever",
        "name": "kendra",
        "label": "AWS Kendra",
        "type": "Kendra | VectorStoreRetriever | BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Use AWS Kendra's intelligent search service for document retrieval and semantic search",
    "baseClasses": [
      "Kendra",
      "VectorStoreRetriever",
      "BaseRetriever"
    ],
    "credential_required": [
      "awsApi"
    ]
  },
  {
    "node_type": "meilisearch",
    "name": "meilisearch",
    "label": "Meilisearch",
    "category": "Vector Stores",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-document-Document",
        "name": "document",
        "label": "document",
        "type": "Document",
        "optional": true,
        "description": "Document"
      },
      {
        "id": "{nodeId}-input-embeddings-Embeddings",
        "name": "embeddings",
        "label": "embeddings",
        "type": "Embeddings",
        "optional": true,
        "description": "Embeddings"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-host-string",
        "name": "host",
        "label": "host",
        "type": "string",
        "optional": true,
        "description": "This is the URL for the desired Meilisearch instance, the URL must not end with a '/'"
      },
      {
        "id": "{nodeId}-input-indexUid-string",
        "name": "indexUid",
        "label": "indexUid",
        "type": "string",
        "optional": true,
        "description": "UID for the index to answer from"
      },
      {
        "id": "{nodeId}-input-deleteIndex-boolean",
        "name": "deleteIndex",
        "label": "deleteIndex",
        "type": "boolean",
        "optional": true,
        "description": "Delete Index if exists"
      },
      {
        "id": "{nodeId}-input-K-number",
        "name": "K",
        "label": "K",
        "type": "number",
        "optional": true,
        "description": "number of top searches to return as context, default is 4"
      },
      {
        "id": "{nodeId}-input-semanticRatio-number",
        "name": "semanticRatio",
        "label": "semanticRatio",
        "type": "number",
        "optional": true,
        "description": "percentage of semantic reasoning in meilisearch hybrid search, default is 0.75"
      },
      {
        "id": "{nodeId}-input-searchFilter-string",
        "name": "searchFilter",
        "label": "searchFilter",
        "type": "string",
        "optional": true,
        "description": "search filter to apply on searchable attributes"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-meilisearch-BaseRetriever",
        "name": "meilisearch",
        "label": "Meilisearch",
        "type": "BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Upsert embedded data and perform similarity search upon query using Meilisearch hybrid search functionality",
    "baseClasses": [
      "BaseRetriever"
    ],
    "credential_required": [
      "meilisearchApi"
    ]
  },
  {
    "node_type": "memoryVectorStore",
    "name": "memoryVectorStore",
    "label": "In-Memory Vector Store",
    "category": "Vector Stores",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-document-Document",
        "name": "document",
        "label": "document",
        "type": "Document",
        "optional": true,
        "description": "Document"
      },
      {
        "id": "{nodeId}-input-embeddings-Embeddings",
        "name": "embeddings",
        "label": "embeddings",
        "type": "Embeddings",
        "optional": true,
        "description": "Embeddings"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Number of top results to fetch. Default to 4"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-memoryVectorStore-Memory|VectorStoreRetriever|BaseRetriever",
        "name": "memoryVectorStore",
        "label": "In-Memory Vector Store",
        "type": "Memory | VectorStoreRetriever | BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "In-memory vectorstore that stores embeddings and does an exact, linear search for the most similar embeddings.",
    "baseClasses": [
      "Memory",
      "VectorStoreRetriever",
      "BaseRetriever"
    ]
  },
  {
    "node_type": "milvus",
    "name": "milvus",
    "label": "Milvus",
    "category": "Vector Stores",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-document-Document",
        "name": "document",
        "label": "document",
        "type": "Document",
        "optional": true,
        "description": "Document"
      },
      {
        "id": "{nodeId}-input-embeddings-Embeddings",
        "name": "embeddings",
        "label": "embeddings",
        "type": "Embeddings",
        "optional": true,
        "description": "Embeddings"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-milvusServerUrl-string",
        "name": "milvusServerUrl",
        "label": "milvusServerUrl",
        "type": "string",
        "optional": true,
        "description": "Milvus Server URL"
      },
      {
        "id": "{nodeId}-input-milvusCollection-string",
        "name": "milvusCollection",
        "label": "milvusCollection",
        "type": "string",
        "optional": true,
        "description": "Milvus Collection Name"
      },
      {
        "id": "{nodeId}-input-milvusPartition-string",
        "name": "milvusPartition",
        "label": "milvusPartition",
        "type": "string",
        "optional": true,
        "default": "_default",
        "description": "Milvus Partition Name"
      },
      {
        "id": "{nodeId}-input-fileUpload-boolean",
        "name": "fileUpload",
        "label": "fileUpload",
        "type": "boolean",
        "optional": true,
        "description": "Allow file upload on the chat"
      },
      {
        "id": "{nodeId}-input-milvusTextField-string",
        "name": "milvusTextField",
        "label": "milvusTextField",
        "type": "string",
        "optional": true,
        "description": "Milvus Text Field"
      },
      {
        "id": "{nodeId}-input-milvusFilter-string",
        "name": "milvusFilter",
        "label": "milvusFilter",
        "type": "string",
        "optional": true,
        "description": "Filter data with a simple string query. Refer Milvus <a target=\"_blank\" href=\"https://milvus.io/blog"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Number of top results to fetch. Default to 4"
      },
      {
        "id": "{nodeId}-input-secure-boolean",
        "name": "secure",
        "label": "secure",
        "type": "boolean",
        "optional": true,
        "description": "Enable secure connection to Milvus server"
      },
      {
        "id": "{nodeId}-input-clientPemPath-string",
        "name": "clientPemPath",
        "label": "clientPemPath",
        "type": "string",
        "optional": true,
        "description": "Path to the client PEM file"
      },
      {
        "id": "{nodeId}-input-clientKeyPath-string",
        "name": "clientKeyPath",
        "label": "clientKeyPath",
        "type": "string",
        "optional": true,
        "description": "Path to the client key file"
      },
      {
        "id": "{nodeId}-input-caPemPath-string",
        "name": "caPemPath",
        "label": "caPemPath",
        "type": "string",
        "optional": true,
        "description": "Path to the root PEM file"
      },
      {
        "id": "{nodeId}-input-serverName-string",
        "name": "serverName",
        "label": "serverName",
        "type": "string",
        "optional": true,
        "description": "Server name for the secure connection"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-milvus-Milvus|VectorStoreRetriever|BaseRetriever",
        "name": "milvus",
        "label": "Milvus",
        "type": "Milvus | VectorStoreRetriever | BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2.1",
    "description": "Upsert embedded data and perform similarity search upon query using Milvus, world's most advanced open-source vector database",
    "baseClasses": [
      "Milvus",
      "VectorStoreRetriever",
      "BaseRetriever"
    ],
    "credential_required": [
      "milvusAuth"
    ]
  },
  {
    "node_type": "mongoDBAtlas",
    "name": "mongoDBAtlas",
    "label": "MongoDB Atlas",
    "category": "Vector Stores",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-document-Document",
        "name": "document",
        "label": "document",
        "type": "Document",
        "optional": true,
        "description": "Document"
      },
      {
        "id": "{nodeId}-input-embeddings-Embeddings",
        "name": "embeddings",
        "label": "embeddings",
        "type": "Embeddings",
        "optional": true,
        "description": "Embeddings"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-databaseName-string",
        "name": "databaseName",
        "label": "databaseName",
        "type": "string",
        "optional": true,
        "description": "Database"
      },
      {
        "id": "{nodeId}-input-collectionName-string",
        "name": "collectionName",
        "label": "collectionName",
        "type": "string",
        "optional": true,
        "description": "Collection Name"
      },
      {
        "id": "{nodeId}-input-indexName-string",
        "name": "indexName",
        "label": "indexName",
        "type": "string",
        "optional": true,
        "description": "Index Name"
      },
      {
        "id": "{nodeId}-input-textKey-string",
        "name": "textKey",
        "label": "textKey",
        "type": "string",
        "optional": true,
        "default": "text",
        "description": "Name of the field (column) that contains the actual content"
      },
      {
        "id": "{nodeId}-input-embeddingKey-string",
        "name": "embeddingKey",
        "label": "embeddingKey",
        "type": "string",
        "optional": true,
        "default": "embedding",
        "description": "Name of the field (column) that contains the Embedding"
      },
      {
        "id": "{nodeId}-input-mongoMetadataFilter-json",
        "name": "mongoMetadataFilter",
        "label": "mongoMetadataFilter",
        "type": "json",
        "optional": true,
        "description": "Mongodb Metadata Filter"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Number of top results to fetch. Default to 4"
      },
      {
        "id": "{nodeId}-input-searchType-options",
        "name": "searchType",
        "label": "searchType",
        "type": "options",
        "optional": true,
        "default": "similarity",
        "description": "Search Type"
      },
      {
        "id": "{nodeId}-input-fetchK-number",
        "name": "fetchK",
        "label": "fetchK",
        "type": "number",
        "optional": true,
        "description": "Number of initial documents to fetch for MMR reranking. Default to 20. Used only when the search typ"
      },
      {
        "id": "{nodeId}-input-lambda-number",
        "name": "lambda",
        "label": "lambda",
        "type": "number",
        "optional": true,
        "description": "Number between 0 and 1 that determines the degree of diversity among the results, where 0 correspond"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-mongoDBAtlas-MongoDB Atlas|VectorStoreRetriever|BaseRetriever",
        "name": "mongoDBAtlas",
        "label": "MongoDB Atlas",
        "type": "MongoDB Atlas | VectorStoreRetriever | BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Upsert embedded data and perform similarity or mmr search upon query using MongoDB Atlas, a managed cloud mongodb database",
    "baseClasses": [
      "MongoDB Atlas",
      "VectorStoreRetriever",
      "BaseRetriever"
    ],
    "credential_required": [
      "mongoDBUrlApi"
    ]
  },
  {
    "node_type": "openSearch",
    "name": "openSearch",
    "label": "OpenSearch",
    "category": "Vector Stores",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-document-Document",
        "name": "document",
        "label": "document",
        "type": "Document",
        "optional": true,
        "description": "Document"
      },
      {
        "id": "{nodeId}-input-embeddings-Embeddings",
        "name": "embeddings",
        "label": "embeddings",
        "type": "Embeddings",
        "optional": true,
        "description": "Embeddings"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-indexName-string",
        "name": "indexName",
        "label": "indexName",
        "type": "string",
        "optional": true,
        "description": "Index Name"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Number of top results to fetch. Default to 4"
      },
      {
        "id": "{nodeId}-input-engine-options",
        "name": "engine",
        "label": "engine",
        "type": "options",
        "optional": true,
        "default": "lucene",
        "description": "Vector search engine. Use \"lucene\" or \"faiss\" for OpenSearch 3.x+, \"nmslib\" for older versions"
      },
      {
        "id": "{nodeId}-input-spaceType-options",
        "name": "spaceType",
        "label": "spaceType",
        "type": "options",
        "optional": true,
        "default": "l2",
        "description": "Distance metric for similarity search"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-openSearch-OpenSearch|VectorStoreRetriever|BaseRetriever",
        "name": "openSearch",
        "label": "OpenSearch",
        "type": "OpenSearch | VectorStoreRetriever | BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "4",
    "description": "Upsert embedded data and perform similarity search upon query using OpenSearch, an open-source, all-in-one vector database",
    "baseClasses": [
      "OpenSearch",
      "VectorStoreRetriever",
      "BaseRetriever"
    ],
    "credential_required": [
      "openSearchUrl"
    ]
  },
  {
    "node_type": "pinecone",
    "name": "pinecone",
    "label": "Pinecone",
    "category": "Vector Stores",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-document-Document",
        "name": "document",
        "label": "document",
        "type": "Document",
        "optional": true,
        "description": "Document"
      },
      {
        "id": "{nodeId}-input-embeddings-Embeddings",
        "name": "embeddings",
        "label": "embeddings",
        "type": "Embeddings",
        "optional": true,
        "description": "Embeddings"
      },
      {
        "id": "{nodeId}-input-recordManager-RecordManager",
        "name": "recordManager",
        "label": "recordManager",
        "type": "RecordManager",
        "optional": true,
        "description": "Keep track of the record to prevent duplication"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-pineconeIndex-string",
        "name": "pineconeIndex",
        "label": "pineconeIndex",
        "type": "string",
        "optional": true,
        "description": "Pinecone Index"
      },
      {
        "id": "{nodeId}-input-pineconeNamespace-string",
        "name": "pineconeNamespace",
        "label": "pineconeNamespace",
        "type": "string",
        "optional": true,
        "description": "Pinecone Namespace"
      },
      {
        "id": "{nodeId}-input-fileUpload-boolean",
        "name": "fileUpload",
        "label": "fileUpload",
        "type": "boolean",
        "optional": true,
        "description": "Allow file upload on the chat"
      },
      {
        "id": "{nodeId}-input-pineconeTextKey-string",
        "name": "pineconeTextKey",
        "label": "pineconeTextKey",
        "type": "string",
        "optional": true,
        "description": "The key in the metadata for storing text. Default to `text`"
      },
      {
        "id": "{nodeId}-input-pineconeMetadataFilter-json",
        "name": "pineconeMetadataFilter",
        "label": "pineconeMetadataFilter",
        "type": "json",
        "optional": true,
        "description": "Pinecone Metadata Filter"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Number of top results to fetch. Default to 4"
      },
      {
        "id": "{nodeId}-input-searchType-options",
        "name": "searchType",
        "label": "searchType",
        "type": "options",
        "optional": true,
        "default": "similarity",
        "description": "Search Type"
      },
      {
        "id": "{nodeId}-input-fetchK-number",
        "name": "fetchK",
        "label": "fetchK",
        "type": "number",
        "optional": true,
        "description": "Number of initial documents to fetch for MMR reranking. Default to 20. Used only when the search typ"
      },
      {
        "id": "{nodeId}-input-lambda-number",
        "name": "lambda",
        "label": "lambda",
        "type": "number",
        "optional": true,
        "description": "Number between 0 and 1 that determines the degree of diversity among the results, where 0 correspond"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-pinecone-Pinecone|VectorStoreRetriever|BaseRetriever",
        "name": "pinecone",
        "label": "Pinecone",
        "type": "Pinecone | VectorStoreRetriever | BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "5",
    "description": "Upsert embedded data and perform similarity or mmr search using Pinecone, a leading fully managed hosted vector database",
    "baseClasses": [
      "Pinecone",
      "VectorStoreRetriever",
      "BaseRetriever"
    ],
    "credential_required": [
      "pineconeApi"
    ]
  },
  {
    "node_type": "pineconeLlamaIndex",
    "name": "pineconeLlamaIndex",
    "label": "Pinecone",
    "category": "Vector Stores",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-document-Document",
        "name": "document",
        "label": "document",
        "type": "Document",
        "optional": true,
        "description": "Document"
      },
      {
        "id": "{nodeId}-input-model-BaseChatModel_LlamaIndex",
        "name": "model",
        "label": "model",
        "type": "BaseChatModel_LlamaIndex",
        "optional": true,
        "description": "Chat Model"
      },
      {
        "id": "{nodeId}-input-embeddings-BaseEmbedding_LlamaIndex",
        "name": "embeddings",
        "label": "embeddings",
        "type": "BaseEmbedding_LlamaIndex",
        "optional": true,
        "description": "Embeddings"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-pineconeIndex-string",
        "name": "pineconeIndex",
        "label": "pineconeIndex",
        "type": "string",
        "optional": true,
        "description": "Pinecone Index"
      },
      {
        "id": "{nodeId}-input-pineconeNamespace-string",
        "name": "pineconeNamespace",
        "label": "pineconeNamespace",
        "type": "string",
        "optional": true,
        "description": "Pinecone Namespace"
      },
      {
        "id": "{nodeId}-input-pineconeMetadataFilter-json",
        "name": "pineconeMetadataFilter",
        "label": "pineconeMetadataFilter",
        "type": "json",
        "optional": true,
        "description": "Pinecone Metadata Filter"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Number of top results to fetch. Default to 4"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-pineconeLlamaIndex-Pinecone|VectorIndexRetriever",
        "name": "pineconeLlamaIndex",
        "label": "Pinecone",
        "type": "Pinecone | VectorIndexRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Upsert embedded data and perform similarity search upon query using Pinecone, a leading fully managed hosted vector database",
    "baseClasses": [
      "Pinecone",
      "VectorIndexRetriever"
    ],
    "credential_required": [
      "pineconeApi"
    ]
  },
  {
    "node_type": "postgres",
    "name": "postgres",
    "label": "Postgres",
    "category": "Vector Stores",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-document-Document",
        "name": "document",
        "label": "document",
        "type": "Document",
        "optional": true,
        "description": "Document"
      },
      {
        "id": "{nodeId}-input-embeddings-Embeddings",
        "name": "embeddings",
        "label": "embeddings",
        "type": "Embeddings",
        "optional": true,
        "description": "Embeddings"
      },
      {
        "id": "{nodeId}-input-recordManager-RecordManager",
        "name": "recordManager",
        "label": "recordManager",
        "type": "RecordManager",
        "optional": true,
        "description": "Keep track of the record to prevent duplication"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-host-string",
        "name": "host",
        "label": "host",
        "type": "string",
        "optional": false,
        "description": "Host"
      },
      {
        "id": "{nodeId}-input-database-string",
        "name": "database",
        "label": "database",
        "type": "string",
        "optional": false,
        "description": "Database"
      },
      {
        "id": "{nodeId}-input-port-number",
        "name": "port",
        "label": "port",
        "type": "number",
        "optional": true,
        "description": "Port"
      },
      {
        "id": "{nodeId}-input-ssl-boolean",
        "name": "ssl",
        "label": "ssl",
        "type": "boolean",
        "optional": true,
        "description": "Use SSL to connect to Postgres"
      },
      {
        "id": "{nodeId}-input-tableName-string",
        "name": "tableName",
        "label": "tableName",
        "type": "string",
        "optional": true,
        "description": "Table Name"
      },
      {
        "id": "{nodeId}-input-distanceStrategy-options",
        "name": "distanceStrategy",
        "label": "distanceStrategy",
        "type": "options",
        "optional": true,
        "default": "cosine",
        "description": "Strategy for calculating distances between vectors"
      },
      {
        "id": "{nodeId}-input-fileUpload-boolean",
        "name": "fileUpload",
        "label": "fileUpload",
        "type": "boolean",
        "optional": true,
        "description": "Allow file upload on the chat"
      },
      {
        "id": "{nodeId}-input-batchSize-number",
        "name": "batchSize",
        "label": "batchSize",
        "type": "number",
        "optional": true,
        "description": "Upsert in batches of size N"
      },
      {
        "id": "{nodeId}-input-additionalConfig-json",
        "name": "additionalConfig",
        "label": "additionalConfig",
        "type": "json",
        "optional": true,
        "description": "Additional Configuration"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Number of top results to fetch. Default to 4"
      },
      {
        "id": "{nodeId}-input-pgMetadataFilter-json",
        "name": "pgMetadataFilter",
        "label": "pgMetadataFilter",
        "type": "json",
        "optional": true,
        "description": "Postgres Metadata Filter"
      },
      {
        "id": "{nodeId}-input-contentColumnName-string",
        "name": "contentColumnName",
        "label": "contentColumnName",
        "type": "string",
        "optional": true,
        "description": "Column name to store the text content (PGVector Driver only, others use pageContent)"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-postgres-Postgres|VectorStoreRetriever|BaseRetriever",
        "name": "postgres",
        "label": "Postgres",
        "type": "Postgres | VectorStoreRetriever | BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "7.1",
    "description": "Upsert embedded data and perform similarity search upon query using pgvector on Postgres",
    "baseClasses": [
      "Postgres",
      "VectorStoreRetriever",
      "BaseRetriever"
    ],
    "credential_required": [
      "PostgresApi"
    ]
  },
  {
    "node_type": "qdrant",
    "name": "qdrant",
    "label": "Qdrant",
    "category": "Vector Stores",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-document-Document",
        "name": "document",
        "label": "document",
        "type": "Document",
        "optional": true,
        "description": "Document"
      },
      {
        "id": "{nodeId}-input-embeddings-Embeddings",
        "name": "embeddings",
        "label": "embeddings",
        "type": "Embeddings",
        "optional": true,
        "description": "Embeddings"
      },
      {
        "id": "{nodeId}-input-recordManager-RecordManager",
        "name": "recordManager",
        "label": "recordManager",
        "type": "RecordManager",
        "optional": true,
        "description": "Keep track of the record to prevent duplication"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-qdrantServerUrl-string",
        "name": "qdrantServerUrl",
        "label": "qdrantServerUrl",
        "type": "string",
        "optional": true,
        "description": "Qdrant Server URL"
      },
      {
        "id": "{nodeId}-input-qdrantCollection-string",
        "name": "qdrantCollection",
        "label": "qdrantCollection",
        "type": "string",
        "optional": true,
        "description": "Qdrant Collection Name"
      },
      {
        "id": "{nodeId}-input-fileUpload-boolean",
        "name": "fileUpload",
        "label": "fileUpload",
        "type": "boolean",
        "optional": true,
        "description": "Allow file upload on the chat"
      },
      {
        "id": "{nodeId}-input-qdrantVectorDimension-number",
        "name": "qdrantVectorDimension",
        "label": "qdrantVectorDimension",
        "type": "number",
        "optional": true,
        "default": "1536",
        "description": "Vector Dimension"
      },
      {
        "id": "{nodeId}-input-contentPayloadKey-string",
        "name": "contentPayloadKey",
        "label": "contentPayloadKey",
        "type": "string",
        "optional": true,
        "default": "content",
        "description": "The key for storing text. Default to `content`"
      },
      {
        "id": "{nodeId}-input-metadataPayloadKey-string",
        "name": "metadataPayloadKey",
        "label": "metadataPayloadKey",
        "type": "string",
        "optional": true,
        "default": "metadata",
        "description": "The key for storing metadata. Default to `metadata`"
      },
      {
        "id": "{nodeId}-input-batchSize-number",
        "name": "batchSize",
        "label": "batchSize",
        "type": "number",
        "optional": true,
        "description": "Upsert in batches of size N"
      },
      {
        "id": "{nodeId}-input-qdrantSimilarity-options",
        "name": "qdrantSimilarity",
        "label": "qdrantSimilarity",
        "type": "options",
        "optional": true,
        "default": "Cosine",
        "description": "Similarity measure used in Qdrant."
      },
      {
        "id": "{nodeId}-input-qdrantCollectionConfiguration-json",
        "name": "qdrantCollectionConfiguration",
        "label": "qdrantCollectionConfiguration",
        "type": "json",
        "optional": true,
        "description": "Refer to collection"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Number of top results to fetch. Default to 4"
      },
      {
        "id": "{nodeId}-input-qdrantFilter-json",
        "name": "qdrantFilter",
        "label": "qdrantFilter",
        "type": "json",
        "optional": true,
        "description": "Only return points which satisfy the conditions"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-qdrant-Qdrant|VectorStoreRetriever|BaseRetriever",
        "name": "qdrant",
        "label": "Qdrant",
        "type": "Qdrant | VectorStoreRetriever | BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "5",
    "description": "Upsert embedded data and perform similarity search upon query using Qdrant, a scalable open source vector database written in Rust",
    "baseClasses": [
      "Qdrant",
      "VectorStoreRetriever",
      "BaseRetriever"
    ],
    "credential_required": [
      "qdrantApi"
    ]
  },
  {
    "node_type": "redis",
    "name": "redis",
    "label": "Redis",
    "category": "Vector Stores",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-document-Document",
        "name": "document",
        "label": "document",
        "type": "Document",
        "optional": true,
        "description": "Document"
      },
      {
        "id": "{nodeId}-input-embeddings-Embeddings",
        "name": "embeddings",
        "label": "embeddings",
        "type": "Embeddings",
        "optional": true,
        "description": "Embeddings"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-indexName-string",
        "name": "indexName",
        "label": "indexName",
        "type": "string",
        "optional": true,
        "description": "Index Name"
      },
      {
        "id": "{nodeId}-input-replaceIndex-boolean",
        "name": "replaceIndex",
        "label": "replaceIndex",
        "type": "boolean",
        "optional": true,
        "default": "False",
        "description": "Selecting this option will delete the existing index and recreate a new one when upserting"
      },
      {
        "id": "{nodeId}-input-contentKey-string",
        "name": "contentKey",
        "label": "contentKey",
        "type": "string",
        "optional": true,
        "default": "content",
        "description": "Name of the field (column) that contains the actual content"
      },
      {
        "id": "{nodeId}-input-metadataKey-string",
        "name": "metadataKey",
        "label": "metadataKey",
        "type": "string",
        "optional": true,
        "default": "metadata",
        "description": "Name of the field (column) that contains the metadata of the document"
      },
      {
        "id": "{nodeId}-input-vectorKey-string",
        "name": "vectorKey",
        "label": "vectorKey",
        "type": "string",
        "optional": true,
        "default": "content_vector",
        "description": "Name of the field (column) that contains the vector"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Number of top results to fetch. Default to 4"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-redis-Redis|VectorStoreRetriever|BaseRetriever",
        "name": "redis",
        "label": "Redis",
        "type": "Redis | VectorStoreRetriever | BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Upsert embedded data and perform similarity search upon query using Redis, an open source, in-memory data structure store",
    "baseClasses": [
      "Redis",
      "VectorStoreRetriever",
      "BaseRetriever"
    ],
    "credential_required": [
      "redisCacheUrlApi",
      "redisCacheApi"
    ]
  },
  {
    "node_type": "simpleStoreLlamaIndex",
    "name": "simpleStoreLlamaIndex",
    "label": "SimpleStore",
    "category": "Vector Stores",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-document-Document",
        "name": "document",
        "label": "document",
        "type": "Document",
        "optional": true,
        "description": "Document"
      },
      {
        "id": "{nodeId}-input-model-BaseChatModel_LlamaIndex",
        "name": "model",
        "label": "model",
        "type": "BaseChatModel_LlamaIndex",
        "optional": true,
        "description": "Chat Model"
      },
      {
        "id": "{nodeId}-input-embeddings-BaseEmbedding_LlamaIndex",
        "name": "embeddings",
        "label": "embeddings",
        "type": "BaseEmbedding_LlamaIndex",
        "optional": true,
        "description": "Embeddings"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-basePath-string",
        "name": "basePath",
        "label": "basePath",
        "type": "string",
        "optional": true,
        "description": "Path to store persist embeddings indexes with persistence. If not specified, default to same path wh"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Number of top results to fetch. Default to 4"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-simpleStoreLlamaIndex-SimpleVectorStore|VectorIndexRetriever",
        "name": "simpleStoreLlamaIndex",
        "label": "SimpleStore",
        "type": "SimpleVectorStore | VectorIndexRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Upsert embedded data to local path and perform similarity search",
    "baseClasses": [
      "SimpleVectorStore",
      "VectorIndexRetriever"
    ]
  },
  {
    "node_type": "singlestore",
    "name": "singlestore",
    "label": "SingleStore",
    "category": "Vector Stores",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-document-Document",
        "name": "document",
        "label": "document",
        "type": "Document",
        "optional": true,
        "description": "Document"
      },
      {
        "id": "{nodeId}-input-embeddings-Embeddings",
        "name": "embeddings",
        "label": "embeddings",
        "type": "Embeddings",
        "optional": true,
        "description": "Embeddings"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-host-string",
        "name": "host",
        "label": "host",
        "type": "string",
        "optional": true,
        "description": "Host"
      },
      {
        "id": "{nodeId}-input-database-string",
        "name": "database",
        "label": "database",
        "type": "string",
        "optional": true,
        "description": "Database"
      },
      {
        "id": "{nodeId}-input-tableName-string",
        "name": "tableName",
        "label": "tableName",
        "type": "string",
        "optional": true,
        "description": "Table Name"
      },
      {
        "id": "{nodeId}-input-contentColumnName-string",
        "name": "contentColumnName",
        "label": "contentColumnName",
        "type": "string",
        "optional": true,
        "description": "Content Column Name"
      },
      {
        "id": "{nodeId}-input-vectorColumnName-string",
        "name": "vectorColumnName",
        "label": "vectorColumnName",
        "type": "string",
        "optional": true,
        "description": "Vector Column Name"
      },
      {
        "id": "{nodeId}-input-metadataColumnName-string",
        "name": "metadataColumnName",
        "label": "metadataColumnName",
        "type": "string",
        "optional": true,
        "description": "Metadata Column Name"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Top K"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-singlestore-SingleStore|VectorStoreRetriever|BaseRetriever",
        "name": "singlestore",
        "label": "SingleStore",
        "type": "SingleStore | VectorStoreRetriever | BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Upsert embedded data and perform similarity search upon query using SingleStore, a fast and distributed cloud relational database",
    "baseClasses": [
      "SingleStore",
      "VectorStoreRetriever",
      "BaseRetriever"
    ],
    "credential_required": [
      "singleStoreApi"
    ]
  },
  {
    "node_type": "supabase",
    "name": "supabase",
    "label": "Supabase",
    "category": "Vector Stores",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-document-Document",
        "name": "document",
        "label": "document",
        "type": "Document",
        "optional": true,
        "description": "Document"
      },
      {
        "id": "{nodeId}-input-embeddings-Embeddings",
        "name": "embeddings",
        "label": "embeddings",
        "type": "Embeddings",
        "optional": true,
        "description": "Embeddings"
      },
      {
        "id": "{nodeId}-input-recordManager-RecordManager",
        "name": "recordManager",
        "label": "recordManager",
        "type": "RecordManager",
        "optional": true,
        "description": "Keep track of the record to prevent duplication"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-supabaseProjUrl-string",
        "name": "supabaseProjUrl",
        "label": "supabaseProjUrl",
        "type": "string",
        "optional": true,
        "description": "Supabase Project URL"
      },
      {
        "id": "{nodeId}-input-tableName-string",
        "name": "tableName",
        "label": "tableName",
        "type": "string",
        "optional": true,
        "description": "Table Name"
      },
      {
        "id": "{nodeId}-input-queryName-string",
        "name": "queryName",
        "label": "queryName",
        "type": "string",
        "optional": true,
        "description": "Query Name"
      },
      {
        "id": "{nodeId}-input-supabaseMetadataFilter-json",
        "name": "supabaseMetadataFilter",
        "label": "supabaseMetadataFilter",
        "type": "json",
        "optional": true,
        "description": "Supabase Metadata Filter"
      },
      {
        "id": "{nodeId}-input-supabaseRPCFilter-string",
        "name": "supabaseRPCFilter",
        "label": "supabaseRPCFilter",
        "type": "string",
        "optional": true,
        "description": "Query builder-style filtering. If this is set, will override the metadata filter. Refer <a href=\"htt"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Number of top results to fetch. Default to 4"
      },
      {
        "id": "{nodeId}-input-searchType-options",
        "name": "searchType",
        "label": "searchType",
        "type": "options",
        "optional": true,
        "default": "similarity",
        "description": "Search Type"
      },
      {
        "id": "{nodeId}-input-fetchK-number",
        "name": "fetchK",
        "label": "fetchK",
        "type": "number",
        "optional": true,
        "description": "Number of initial documents to fetch for MMR reranking. Default to 20. Used only when the search typ"
      },
      {
        "id": "{nodeId}-input-lambda-number",
        "name": "lambda",
        "label": "lambda",
        "type": "number",
        "optional": true,
        "description": "Number between 0 and 1 that determines the degree of diversity among the results, where 0 correspond"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-supabase-Supabase|VectorStoreRetriever|BaseRetriever",
        "name": "supabase",
        "label": "Supabase",
        "type": "Supabase | VectorStoreRetriever | BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "4",
    "description": "Upsert embedded data and perform similarity or mmr search upon query using Supabase via pgvector extension",
    "baseClasses": [
      "Supabase",
      "VectorStoreRetriever",
      "BaseRetriever"
    ],
    "credential_required": [
      "supabaseApi"
    ]
  },
  {
    "node_type": "upstash",
    "name": "upstash",
    "label": "Upstash Vector",
    "category": "Vector Stores",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-document-Document",
        "name": "document",
        "label": "document",
        "type": "Document",
        "optional": true,
        "description": "Document"
      },
      {
        "id": "{nodeId}-input-embeddings-Embeddings",
        "name": "embeddings",
        "label": "embeddings",
        "type": "Embeddings",
        "optional": true,
        "description": "Embeddings"
      },
      {
        "id": "{nodeId}-input-recordManager-RecordManager",
        "name": "recordManager",
        "label": "recordManager",
        "type": "RecordManager",
        "optional": true,
        "description": "Keep track of the record to prevent duplication"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-fileUpload-boolean",
        "name": "fileUpload",
        "label": "fileUpload",
        "type": "boolean",
        "optional": true,
        "description": "Allow file upload on the chat"
      },
      {
        "id": "{nodeId}-input-upstashMetadataFilter-string",
        "name": "upstashMetadataFilter",
        "label": "upstashMetadataFilter",
        "type": "string",
        "optional": true,
        "description": "Upstash Metadata Filter"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Number of top results to fetch. Default to 4"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-upstash-Upstash|VectorStoreRetriever|BaseRetriever",
        "name": "upstash",
        "label": "Upstash Vector",
        "type": "Upstash | VectorStoreRetriever | BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Upsert data as embedding or string and perform similarity search with Upstash, the leading serverless data platform",
    "baseClasses": [
      "Upstash",
      "VectorStoreRetriever",
      "BaseRetriever"
    ],
    "credential_required": [
      "upstashVectorApi"
    ]
  },
  {
    "node_type": "vectara",
    "name": "vectara",
    "label": "Vectara",
    "category": "Vector Stores",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-document-Document",
        "name": "document",
        "label": "document",
        "type": "Document",
        "optional": true,
        "description": "Document"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-file-file",
        "name": "file",
        "label": "file",
        "type": "file",
        "optional": true,
        "description": "File to upload to Vectara. Supported file types: https://docs.vectara.com/docs/api-reference/indexin"
      },
      {
        "id": "{nodeId}-input-filter-string",
        "name": "filter",
        "label": "filter",
        "type": "string",
        "optional": true,
        "description": "Filter to apply to Vectara metadata. Refer to the <a target=\"_blank\" href=\"https://docs.flowiseai.co"
      },
      {
        "id": "{nodeId}-input-sentencesBefore-number",
        "name": "sentencesBefore",
        "label": "sentencesBefore",
        "type": "number",
        "optional": true,
        "default": "2",
        "description": "Number of sentences to fetch before the matched sentence. Defaults to 2."
      },
      {
        "id": "{nodeId}-input-sentencesAfter-number",
        "name": "sentencesAfter",
        "label": "sentencesAfter",
        "type": "number",
        "optional": true,
        "default": "2",
        "description": "Number of sentences to fetch after the matched sentence. Defaults to 2."
      },
      {
        "id": "{nodeId}-input-lambda-number",
        "name": "lambda",
        "label": "lambda",
        "type": "number",
        "optional": true,
        "default": "0",
        "description": "Enable hybrid search to improve retrieval accuracy by adjusting the balance (from 0 to 1) between ne"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Number of top results to fetch. Defaults to 5"
      },
      {
        "id": "{nodeId}-input-mmrK-number",
        "name": "mmrK",
        "label": "mmrK",
        "type": "number",
        "optional": true,
        "description": "Number of top results to fetch for MMR. Defaults to 50"
      },
      {
        "id": "{nodeId}-input-mmrDiversityBias-number",
        "name": "mmrDiversityBias",
        "label": "mmrDiversityBias",
        "type": "number",
        "optional": true,
        "description": "The diversity bias to use for MMR. This is a value between 0.0 and 1.0Values closer to 1.0 optimize"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-vectara-Vectara|VectorStoreRetriever|BaseRetriever",
        "name": "vectara",
        "label": "Vectara",
        "type": "Vectara | VectorStoreRetriever | BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Upsert embedded data and perform similarity search upon query using Vectara, a LLM-powered search-as-a-service",
    "baseClasses": [
      "Vectara",
      "VectorStoreRetriever",
      "BaseRetriever"
    ],
    "credential_required": [
      "vectaraApi"
    ]
  },
  {
    "node_type": "vectaraUpload",
    "name": "vectaraUpload",
    "label": "Vectara Upload File",
    "category": "Vector Stores",
    "inputAnchors": [],
    "inputParams": [
      {
        "id": "{nodeId}-input-file-file",
        "name": "file",
        "label": "file",
        "type": "file",
        "optional": true,
        "description": "File to upload to Vectara. Supported file types: https://docs.vectara.com/docs/api-reference/indexin"
      },
      {
        "id": "{nodeId}-input-filter-string",
        "name": "filter",
        "label": "filter",
        "type": "string",
        "optional": true,
        "description": "Filter to apply to Vectara metadata. Refer to the <a target=\"_blank\" href=\"https://docs.flowiseai.co"
      },
      {
        "id": "{nodeId}-input-sentencesBefore-number",
        "name": "sentencesBefore",
        "label": "sentencesBefore",
        "type": "number",
        "optional": true,
        "description": "Number of sentences to fetch before the matched sentence. Defaults to 2."
      },
      {
        "id": "{nodeId}-input-sentencesAfter-number",
        "name": "sentencesAfter",
        "label": "sentencesAfter",
        "type": "number",
        "optional": true,
        "description": "Number of sentences to fetch after the matched sentence. Defaults to 2."
      },
      {
        "id": "{nodeId}-input-lambda-number",
        "name": "lambda",
        "label": "lambda",
        "type": "number",
        "optional": true,
        "description": "Improves retrieval accuracy by adjusting the balance (from 0 to 1) between neural search and keyword"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Number of top results to fetch. Defaults to 4"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-vectaraUpload-Vectara|VectorStoreRetriever|BaseRetriever",
        "name": "vectaraUpload",
        "label": "Vectara Upload File",
        "type": "Vectara | VectorStoreRetriever | BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "1",
    "description": "Upload files to Vectara",
    "baseClasses": [
      "Vectara",
      "VectorStoreRetriever",
      "BaseRetriever"
    ],
    "credential_required": [
      "vectaraApi"
    ]
  },
  {
    "node_type": "weaviate",
    "name": "weaviate",
    "label": "Weaviate",
    "category": "Vector Stores",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-document-Document",
        "name": "document",
        "label": "document",
        "type": "Document",
        "optional": true,
        "description": "Document"
      },
      {
        "id": "{nodeId}-input-embeddings-Embeddings",
        "name": "embeddings",
        "label": "embeddings",
        "type": "Embeddings",
        "optional": true,
        "description": "Embeddings"
      },
      {
        "id": "{nodeId}-input-recordManager-RecordManager",
        "name": "recordManager",
        "label": "recordManager",
        "type": "RecordManager",
        "optional": true,
        "description": "Keep track of the record to prevent duplication"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-weaviateScheme-options",
        "name": "weaviateScheme",
        "label": "weaviateScheme",
        "type": "options",
        "optional": true,
        "default": "https",
        "description": "Weaviate Scheme"
      },
      {
        "id": "{nodeId}-input-weaviateHost-string",
        "name": "weaviateHost",
        "label": "weaviateHost",
        "type": "string",
        "optional": true,
        "description": "Weaviate Host"
      },
      {
        "id": "{nodeId}-input-weaviateIndex-string",
        "name": "weaviateIndex",
        "label": "weaviateIndex",
        "type": "string",
        "optional": true,
        "description": "Weaviate Index"
      },
      {
        "id": "{nodeId}-input-weaviateTextKey-string",
        "name": "weaviateTextKey",
        "label": "weaviateTextKey",
        "type": "string",
        "optional": true,
        "description": "Weaviate Text Key"
      },
      {
        "id": "{nodeId}-input-weaviateMetadataKeys-string",
        "name": "weaviateMetadataKeys",
        "label": "weaviateMetadataKeys",
        "type": "string",
        "optional": true,
        "description": "Weaviate Metadata Keys"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Number of top results to fetch. Default to 4"
      },
      {
        "id": "{nodeId}-input-weaviateFilter-json",
        "name": "weaviateFilter",
        "label": "weaviateFilter",
        "type": "json",
        "optional": true,
        "description": "Weaviate Search Filter"
      },
      {
        "id": "{nodeId}-input-searchType-options",
        "name": "searchType",
        "label": "searchType",
        "type": "options",
        "optional": true,
        "default": "similarity",
        "description": "Search Type"
      },
      {
        "id": "{nodeId}-input-fetchK-number",
        "name": "fetchK",
        "label": "fetchK",
        "type": "number",
        "optional": true,
        "description": "Number of initial documents to fetch for MMR reranking. Default to 20. Used only when the search typ"
      },
      {
        "id": "{nodeId}-input-lambda-number",
        "name": "lambda",
        "label": "lambda",
        "type": "number",
        "optional": true,
        "description": "Number between 0 and 1 that determines the degree of diversity among the results, where 0 correspond"
      },
      {
        "id": "{nodeId}-input-alpha-number",
        "name": "alpha",
        "label": "alpha",
        "type": "number",
        "optional": true,
        "description": "Number between 0 and 1 that determines the weighting of keyword (BM25) portion of the hybrid search."
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-weaviate-Weaviate|VectorStoreRetriever|BaseRetriever",
        "name": "weaviate",
        "label": "Weaviate",
        "type": "Weaviate | VectorStoreRetriever | BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "4",
    "description": "Upsert embedded data and perform similarity or mmr search using Weaviate, a scalable open-source vector database",
    "baseClasses": [
      "Weaviate",
      "VectorStoreRetriever",
      "BaseRetriever"
    ],
    "credential_required": [
      "weaviateApi"
    ]
  },
  {
    "node_type": "zep",
    "name": "zep",
    "label": "Zep Collection - Open Source",
    "category": "Vector Stores",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-document-Document",
        "name": "document",
        "label": "document",
        "type": "Document",
        "optional": true,
        "description": "Document"
      },
      {
        "id": "{nodeId}-input-embeddings-Embeddings",
        "name": "embeddings",
        "label": "embeddings",
        "type": "Embeddings",
        "optional": true,
        "description": "Embeddings"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-baseURL-string",
        "name": "baseURL",
        "label": "baseURL",
        "type": "string",
        "optional": true,
        "default": "http://127.0.0.1:8000",
        "description": "Base URL"
      },
      {
        "id": "{nodeId}-input-zepCollection-string",
        "name": "zepCollection",
        "label": "zepCollection",
        "type": "string",
        "optional": true,
        "description": "Zep Collection"
      },
      {
        "id": "{nodeId}-input-zepMetadataFilter-json",
        "name": "zepMetadataFilter",
        "label": "zepMetadataFilter",
        "type": "json",
        "optional": true,
        "description": "Zep Metadata Filter"
      },
      {
        "id": "{nodeId}-input-dimension-number",
        "name": "dimension",
        "label": "dimension",
        "type": "number",
        "optional": true,
        "default": "1536",
        "description": "Embedding Dimension"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Number of top results to fetch. Default to 4"
      },
      {
        "id": "{nodeId}-input-searchType-options",
        "name": "searchType",
        "label": "searchType",
        "type": "options",
        "optional": true,
        "default": "similarity",
        "description": "Search Type"
      },
      {
        "id": "{nodeId}-input-fetchK-number",
        "name": "fetchK",
        "label": "fetchK",
        "type": "number",
        "optional": true,
        "description": "Number of initial documents to fetch for MMR reranking. Default to 20. Used only when the search typ"
      },
      {
        "id": "{nodeId}-input-lambda-number",
        "name": "lambda",
        "label": "lambda",
        "type": "number",
        "optional": true,
        "description": "Number between 0 and 1 that determines the degree of diversity among the results, where 0 correspond"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-zep-Zep|VectorStoreRetriever|BaseRetriever",
        "name": "zep",
        "label": "Zep Collection - Open Source",
        "type": "Zep | VectorStoreRetriever | BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Upsert embedded data and perform similarity or mmr search upon query using Zep, a fast and scalable building block for LLM apps",
    "baseClasses": [
      "Zep",
      "VectorStoreRetriever",
      "BaseRetriever"
    ],
    "credential_required": [
      "zepMemoryApi"
    ]
  },
  {
    "node_type": "zepCloud",
    "name": "zepCloud",
    "label": "Zep Collection - Cloud",
    "category": "Vector Stores",
    "inputAnchors": [
      {
        "id": "{nodeId}-input-document-Document",
        "name": "document",
        "label": "document",
        "type": "Document",
        "optional": true,
        "description": "Document"
      }
    ],
    "inputParams": [
      {
        "id": "{nodeId}-input-zepCollection-string",
        "name": "zepCollection",
        "label": "zepCollection",
        "type": "string",
        "optional": true,
        "description": "Zep Collection"
      },
      {
        "id": "{nodeId}-input-zepMetadataFilter-json",
        "name": "zepMetadataFilter",
        "label": "zepMetadataFilter",
        "type": "json",
        "optional": true,
        "description": "Zep Metadata Filter"
      },
      {
        "id": "{nodeId}-input-topK-number",
        "name": "topK",
        "label": "topK",
        "type": "number",
        "optional": true,
        "description": "Number of top results to fetch. Default to 4"
      },
      {
        "id": "{nodeId}-input-searchType-options",
        "name": "searchType",
        "label": "searchType",
        "type": "options",
        "optional": true,
        "default": "similarity",
        "description": "Search Type"
      },
      {
        "id": "{nodeId}-input-fetchK-number",
        "name": "fetchK",
        "label": "fetchK",
        "type": "number",
        "optional": true,
        "description": "Number of initial documents to fetch for MMR reranking. Default to 20. Used only when the search typ"
      },
      {
        "id": "{nodeId}-input-lambda-number",
        "name": "lambda",
        "label": "lambda",
        "type": "number",
        "optional": true,
        "description": "Number between 0 and 1 that determines the degree of diversity among the results, where 0 correspond"
      }
    ],
    "outputAnchors": [
      {
        "id": "{nodeId}-output-zepCloud-Zep|VectorStoreRetriever|BaseRetriever",
        "name": "zepCloud",
        "label": "Zep Collection - Cloud",
        "type": "Zep | VectorStoreRetriever | BaseRetriever"
      }
    ],
    "outputs": {},
    "_flowdata_note": "Replace {nodeId} in all 'id' fields with your actual node ID (e.g. 'chatOpenAI_0'). Embed inputAnchors, inputParams, outputAnchors, and outputs verbatim in each flowData node's data object.",
    "version": "2",
    "description": "Upsert embedded data and perform similarity or mmr search upon query using Zep, a fast and scalable building block for LLM apps",
    "baseClasses": [
      "Zep",
      "VectorStoreRetriever",
      "BaseRetriever"
    ],
    "credential_required": [
      "zepMemoryApi"
    ]
  }
]